link,category,title,abstract,keywords,ccs_concepts,author_names,author_affiliations,author_countries
https://arxiv.org/abs/2010.06002,Transparency & Explainability,Incorporating Behavioral Constraints in Online AI Systems.,"This paper proposes a research direction to advance AI which draws inspiration from cognitive theories of human decision making. The premise is that if we gain insights about the causes of some human capabilities that are still lacking in AI (for instance, adaptability, generalizability, common sense, and causal reasoning), we may obtain similar capabilities in an AI system by embedding these causal components. We hope that the high-level description of our vision included in this paper, as well as the several research questions that we propose to consider, can stimulate the AI research community to define, try and evaluate new methodologies, frameworks, and evaluation metrics, in the spirit of achieving a better understanding of both human and machine intelligence.",[],[],"['Grady Booch', 'Francesco Fabiano', 'Lior Horesh', 'Kiran Kate', 'Jon Lenchner', 'Nick Linck', 'Andrea Loreggia', 'Keerthiram Murugesan', 'Nicholas Mattei', 'Francesca Rossi', 'Biplav Srivastava']",[],[]
https://arxiv.org/abs/2204.11910,Transparency & Explainability,Selecting Compliant Agents for Opt-in Micro-Tolling.,"We introduce a new setting, optimize-and-estimate structured bandits. Here, a policy must select a batch of arms, each characterized by its own context, that would allow it to both maximize reward and maintain an accurate (ideally unbiased) population estimate of the reward. This setting is inherent to many public and private sector applications and often requires handling delayed feedback, small data, and distribution shifts. We demonstrate its importance on real data from the United States Internal Revenue Service (IRS). The IRS performs yearly audits of the tax base. Two of its most important objectives are to identify suspected misreporting and to estimate the ""tax gap"" -- the global difference between the amount paid and true amount owed. Based on a unique collaboration with the IRS, we cast these two processes as a unified optimize-and-estimate structured bandit. We analyze optimize-and-estimate approaches to the IRS problem and propose a novel mechanism for unbiased population estimation that achieves rewards comparable to baseline approaches. This approach has the potential to improve audit efficacy, while maintaining policy-relevant estimates of the tax gap. This has important social consequences given that the current tax gap is estimated at nearly half a trillion dollars. We suggest that this problem setting is fertile ground for further research and we highlight its interesting challenges. The results of this and related research are currently being incorporated into the continual improvement of the IRS audit selection methods.",[],[],"['Peter Henderson', 'Ben Chugg', 'Brandon Anderson', 'Kristen Altenburger', 'Alex Turk', 'John Guyton', 'Jacob Goldin', 'Daniel E. Ho']","['The University of Texas at Austin', 'Texas A & M University', 'The University of Texas at Austin', 'The University of Texas at Austin']",[]
https://arxiv.org/abs/2109.09276,Transparency & Explainability,Violence Rating Prediction from Movie Scripts.,"In this paper, we introduce the task of predicting severity of age-restricted aspects of movie content based solely on the dialogue script. We first investigate categorizing the ordinal severity of movies on 5 aspects: Sex, Violence, Profanity, Substance consumption, and Frightening scenes. The problem is handled using a siamese network-based multitask framework which concurrently improves the interpretability of the predictions. The experimental results show that our method outperforms the previous state-of-the-art model and provides useful information to interpret model predictions. The proposed dataset and source code are publicly available at our GitHub repository.",[],[],"['Yigeng Zhang', 'Mahsa Shafaei', 'Fabio Gonzalez', 'Thamar Solorio']","['University of Southern California, Los Angeles, CA', 'University of Southern California, Los Angeles, CA', 'University of Southern California, Los Angeles, CA', 'University of Southern California, Los Angeles, CA', 'University of California Los Angeles, Los Angeles, CA', 'University of Southern California, Los Angeles, CA']",[]
https://arxiv.org/abs/2212.10788,Transparency & Explainability,Predicting Concrete and Abstract Entities in Modern Poetry.,"Drug repositioning holds great promise because it can reduce the time and cost of new drug development. While drug repositioning can omit various R&D processes, confirming pharmacological effects on biomolecules is essential for application to new diseases. Biomedical explainability in a drug repositioning model can support appropriate insights in subsequent in-depth studies. However, the validity of the XAI methodology is still under debate, and the effectiveness of XAI in drug repositioning prediction applications remains unclear. In this study, we propose GraphIX, an explainable drug repositioning framework using biological networks, and quantitatively evaluate its explainability. GraphIX first learns the network weights and node features using a graph neural network from known drug indication and knowledge graph that consists of three types of nodes (but not given node type information): disease, drug, and protein. Analysis of the post-learning features showed that node types that were not known to the model beforehand are distinguished through the learning process based on the graph structure. From the learned weights and features, GraphIX then predicts the disease-drug association and calculates the contribution values of the nodes located in the neighborhood of the predicted disease and drug. We hypothesized that the neighboring protein node to which the model gave a high contribution is important in understanding the actual pharmacological effects. Quantitative evaluation of the validity of protein nodes' contribution using a real-world database showed that the high contribution proteins shown by GraphIX are reasonable as a mechanism of drug action. GraphIX is a framework for evidence-based drug discovery that can present to users new disease-drug associations and identify the protein important for understanding its pharmacological effects from a large and complex knowledge base.",[],[],"['Atsuko Takagi', 'Mayumi Kamada', 'Eri Hamatani', 'Ryosuke Kojima', 'Yasushi Okuno']","['University of Copenhagen, DK Copenhagen', 'University of Copenhagen, DK Copenhagen']",[]
https://arxiv.org/abs/1812.02640,Transparency & Explainability,Pathological Evidence Exploration in Deep Retinal Image Diagnosis.,"Though deep learning has shown successful performance in classifying the label and severity stage of certain disease, most of them give few evidence on how to make prediction. Here, we propose to exploit the interpretability of deep learning application in medical diagnosis. Inspired by Koch's Postulates, a well-known strategy in medical research to identify the property of pathogen, we define a pathological descriptor that can be extracted from the activated neurons of a diabetic retinopathy detector. To visualize the symptom and feature encoded in this descriptor, we propose a GAN based method to synthesize pathological retinal image given the descriptor and a binary vessel segmentation. Besides, with this descriptor, we can arbitrarily manipulate the position and quantity of lesions. As verified by a panel of 5 licensed ophthalmologists, our synthesized images carry the symptoms that are directly related to diabetic retinopathy diagnosis. The panel survey also shows that our generated images is both qualitatively and quantitatively superior to existing methods.",[],[],"['Yuhao Niu', 'Lin Gu', 'Feng Lu', 'Feifan Lv', 'Zongji Wang', 'Imari Sato', 'Zijian Zhang', 'Yangyan Xiao', 'Xunzhang Dai', 'Tingting Cheng']","['State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University, Beijing, China and Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, China', 'National Institute of Informatics, Japan', 'State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University, Beijing, China and Beijing Advanced Innovation Center for Big Data-Based Precision Medicine, Beihang University, Beijing, China and Peng Cheng Laboratory, Shenzhen, China', 'State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University, Beijing, China and Peng Cheng Laboratory, Shenzhen, China', 'State Key Laboratory of VR Technology and Systems, School of CSE, Beihang University, Beijing, China', 'National Institute of Informatics, Japan', 'Xiangya Hospital Central South University, China', 'The Second Xiangya Hospital of Central South University, China', 'Xiangya Hospital Central South University, China', 'Xiangya Hospital Central South University, China']","['China', 'Japan', 'China', 'China', 'China', 'Japan', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/1909.01302,Transparency & Explainability,MPD-AL: An Efficient Membrane Potential Driven Aggregate-Label Learning Algorithm for Spiking Neurons.,"Auditory front-end is an integral part of a spiking neural network (SNN) when performing auditory cognitive tasks. It encodes the temporal dynamic stimulus, such as speech and audio, into an efficient, effective and reconstructable spike pattern to facilitate the subsequent processing. However, most of the auditory front-ends in current studies have not made use of recent findings in psychoacoustics and physiology concerning human listening. In this paper, we propose a neural encoding and decoding scheme that is optimized for speech processing. The neural encoding scheme, that we call Biologically plausible Auditory Encoding (BAE), emulates the functions of the perceptual components of the human auditory system, that include the cochlear filter bank, the inner hair cells, auditory masking effects from psychoacoustic models, and the spike neural encoding by the auditory nerve. We evaluate the perceptual quality of the BAE scheme using PESQ; the performance of the BAE based on speech recognition experiments. Finally, we also built and published two spike-version of speech datasets: the Spike-TIDIGITS and the Spike-TIMIT, for researchers to use and benchmarking of future SNN research.",[],[],"['Zihan Pan', 'Yansong Chua', 'Jibin Wu', 'Malu Zhang', 'Haizhou Li', 'Eliathamby Ambikairajah']","['School of Computer Science and Engineering, University of Electronic Science and Technology of China, China and Department of Electrical and Computer Engineering, National University of Singapore, Singapore', 'Department of Electrical and Computer Engineering, National University of Singapore, Singapore', 'Institute for Infocomm Research, A*STAR, Singapore', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China, China', 'Department of Electrical and Computer Engineering, National University of Singapore, Singapore', 'JD AI Research', 'Department of Electrical and Computer Engineering, National University of Singapore, Singapore and Institute for Infocomm Research, A*STAR, Singapore']","['China', 'Singapore', 'Singapore', 'China', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2009.12078,Transparency & Explainability,Adaptive Proximal Average Based Variance Reducing Stochastic Methods for Optimization with Composite Regularization.,"Optimizing with group sparsity is significant in enhancing model interpretability in machining learning applications, e.g., feature selection, compressed sensing and model compression. However, for large-scale stochastic training problems, effective group sparsity exploration are typically hard to achieve. Particularly, the state-of-the-art stochastic optimization algorithms usually generate merely dense solutions. To overcome this shortage, we propose a stochastic method -- Half-space Stochastic Projected Gradient (HSPG) method to search solutions of high group sparsity while maintain the convergence. Initialized by a simple Prox-SG Step, the HSPG method relies on a novel Half-Space Step to substantially boost the sparsity level. Numerically, HSPG demonstrates its superiority in deep neural networks, e.g., VGG16, ResNet18 and MobileNetV1, by computing solutions of higher group sparsity, competitive objective values and generalization accuracy.",[],[],"['Tianyi Chen', 'Guanyi Wang', 'Tianyu Ding', 'Bo Ji', 'Sheng Yi', 'Zhihui Zhu']","['School of Computer Science and Technology, University of Science and Technology of China, Hefei, China', 'School of Computer Science and Technology, University of Science and Technology of China, Hefei, China', 'School of Computer Science and Technology, University of Science and Technology of China, Hefei, China', 'School of Computer Science and Technology, University of Science and Technology of China, Hefei, China']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/1812.02993,Transparency & Explainability,Optimal Dynamic Auctions Are Virtual Welfare Maximizers.,"We are interested in the setting where a seller sells sequentially arriving items, one per period, via a dynamic auction. At the beginning of each period, each buyer draws a private valuation for the item to be sold in that period and this valuation is independent across buyers and periods. The auction can be dynamic in the sense that the auction at period $t$ can be conditional on the bids in that period and all previous periods, subject to certain appropriately defined incentive compatible and individually rational conditions. Perhaps not surprisingly, the revenue optimal dynamic auctions are computationally hard to find and existing literatures that aim to approximate the optimal auctions are all based on solving complex dynamic programs. It remains largely open on the structural interpretability of the optimal dynamic auctions. In this paper, we show that any optimal dynamic auction is a virtual welfare maximizer subject to some monotone allocation constraints. In particular, the explicit definition of the virtual value function above arises naturally from the primal-dual analysis by relaxing the monotone constraints. We further develop an ironing technique that gets rid of the monotone allocation constraints. Quite different from Myerson's ironing approach, our technique is more technically involved due to the interdependence of the virtual value functions across buyers. We nevertheless show that ironing can be done approximately and efficiently, which in turn leads to a Fully Polynomial Time Approximation Scheme of the optimal dynamic auction.",[],[],"['Vahab Mirrokni', 'Renato Paes Leme', 'Pingzhong Tang', 'Song Zuo']","['Google Research', 'Google Research', 'Tsinghua University', 'Google Research']",[]
https://arxiv.org/abs/2111.06721,Transparency & Explainability,Counterfactual Randomization: Rescuing Experimental Studies from Obscured Confounding.,"This paper serves to introduce the reader to the field of multi-agent reinforcement learning (MARL) and its intersection with methods from the study of causality. We highlight key challenges in MARL and discuss these in the context of how causal methods may assist in tackling them. We promote moving toward a 'causality first' perspective on MARL. Specifically, we argue that causality can offer improved safety, interpretability, and robustness, while also providing strong theoretical guarantees for emergent behaviour. We discuss potential solutions for common challenges, and use this context to motivate future research directions.",[],[],"['St John Grimbly', 'Jonathan Shock', 'Arnu Pretorius']","['Department of Computer Science, Loyola Marymount University, Los Angeles, CA', 'Department of Computer Science, Purdue University, West Lafayette, IN']",[]
https://arxiv.org/abs/2208.12523,Transparency & Explainability,Deep Neural Networks Constrained by Decision Rules.,"We describe a novel approach to explainable prediction of a continuous variable based on learning fuzzy weighted rules. Our model trains a set of weighted rules to maximise prediction accuracy and minimise an ontology-based 'semantic loss' function including user-specified constraints on the rules that should be learned in order to maximise the explainability of the resulting rule set from a user perspective. This system fuses quantitative sub-symbolic learning with symbolic learning and constraints based on domain knowledge. We illustrate our system on a case study in predicting the outcomes of behavioural interventions for smoking cessation, and show that it outperforms other interpretable approaches, achieving performance close to that of a deep learning model, while offering transparent explainability that is an essential requirement for decision-makers in the health domain.",[],[],"['Martin Glauer', 'Robert West', 'Susan Michie', 'Janna Hastings']","['NEC Corporation, Kawasaki, Kanagawa, Japan', 'NEC Corporation, Kawasaki, Kanagawa, Japan']","['Japan', 'Japan']"
https://arxiv.org/abs/2103.11072,Transparency & Explainability,FLEX: Faithful Linguistic Explanations for Neural Net Based Model Decisions.,"As the use of deep learning techniques has grown across various fields over the past decade, complaints about the opaqueness of the black-box models have increased, resulting in an increased focus on transparency in deep learning models. This work investigates various methods to improve the interpretability of deep neural networks for natural language processing (NLP) tasks, including machine translation and sentiment analysis. We provide a comprehensive discussion on the definition of the term \textit{interpretability} and its various aspects at the beginning of this work. The methods collected and summarised in this survey are only associated with local interpretation and are divided into three categories: 1) explaining the model's predictions through related input features; 2) explaining through natural language explanation; 3) probing the hidden states of models and word representations.",[],[],"['Siwen Luo', 'Hamish Ivison', 'Caren Han', 'Josiah Poon']","['School of Computing, National University of Singapore', 'School of Computing, National University of Singapore', 'School of Computing, National University of Singapore']","['Singapore', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2003.05311,Transparency & Explainability,Certifying the True Error: Machine Learning in Coq with Verified Generalization Guarantees.,"Increasingly sophisticated mathematical modelling processes from Machine Learning are being used to analyse complex data. However, the performance and explainability of these models within practical critical systems requires a rigorous and continuous verification of their safe utilisation. Working towards addressing this challenge, this paper presents a principled novel safety argument framework for critical systems that utilise deep neural networks. The approach allows various forms of predictions, e.g., future reliability of passing some demands, or confidence on a required reliability level. It is supported by a Bayesian analysis using operational data and the recent verification and validation techniques for deep learning. The prediction is conservative -- it starts with partial prior knowledge obtained from lifecycle activities and then determines the worst-case prediction. Open challenges are also identified.",[],[],"['Xingyu Zhao', 'Alec Banks', 'James Sharp', 'Valentin Robu', 'David Flynn', 'Michael Fisher', 'Xiaowei Huang']","['Ohio University, Athens, OH', 'Ohio University, Athens, OH']",[]
https://arxiv.org/abs/1901.00433,Transparency & Explainability,Identification of Causal Effects in the Presence of Selection Bias.,"We prove the main rules of causal calculus (also called do-calculus) for i/o structural causal models (ioSCMs), a generalization of a recently proposed general class of non-/linear structural causal models that allow for cycles, latent confounders and arbitrary probability distributions. We also generalize adjustment criteria and formulas from the acyclic setting to the general one (i.e. ioSCMs). Such criteria then allow to estimate (conditional) causal effects from observational data that was (partially) gathered under selection bias and cycles. This generalizes the backdoor criterion, the selection-backdoor criterion and extensions of these to arbitrary ioSCMs. Together, our results thus enable causal reasoning in the presence of cycles, latent confounders and selection bias. Finally, we extend the ID algorithm for the identification of causal effects to ioSCMs.",[],[],"['Patrick Forré', 'Joris M. Mooij']","['Computer Science Department, Purdue University', 'Department of Computer Science, Iowa State University', 'Computer Science Department, Purdue University']",[]
https://arxiv.org/abs/1811.00090,Transparency & Explainability,SDRL: Interpretable and Data-Efficient Deep Reinforcement Learning Leveraging Symbolic Planning.,"Deep reinforcement learning (DRL) has gained great success by learning directly from high-dimensional sensory inputs, yet is notorious for the lack of interpretability. Interpretability of the subtasks is critical in hierarchical decision-making as it increases the transparency of black-box-style DRL approach and helps the RL practitioners to understand the high-level behavior of the system better. In this paper, we introduce symbolic planning into DRL and propose a framework of Symbolic Deep Reinforcement Learning (SDRL) that can handle both high-dimensional sensory inputs and symbolic planning. The task-level interpretability is enabled by relating symbolic actions to options.This framework features a planner -- controller -- meta-controller architecture, which takes charge of subtask scheduling, data-driven subtask learning, and subtask evaluation, respectively. The three components cross-fertilize each other and eventually converge to an optimal symbolic plan along with the learned subtasks, bringing together the advantages of long-term planning capability with symbolic knowledge and end-to-end reinforcement learning directly from a high-dimensional sensory input. Experimental results validate the interpretability of subtasks, along with improved data efficiency compared with state-of-the-art approaches.",[],[],"['Daoming Lyu', 'Fangkai Yang', 'Bo Liu', 'Steven Gustafson']","['Auburn University, Auburn, AL', 'Maana Inc., Bellevue, WA', 'Auburn University, Auburn, AL', 'Maana Inc., Bellevue, WA']",[]
https://arxiv.org/abs/1809.09307,Transparency & Explainability,Utilizing Class Information for Deep Network Representation Shaping.,"Statistical characteristics of deep network representations, such as sparsity and correlation, are known to be relevant to the performance and interpretability of deep learning. When a statistical characteristic is desired, often an adequate regularizer can be designed and applied during the training phase. Typically, such a regularizer aims to manipulate a statistical characteristic over all classes together. For classification tasks, however, it might be advantageous to enforce the desired characteristic per class such that different classes can be better distinguished. Motivated by the idea, we design two class-wise regularizers that explicitly utilize class information: class-wise Covariance Regularizer (cw-CR) and class-wise Variance Regularizer (cw-VR). cw-CR targets to reduce the covariance of representations calculated from the same class samples for encouraging feature independence. cw-VR is similar, but variance instead of covariance is targeted to improve feature compactness. For the sake of completeness, their counterparts without using class information, Covariance Regularizer (CR) and Variance Regularizer (VR), are considered together. The four regularizers are conceptually simple and computationally very efficient, and the visualization shows that the regularizers indeed perform distinct representation shaping. In terms of classification performance, significant improvements over the baseline and L1/L2 weight regularization methods were found for 21 out of 22 tasks over popular benchmark datasets. In particular, cw-VR achieved the best performance for 13 tasks including ResNet-32/110.",[],[],"['Daeyoung Choi', 'Wonjong Rhee']","['Department of Transdisciplinary Studies, Seoul National University, Seoul, South Korea', 'Department of Transdisciplinary Studies, Seoul National University, Seoul, South Korea']",[]
https://arxiv.org/abs/2309.11196,Transparency & Explainability,Inverse Abstraction of Neural Networks Using Symbolic Interpolation.,"Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges.",[],[],"['Marta Kwiatkowska', 'Xiyue Zhang']","['Computing and Mathematical Sciences, California Institute of Technology', 'Computer Science and Engineering, University of California, San Diego', 'Computing and Mathematical Sciences, California Institute of Technology']",[]
https://arxiv.org/abs/2309.16693,Transparency & Explainability,Precision-Recall versus Accuracy and the Role of Large Data Sets.,"This study explores the application and performance of Transformational Machine Learning (TML) in drug discovery. TML, a meta learning algorithm, excels in exploiting common attributes across various domains, thus developing composite models that outperform conventional models. The drug discovery process, which is complex and time-consuming, can benefit greatly from the enhanced prediction accuracy, improved interpretability and greater generalizability provided by TML. We explore the efficacy of different machine learning classifiers, where no individual classifier exhibits distinct superiority, leading to the consideration of ensemble classifiers such as the Random Forest. Our findings show that TML outperforms base Machine Learning (ML) as the number of training datasets increases, due to its capacity to better approximate the correct hypothesis, overcome local optima, and expand the space of representable functions by combining separate classifiers capabilities. However, this superiority is relative to the resampling methods applied, with Near Miss demonstrating poorer performance due to noisy data, overlapping classes, and nonlinear class boundaries. Conversely, Random Over Sampling (ROS) provides a more robust performance given its resistance to noise and outliers, improved class overlap management, and suitability for nonlinear class boundaries.",[],[],"['Adnan Mahmud', 'Oghenejokpeme Orhobor', 'Ross D. King']","['Washington University in St. Louis, St. Louis, MO', 'Washington University in St. Louis, St. Louis, MO']",[]
https://arxiv.org/abs/1909.05038,Transparency & Explainability,Accurate and Interpretable Factorization Machines.,"Model-based approaches to recommendation can recommend items with a very high level of accuracy. Unfortunately, even when the model embeds content-based information, if we move to a latent space we miss references to the actual semantics of recommended items. Consequently, this makes non-trivial the interpretation of a recommendation process. In this paper, we show how to initialize latent factors in Factorization Machines by using semantic features coming from a knowledge graph in order to train an interpretable model. With our model, semantic features are injected into the learning process to retain the original informativeness of the items available in the dataset. The accuracy and effectiveness of the trained model have been tested using two well-known recommender systems datasets. By relying on the information encoded in the original knowledge graph, we have also evaluated the semantic accuracy and robustness for the knowledge-aware interpretability of the final model.",[],[],"['Vito Walter Anelli', 'Tommaso Di Noia', 'Eugenio Di Sciascio', 'Azzurra Ragone', 'Joseph Trotta']","['Department of Computer Science, Hong Kong Baptist University, Hong Kong SAR, China', 'Department of Computer Science and Technology, East China Normal University, China']","['China', 'China']"
https://arxiv.org/abs/2001.04163,Transparency & Explainability,Scale Invariant Fully Convolutional Network: Detecting Hands Efficiently.,"The lack of interpretability of existing CNN-based hand detection methods makes it difficult to understand the rationale behind their predictions. In this paper, we propose a novel neural network model, which introduces interpretability into hand detection for the first time. The main improvements include: (1) Detect hands at pixel level to explain what pixels are the basis for its decision and improve transparency of the model. (2) The explainable Highlight Feature Fusion block highlights distinctive features among multiple layers and learns discriminative ones to gain robust performance. (3) We introduce a transparent representation, the rotation map, to learn rotation features instead of complex and non-transparent rotation and derotation layers. (4) Auxiliary supervision accelerates the training process, which saves more than 10 hours in our experiments. Experimental results on the VIVA and Oxford hand detection and tracking datasets show competitive accuracy of our method compared with state-of-the-art methods with higher speed.",[],[],"['Dan Liu', 'Libo Zhang', 'Tiejian Luo', 'Lili Tao', 'Yanjun Wu']","['University of the Chinese Academy of Sciences, China', 'University at Albany, SUNY', 'Institute of Software Chinese Academy of Sciences, China', 'University of the Chinese Academy of Sciences, China', 'Institute of Software Chinese Academy of Sciences, China', 'Tencent Youtu Lab, China', 'University at Albany, SUNY']","['China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/1809.05630,Transparency & Explainability,Towards Better Interpretability in Deep Q-Networks.,"Deep reinforcement learning techniques have demonstrated superior performance in a wide variety of environments. As improvements in training algorithms continue at a brisk pace, theoretical or empirical studies on understanding what these networks seem to learn, are far behind. In this paper we propose an interpretable neural network architecture for Q-learning which provides a global explanation of the model's behavior using key-value memories, attention and reconstructible embeddings. With a directed exploration strategy, our model can reach training rewards comparable to the state-of-the-art deep Q-learning models. However, results suggest that the features extracted by the neural network are extremely shallow and subsequent testing using out-of-sample examples shows that the agent can easily overfit to trajectories seen during training.",[],[],"['Raghuram Mandyam Annasamy', 'Katia Sycara']","['Carnegie Mellon University', 'Carnegie Mellon University']",[]
https://arxiv.org/abs/2201.08164,Transparency & Explainability,Interpretable Preference Learning: A Game Theoretic Framework for Large Margin On-Line Feature and Rule Learning.,"The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the last 7 years at major AI and ML conferences that introduce an XAI method. We find that 1 in 3 papers evaluate exclusively with anecdotal evidence, and 1 in 5 papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training in order to optimize for accuracy and interpretability simultaneously.",[],[],"['Meike Nauta', 'Jan Trienes', 'Shreyasi Pathak', 'Elisa Nguyen', 'Michelle Peters', 'Yasmin Schmitt', 'Jörg Schlötterer', 'Maurice van Keulen', 'Christin Seifert']","['Department of Mathematics, University of Padova, Italy', 'Department of Mathematics, University of Padova, Italy']","['Italy', 'Italy']"
https://arxiv.org/abs/1902.05731,Transparency & Explainability,SVM-Based Deep Stacking Networks.,"The deep network model, with the majority built on neural networks, has been proved to be a powerful framework to represent complex data for high performance machine learning. In recent years, more and more studies turn to nonneural network approaches to build diverse deep structures, and the Deep Stacking Network (DSN) model is one of such approaches that uses stacked easy-to-learn blocks to build a parameter-training-parallelizable deep network. In this paper, we propose a novel SVM-based Deep Stacking Network (SVM-DSN), which uses the DSN architecture to organize linear SVM classifiers for deep learning. A BP-like layer tuning scheme is also proposed to ensure holistic and local optimizations of stacked SVMs simultaneously. Some good math properties of SVM, such as the convex optimization, is introduced into the DSN framework by our model. From a global view, SVM-DSN can iteratively extract data representations layer by layer as a deep neural network but with parallelizability, and from a local view, each stacked SVM can converge to its optimal solution and obtain the support vectors, which compared with neural networks could lead to interesting improvements in anti-saturation and interpretability. Experimental results on both image and text data sets demonstrate the excellent performances of SVM-DSN compared with some competitive benchmark models.",[],[],"['Jingyuan Wang', 'Kai Feng', 'Junjie Wu']",[],[]
https://arxiv.org/abs/1811.04540,Transparency & Explainability,Explainable Reasoning over Knowledge Graphs for Recommendation.,"Incorporating knowledge graph into recommender systems has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity between users and items can be discovered as paths, which provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics of entities and relations, but also helps to comprehend a user's interest. However, existing efforts have not fully explored this connectivity to infer user preferences, especially in terms of modeling the sequential dependencies within and holistic semantics of a path. In this paper, we contribute a new model named Knowledge-aware Path Recurrent Network (KPRN) to exploit knowledge graph for recommendation. KPRN can generate path representations by composing the semantics of both entities and relations. By leveraging the sequential dependencies within a path, we allow effective reasoning on paths to infer the underlying rationale of a user-item interaction. Furthermore, we design a new weighted pooling operation to discriminate the strengths of different paths in connecting a user with an item, endowing our model with a certain level of explainability. We conduct extensive experiments on two datasets about movie and music, demonstrating significant improvements over state-of-the-art solutions Collaborative Knowledge Base Embedding and Neural Factorization Machine.",[],[],"['Xiang Wang', 'Dingxian Wang', 'Canran Xu', 'Xiangnan He', 'Yixin Cao', 'Tat-Seng Chua']","['School of Computing, National University of Singapo', 'eBay', 'eBay', 'School of Information Science and Technology, University of Science and Technology of China', 'School of Computing, National University of Singapore', 'School of Computing, National University of Singapore']","['China', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2009.08559,Transparency & Explainability,How Does Knowledge of the AUC Constrain the Set of Possible Ground-Truth Labelings?,"Membership Inference Attacks exploit the vulnerabilities of exposing models trained on customer data to queries by an adversary. In a recently proposed implementation of an auditing tool for measuring privacy leakage from sensitive datasets, more refined aggregates like the Log-Loss scores are exposed for simulating inference attacks as well as to assess the total privacy leakage based on the adversary's predictions. In this paper, we prove that this additional information enables the adversary to infer the membership of any number of datapoints with full accuracy in a single query, causing complete membership privacy breach. Our approach obviates any attack model training or access to side knowledge with the adversary. Moreover, our algorithms are agnostic to the model under attack and hence, enable perfect membership inference even for models that do not memorize or overfit. In particular, our observations provide insight into the extent of information leakage from statistical aggregates and how they can be exploited.",[],[],"['Abhinav Aggarwal', 'Zekun Xu', 'Oluwaseyi Feyisetan', 'Nathanael Teissier']","['Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA']",[]
https://arxiv.org/abs/2207.09237,Transparency & Explainability,Hierarchical Classification Based on Label Distribution Learning.,"Semi-supervised learning (SSL) is a common approach to learning predictive models using not only labeled examples, but also unlabeled examples. While SSL for the simple tasks of classification and regression has received a lot of attention from the research community, this is not properly investigated for complex prediction tasks with structurally dependent variables. This is the case of multi-label classification and hierarchical multi-label classification tasks, which may require additional information, possibly coming from the underlying distribution in the descriptive space provided by unlabeled examples, to better face the challenging task of predicting simultaneously multiple class labels. In this paper, we investigate this aspect and propose a (hierarchical) multi-label classification method based on semi-supervised learning of predictive clustering trees. We also extend the method towards ensemble learning and propose a method based on the random forest approach. Extensive experimental evaluation conducted on 23 datasets shows significant advantages of the proposed method and its extension with respect to their supervised counterparts. Moreover, the method preserves interpretability and reduces the time complexity of classical tree-based models.",[],[],"['Jurica Levatić', 'Michelangelo Ceci', 'Dragi Kocev', 'Sašo Džeroski']","['MOE Key Laboratory of Computer Network and Information Integration, School of Computer Science and Engineering, Southeast University, Nanjing, China', 'MOE Key Laboratory of Computer Network and Information Integration, School of Computer Science and Engineering, Southeast University, Nanjing, China']","['China', 'China']"
https://arxiv.org/abs/2101.12457,Transparency & Explainability,Multi-Order Attentive Ranking Model for Sequential Recommendation.,"Sequential recommendation (SR) is to accurately recommend a list of items for a user based on her current accessed ones. While new-coming users continuously arrive in the real world, one crucial task is to have inductive SR that can produce embeddings of users and items without re-training. Given user-item interactions can be extremely sparse, another critical task is to have transferable SR that can transfer the knowledge derived from one domain with rich data to another domain. In this work, we aim to present the holistic SR that simultaneously accommodates conventional, inductive, and transferable settings. We propose a novel deep learning-based model, Relational Temporal Attentive Graph Neural Networks (RetaGNN), for holistic SR. The main idea of RetaGNN is three-fold. First, to have inductive and transferable capabilities, we train a relational attentive GNN on the local subgraph extracted from a user-item pair, in which the learnable weight matrices are on various relations among users, items, and attributes, rather than nodes or edges. Second, long-term and short-term temporal patterns of user preferences are encoded by a proposed sequential self-attention mechanism. Third, a relation-aware regularization term is devised for better training of RetaGNN. Experiments conducted on MovieLens, Instagram, and Book-Crossing datasets exhibit that RetaGNN can outperform state-of-the-art methods under conventional, inductive, and transferable settings. The derived attention weights also bring model explainability.",[],[],"['Cheng Hsu', 'Cheng-Te Li']","['King Abdullah University of Science and Technology, Thuwal, SA', 'University of Notre Dame, IN', 'King Abdullah University of Science and Technology, Thuwal and School of Data and Computer Science, Sun Yat-sen University, China', 'King Abdullah University of Science and Technology, Thuwal, SA']",['China']
https://arxiv.org/abs/2006.00075,Transparency & Explainability,Interpreting Deep Models for Text Analysis via Optimization and Regularization Methods.,"Many text classification applications require models with satisfying performance as well as good interpretability. Traditional machine learning methods are easy to interpret but have low accuracies. The development of deep learning models boosts the performance significantly. However, deep learning models are typically hard to interpret. In this work, we propose interpretable capsule networks (iCapsNets) to bridge this gap. iCapsNets use capsules to model semantic meanings and explore novel methods to increase interpretability. The design of iCapsNets is consistent with human intuition and enables it to produce human-understandable interpretation results. Notably, iCapsNets can be interpreted both locally and globally. In terms of local interpretability, iCapsNets offer a simple yet effective method to explain the predictions for each data sample. On the other hand, iCapsNets explore a novel way to explain the model's general behavior, achieving global interpretability. Experimental studies show that our iCapsNets yield meaningful local and global interpretation results, without suffering from significant performance loss compared to non-interpretable methods.",[],[],"['Zhengyang Wang', 'Xia Hu', 'Shuiwang Ji']","['Washington State University', 'Washington State University', 'Texas A & M University', 'Texas A & M University']",[]
https://arxiv.org/abs/1812.09355,Transparency & Explainability,What Is One Grain of Sand in the Desert? Analyzing Individual Neurons in Deep NLP Models.,"Despite the remarkable evolution of deep neural networks in natural language processing (NLP), their interpretability remains a challenge. Previous work largely focused on what these models learn at the representation level. We break this analysis down further and study individual dimensions (neurons) in the vector representation learned by end-to-end neural models in NLP tasks. We propose two methods: Linguistic Correlation Analysis, based on a supervised method to extract the most relevant neurons with respect to an extrinsic task, and Cross-model Correlation Analysis, an unsupervised method to extract salient neurons w.r.t. the model itself. We evaluate the effectiveness of our techniques by ablating the identified neurons and reevaluating the network's performance for two tasks: neural machine translation (NMT) and neural language modeling (NLM). We further present a comprehensive analysis of neurons with the aim to address the following questions: i) how localized or distributed are different linguistic properties in the models? ii) are certain neurons exclusive to some properties and not others? iii) is the information more or less distributed in NMT vs. NLM? and iv) how important are the neurons identified through the linguistic correlation method to the overall task? Our code is publicly available as part of the NeuroX toolkit (Dalvi et al. 2019).",[],[],"['Fahim Dalvi', 'Nadir Durrani', 'Hassan Sajjad', 'Yonatan Belinkov', 'Anthony Bau', 'James Glass']","['Qatar Computing Research Institute, HBKU Research Complex, Doha, Qatar', 'Qatar Computing Research Institute, HBKU Research Complex, Doha, Qatar', 'Qatar Computing Research Institute, HBKU Research Complex, Doha, Qatar', 'MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA', 'MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA', 'MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA']","['Qatar', 'Qatar', 'Qatar']"
https://arxiv.org/abs/1809.06709,Transparency & Explainability,Document Informed Neural Autoregressive Topic Models with Distributional Prior.,"We address two challenges in topic models: (1) Context information around words helps in determining their actual meaning, e.g., ""networks"" used in the contexts ""artificial neural networks"" vs. ""biological neuron networks"". Generative topic models infer topic-word distributions, taking no or only little context into account. Here, we extend a neural autoregressive topic model to exploit the full context information around words in a document in a language modeling fashion. The proposed model is named as iDocNADE. (2) Due to the small number of word occurrences (i.e., lack of context) in short text and data sparsity in a corpus of few documents, the application of topic models is challenging on such texts. Therefore, we propose a simple and efficient way of incorporating external knowledge into neural autoregressive topic models: we use embeddings as a distributional prior. The proposed variants are named as DocNADEe and iDocNADEe. We present novel neural autoregressive topic model variants that consistently outperform state-of-the-art generative topic models in terms of generalization, interpretability (topic coherence) and applicability (retrieval and classification) over 7 long-text and 8 short-text datasets from diverse domains.",[],[],"['Pankaj Gupta', 'Yatin Chaudhary', 'Florian Buettner', 'Hinrich Schütze']","['Corporate Technology, Machine-Intelligence (MIC-DE), Siemens AG Munich, Germany and CIS, University of Munich (LMU) Munich, Germany', 'Corporate Technology, Machine-Intelligence (MIC-DE), Siemens AG Munich, Germany', 'Corporate Technology, Machine-Intelligence (MIC-DE), Siemens AG Munich, Germany', 'CIS, University of Munich (LMU) Munich, Germany']","['Germany', 'Germany', 'Germany', 'Germany']"
https://arxiv.org/abs/1811.08600,Transparency & Explainability,Contextualized Non-Local Neural Networks for Sequence Learning.,"Recently, a large number of neural mechanisms and models have been proposed for sequence learning, of which self-attention, as exemplified by the Transformer model, and graph neural networks (GNNs) have attracted much attention. In this paper, we propose an approach that combines and draws on the complementary strengths of these two methods. Specifically, we propose contextualized non-local neural networks (CN$^{\textbf{3}}$), which can both dynamically construct a task-specific structure of a sentence and leverage rich local dependencies within a particular neighborhood. Experimental results on ten NLP tasks in text classification, semantic matching, and sequence labeling show that our proposed model outperforms competitive baselines and discovers task-specific dependency structures, thus providing better interpretability to users.",[],[],"['Pengfei Liu', 'Shuaichen Chang', 'Xuanjing Huang', 'Jian Tang', 'Jackie Chi Kit Cheung']","['School of Computer Science, Fudan University, Shanghai Insitute of Intelligent Electronics & Systems and MILA', '', 'School of Computer Science, Fudan University, Shanghai Insitute of Intelligent Electronics & Systems', 'MILA', 'MILA and McGill University & The Ohio State University']",[]
https://arxiv.org/abs/2009.12431,Transparency & Explainability,Exploring Knowledge Graphs in an Interpretable Composite Approach for Text Entailment.,"Text entailment, the task of determining whether a piece of text logically follows from another piece of text, is a key component in NLP, providing input for many semantic applications such as question answering, text summarization, information extraction, and machine translation, among others. Entailment scenarios can range from a simple syntactic variation to more complex semantic relationships between pieces of text, but most approaches try a one-size-fits-all solution that usually favors some scenario to the detriment of another. Furthermore, for entailments requiring world knowledge, most systems still work as a ""black box"", providing a yes/no answer that does not explain the underlying reasoning process. In this work, we introduce XTE - Explainable Text Entailment - a novel composite approach for recognizing text entailment which analyzes the entailment pair to decide whether it must be resolved syntactically or semantically. Also, if a semantic matching is involved, we make the answer interpretable, using external knowledge bases composed of structured lexical definitions to generate natural language justifications that explain the semantic relationship holding between the pieces of text. Besides outperforming well-established entailment algorithms, our composite approach gives an important step towards Explainable AI, allowing the inference model interpretation, making the semantic reasoning process explicit and understandable.",[],[],"['Vivian S. Silva', 'André Freitas', 'Siegfried Handschuh']","['Department of Computer Science and Mathematics, University of Passau, Passau, Germany', 'School of Computer Science, University of Manchester, UK', 'Department of Computer Science and Mathematics, University of Passau, Passau, Germany and Institute of Computer Science, University of St. Gallen, St. Gallen, Switzerland']","['Germany', 'UK', 'Switzerland']"
https://arxiv.org/abs/2202.00486,Transparency & Explainability,Fast PMI-Based Word Embedding with Efficient Use of Unobserved Patterns.,"Representing words by vectors, or embeddings, enables computational reasoning and is foundational to automating natural language tasks. For example, if word embeddings of similar words contain similar values, word similarity can be readily assessed, whereas judging that from their spelling is often impossible (e.g. cat /feline) and to predetermine and store similarities between all words is prohibitively time-consuming, memory intensive and subjective. We focus on word embeddings learned from text corpora and knowledge graphs. Several well-known algorithms learn word embeddings from text on an unsupervised basis by learning to predict those words that occur around each word, e.g. word2vec and GloVe. Parameters of such word embeddings are known to reflect word co-occurrence statistics, but how they capture semantic meaning has been unclear. Knowledge graph representation models learn representations both of entities (words, people, places, etc.) and relations between them, typically by training a model to predict known facts in a supervised manner. Despite steady improvements in fact prediction accuracy, little is understood of the latent structure that enables this. The limited understanding of how latent semantic structure is encoded in the geometry of word embeddings and knowledge graph representations makes a principled means of improving their performance, reliability or interpretability unclear. To address this: 1. we theoretically justify the empirical observation that particular geometric relationships between word embeddings learned by algorithms such as word2vec and GloVe correspond to semantic relations between words; and 2. we extend this correspondence between semantics and geometry to the entities and relations of knowledge graphs, providing a model for the latent structure of knowledge graph representation linked to that of word embeddings.",[],[],['Carl Allen'],"['Institute for Big Data Analytics, Faculty of Computer Science, Dalhousie University, Halifax NS, Canada', 'Institute for Big Data Analytics, Faculty of Computer Science, Dalhousie University, Halifax NS, Canada and Institute of Computer Science, Polish Academy of Sciences, Warsaw, Poland']","['Canada', 'Canada']"
https://arxiv.org/abs/2105.09045,Transparency & Explainability,Improving Hypernymy Prediction via Taxonomy Enhanced Adversarial Learning.,"Deep neural networks such as BERT have made great progress in relation classification. Although they can achieve good performance, it is still a question of concern whether these models recognize the directionality of relations, especially when they may lack interpretability. To explore the question, a novel evaluation task, called Relation Direction Recognition (RDR), is proposed to explore whether models learn the directionality of relations. Three metrics for RDR are introduced to measure the degree to which models recognize the directionality of relations. Several state-of-the-art models are evaluated on RDR. Experimental results on a real-world dataset indicate that there are clear gaps among them in recognizing the directionality of relations, even though these models obtain similar performance in the traditional metric (e.g. Macro-F1). Finally, some suggestions are discussed to enhance models to recognize the directionality of relations from the perspective of model design or training.",[],[],"['Shengfei Lyu', 'Xingyu Wu', 'Jinlong Li', 'Qiuju Chen', 'Huanhuan Chen']","['School of Computer Science and Software Engineering, East China Normal University', 'School of Computer Science and Software Engineering, East China Normal University', 'School of Data Science and Engineering, East China Normal University']","['China', 'China', 'China']"
https://arxiv.org/abs/2011.10707,Transparency & Explainability,Red-Black Heuristics for Planning Tasks with Conditional Effects.,"A new design of an AI assistant that has become increasingly popular is that of an ""aggregated assistant"" -- realized as an orchestrated composition of several individual skills or agents that can each perform atomic tasks. In this paper, we will talk about the role of planning in the automated composition of such assistants and explore how concepts in automated planning can help to establish transparency of the inner workings of the assistant to the end-user.",[],[],"['Sarath Sreedharan', 'Tathagata Chakraborti', 'Yara Rizk', 'Yasaman Khazaeni']","['IBM Research, Yorktown Heights, NY']",[]
https://arxiv.org/abs/1011.1937,Transparency & Explainability,A Generative Model for Dynamic Networks with Applications.,"Models of dynamic networks --- networks that evolve over time --- have manifold applications. We develop a discrete-time generative model for social network evolution that inherits the richness and flexibility of the class of exponential-family random graph models. The model --- a Separable Temporal ERGM (STERGM) --- facilitates separable modeling of the tie duration distributions and the structural dynamics of tie formation. We develop likelihood-based inference for the model, and provide computational algorithms for maximum likelihood estimation. We illustrate the interpretability of the model in analyzing a longitudinal network of friendship ties within a school.",[],[],"['Pavel N. Krivitsky', 'Mark S. Handcock']","['Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India', 'Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India', 'Department of Computer Science and Automation, Indian Institute of Science, Bangalore, India']","['India', 'India', 'India']"
https://arxiv.org/abs/2105.12115,Transparency & Explainability,Calibrated Stochastic Gradient Descent for Convolutional Neural Networks.,"Deep neural networks offer numerous potential applications across geoscience, for example, one could argue that they are the state-of-the-art method for predicting faults in seismic datasets. In quantitative reservoir characterization workflows, it is common to incorporate the uncertainty of predictions thus such subsurface models should provide calibrated probabilities and the associated uncertainties in their predictions. It has been shown that popular Deep Learning-based models are often miscalibrated, and due to their deterministic nature, provide no means to interpret the uncertainty of their predictions. We compare three different approaches to obtaining probabilistic models based on convolutional neural networks in a Bayesian formalism, namely Deep Ensembles, Concrete Dropout, and Stochastic Weight Averaging-Gaussian (SWAG). These methods are consistently applied to fault detection case studies where Deep Ensembles use independently trained models to provide fault probabilities, Concrete Dropout represents an extension to the popular Dropout technique to approximate Bayesian neural networks, and finally, we apply SWAG, a recent method that is based on the Bayesian inference equivalence of mini-batch Stochastic Gradient Descent. We provide quantitative results in terms of model calibration and uncertainty representation, as well as qualitative results on synthetic and real seismic datasets. Our results show that the approximate Bayesian methods, Concrete Dropout and SWAG, both provide well-calibrated predictions and uncertainty attributes at a lower computational cost when compared to the baseline Deep Ensemble approach. The resulting uncertainties also offer a possibility to further improve the model performance as well as enhancing the interpretability of the models.",[],[],"['Lukas Mosser', 'Ehsan Zabihi Naeini']","['School of Automation Science and Electrical Engineering, Beihang University, Beijing', 'School of Automation Science and Electrical Engineering, Beihang University, Beijing', 'University of North Carolina at Charlotte, Charlotte, NC', 'University of Chinese Academy of Sciences, China', ""Huawei Noah's Ark Lab"", 'Department of Computer Science and Engineering University at Buffalo, Buffalo, NY']",['China']
https://arxiv.org/abs/2008.08753,Transparency & Explainability,Logistic Regression on Homomorphic Encrypted Data at Scale.,"Logistic Regression (LR) is the most widely used machine learning model in industry for its efficiency, robustness, and interpretability. Due to the problem of data isolation and the requirement of high model performance, many applications in industry call for building a secure and efficient LR model for multiple parties. Most existing work uses either Homomorphic Encryption (HE) or Secret Sharing (SS) to build secure LR. HE based methods can deal with high-dimensional sparse features, but they incur potential security risks. SS based methods have provable security, but they have efficiency issue under high-dimensional sparse features. In this paper, we first present CAESAR, which combines HE and SS to build secure large-scale sparse logistic regression model and achieves both efficiency and security. We then present the distributed implementation of CAESAR for scalability requirement. We have deployed CAESAR in a risk control task and conducted comprehensive experiments. Our experimental results show that CAESAR improves the state-of-the-art model by around 130 times.",[],[],"['Chaochao Chen', 'Jun Zhou', 'Li Wang', 'Xibin Wu', 'Wenjing Fang', 'Jin Tan', 'Lei Wang', 'Alex X. Liu', 'Hao Wang', 'Cheng Hong']","['Seoul National University, Seoul, South Korea', 'Seoul National University, Seoul, South Korea', 'Seoul National University, Seoul, South Korea', 'University of Illinois, Urbana-Champaign, IL']",[]
https://arxiv.org/abs/2202.03583,Transparency & Explainability,Building Trust in Deep Learning System towards Automated Disease Detection.,"Traditional methods of identifying pathologies in X-ray images rely heavily on skilled human interpretation and are often time-consuming. The advent of deep learning techniques has enabled the development of automated disease diagnosis systems, but the performance of such systems is dependent on the quality of the model and the level of interpretability it provides. In this paper, we propose a multi-label disease diagnosis model for chest X-rays using a dense convolutional neural network (DenseNet) and model interpretability using GRADCAM. We trained our model using frontal X-rays and evaluated its performance using various quantitative metrics, including the area under the receiver operating characteristic curve (AUC). Our proposed model achieved the highest AUC score of 0.896 for the condition Cardiomegaly with an accuracy of 0.826, while the lowest AUC score was obtained for Nodule, at 0.655 with an accuracy of 0.66. To promote model interpretability and build trust in decision making, we generated heatmaps on X-rays to visualize the regions where the model paid attention to make certain predictions. Additionally, we estimated the uncertainty in model predictions by presenting the confidence interval of our measurements. Our proposed automated disease diagnosis model obtained high performance metrics in multi-label disease diagnosis tasks and provided visualization of model predictions for model interpretability.",[],[],"['Dipkamal Bhusal', 'Sanjeeb Prasad Panday']","['School of Computing, National University of Singapore', 'School of Computing, National University of Singapore', 'School of Computing, National University of Singapore', 'Duke-NUS Medical School, National University of Singapore']","['Singapore', 'Singapore', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2206.03031,Transparency & Explainability,"Explainable, Normative, and Justified Agency.","Designing and implementing explainable systems is seen as the next step towards increasing user trust in, acceptance of and reliance on Artificial Intelligence (AI) systems. While explaining choices made by black-box algorithms such as machine learning and deep learning has occupied most of the limelight, systems that attempt to explain decisions (even simple ones) in the context of social choice are steadily catching up. In this paper, we provide a comprehensive survey of explainability in mechanism design, a domain characterized by economically motivated agents and often having no single choice that maximizes all individual utility functions. We discuss the main properties and goals of explainability in mechanism design, distinguishing them from those of Explainable AI in general. This discussion is followed by a thorough review of the challenges one may face when working on Explainable Mechanism Design and propose a few solution concepts to those.",[],[],"['Sharadhi Alape Suryanarayana', 'David Sarne', 'Sarit Kraus']","['Institute for the Study of Learning and Expertise, Palo Alto, CA and Department of Computer Science, University of Auckland, Auckland, NZ']",[]
https://arxiv.org/abs/1805.10820,Transparency & Explainability,Meaningful Explanations of Black Box AI Decision Systems.,"The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.",[],[],"['Riccardo Guidotti', 'Anna Monreale', 'Salvatore Ruggieri', 'Dino Pedreschi', 'Franco Turini', 'Fosca Giannotti']","['University of Pisa', 'ISTI-CNR Pisa, Italy', 'ISTI-CNR Pisa, Italy', 'University of Pisa', 'University of Pisa', 'University of Pisa']","['Italy', 'Italy']"
https://arxiv.org/abs/2306.12507,Transparency & Explainability,"Performance Evaluation in Machine Learning: The Good, the Bad, the Ugly, and the Way Forward.","Interpreting machine learning models remains a challenge, hindering their adoption in clinical settings. This paper proposes leveraging Local Interpretable Model-Agnostic Explanations (LIME) to provide interpretable descriptions of black box classification models in high-stakes sepsis detection. By analyzing misclassified instances, significant features contributing to suboptimal performance are identified. The analysis reveals regions where the classifier performs poorly, allowing the calculation of error rates within these regions. This knowledge is crucial for cautious decision-making in sepsis detection and other critical applications. The proposed approach is demonstrated using the eICU dataset, effectively identifying and visualizing regions where the classifier underperforms. By enhancing interpretability, our method promotes the adoption of machine learning models in clinical practice, empowering informed decision-making and mitigating risks in critical scenarios.",[],[],"['Mozhgan Salimiparsa', 'Surajsinh Parmar', 'San Lee', 'Choongmin Kim', 'Yonghwan Kim', 'Jang Yong Kim']",[],[]
https://arxiv.org/abs/2007.00820,Transparency & Explainability,Stochastic Goal Recognition Design.,"Designing robots capable of generating interpretable behavior is a prerequisite for achieving effective human-robot collaboration. This means that the robots need to be capable of generating behavior that aligns with human expectations and, when required, provide explanations to the humans in the loop. However, exhibiting such behavior in arbitrary environments could be quite expensive for robots, and in some cases, the robot may not even be able to exhibit the expected behavior. Given structured environments (like warehouses and restaurants), it may be possible to design the environment so as to boost the interpretability of the robot's behavior or to shape the human's expectations of the robot's behavior. In this paper, we investigate the opportunities and limitations of environment design as a tool to promote a type of interpretable behavior -- known in the literature as explicable behavior. We formulate a novel environment design framework that considers design over multiple tasks and over a time horizon. In addition, we explore the longitudinal aspect of explicable behavior and the trade-off that arises between the cost of design and the cost of generating explicable behavior over a time horizon.",[],[],"['Anagha Kulkarni', 'Sarath Sreedharan', 'Sarah Keren', 'Tathagata Chakraborti', 'David Smith', 'Subbarao Kambhampati']",['Washington University in St. Louis'],[]
https://arxiv.org/abs/1901.08558,Transparency & Explainability,Building Human-Machine Trust via Interpretability.,"Decisions by Machine Learning (ML) models have become ubiquitous. Trusting these decisions requires understanding how algorithms take them. Hence interpretability methods for ML are an active focus of research. A central problem in this context is that both the quality of interpretability methods as well as trust in ML predictions are difficult to measure. Yet evaluations, comparisons and improvements of trust and interpretability require quantifiable measures. Here we propose a quantitative measure for the quality of interpretability methods. Based on that we derive a quantitative measure of trust in ML decisions. Building on previous work we propose to measure intuitive understanding of algorithmic decisions using the information transfer rate at which humans replicate ML model predictions. We provide empirical evidence from crowdsourcing experiments that the proposed metric robustly differentiates interpretability methods. The proposed metric also demonstrates the value of interpretability for ML assisted human decision making: in our experiments providing explanations more than doubled productivity in annotation tasks. However unbiased human judgement is critical for doctors, judges, policy makers and others. Here we derive a trust metric that identifies when human decisions are overly biased towards ML predictions. Our results complement existing qualitative work on trust and interpretability by quantifiable measures that can serve as objectives for further improving methods in this field of research.",[],[],"['Philipp Schmidt', 'Felix Biessmann']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']",[]
https://arxiv.org/abs/1905.07030,Transparency & Explainability,Logic-Based Sequential Decision-Making.,"Deep reinforcement learning (DRL) algorithms have achieved great success on sequential decision-making problems, yet is criticized for the lack of data-efficiency and explainability. Especially, explainability of subtasks is critical in hierarchical decision-making since it enhances the transparency of black-box-style DRL methods and helps the RL practitioners to understand the high-level behavior of the system better. To improve the data-efficiency and explainability of DRL, declarative knowledge is introduced in this work and a novel algorithm is proposed by integrating DRL with symbolic planning. Experimental analysis on publicly available benchmarks validates the explainability of the subtasks and shows that our method can outperform the state-of-the-art approach in terms of data-efficiency.",[],[],['Daoming Lyu'],"['Auburn University, Auburn, AL', 'Maana Inc., Bellevue, WA', 'Auburn University, Auburn, AL', 'ETRI, Daejeon, South Korea']",[]
https://arxiv.org/abs/2301.09937,Transparency & Explainability,Strategic Tasks for Explainable Reinforcement Learning.,"Interpretability, explainability and transparency are key issues to introducing Artificial Intelligence methods in many critical domains: This is important due to ethical concerns and trust issues strongly connected to reliability, robustness, auditability and fairness, and has important consequences towards keeping the human in the loop in high levels of automation, especially in critical cases for decision making, where both (human and the machine) play important roles. While the research community has given much attention to explainability of closed (or black) prediction boxes, there are tremendous needs for explainability of closed-box methods that support agents to act autonomously in the real world. Reinforcement learning methods, and especially their deep versions, are such closed-box methods. In this article we aim to provide a review of state of the art methods for explainable deep reinforcement learning methods, taking also into account the needs of human operators - i.e., of those that take the actual and critical decisions in solving real-world problems. We provide a formal specification of the deep reinforcement learning explainability problems, and we identify the necessary components of a general explainable reinforcement learning framework. Based on these, we provide a comprehensive review of state of the art methods, categorizing them in classes according to the paradigm they follow, the interpretable models they use, and the surface representation of explanations provided. The article concludes identifying open questions and important challenges.",[],[],['George A. Vouros'],[],[]
https://arxiv.org/abs/2112.14466,Transparency & Explainability,Desiderata for Interpretability: Explaining Decision Tree Predictions with Counterfactuals.,"Explainable artificial intelligence and interpretable machine learning are research domains growing in importance. Yet, the underlying concepts remain somewhat elusive and lack generally agreed definitions. While recent inspiration from social sciences has refocused the work on needs and expectations of human recipients, the field still misses a concrete conceptualisation. We take steps towards addressing this challenge by reviewing the philosophical and social foundations of human explainability, which we then translate into the technological realm. In particular, we scrutinise the notion of algorithmic black boxes and the spectrum of understanding determined by explanatory processes and explainees' background knowledge. This approach allows us to define explainability as (logical) reasoning applied to transparent insights (into, possibly black-box, predictive systems) interpreted under background knowledge and placed within a specific context -- a process that engenders understanding in a selected group of explainees. We then employ this conceptualisation to revisit strategies for evaluating explainability as well as the much disputed trade-off between transparency and predictive power, including its implications for ante-hoc and post-hoc techniques along with fairness and accountability established by explainability. We furthermore discuss components of the machine learning workflow that may be in need of interpretability, building on a range of ideas from human-centred explainability, with a particular focus on explainees, contrastive statements and explanatory processes. Our discussion reconciles and complements current research to help better navigate open questions -- rather than attempting to address any individual issue -- thus laying a solid foundation for a grounded discussion and future progress of explainable artificial intelligence and interpretable machine learning.",[],[],"['Kacper Sokol', 'Peter Flach']","['Department of Computer Science, University of Bristol, Bristol, UK', 'Department of Computer Science, University of Bristol, Bristol, UK']","['UK', 'UK']"
https://arxiv.org/abs/2307.13582,Transparency & Explainability,Computing Argumentative Explanations in Bipolar Argumentation Frameworks.,"Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of extension-based semantics, explaining the quantitative reasoning outcomes of AFs under gradual semantics has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of Argument Attribution Explanations (AAEs) by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards topic arguments of interest. We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting. To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.",[],[],"['Xiang Yin', 'Nico Potyka', 'Francesca Toni']","['LILY Research Center, Nanyang Technological University, Singapore and IGS, Nanyang Technological University, Singapore and Alibaba-NTU Singapore JRI, Nanyang Technological University, Singapore', 'LILY Research Center, Nanyang Technological University, Singapore and Alibaba-NTU Singapore JRI, Nanyang Technological University, Singapore and SCSE, Nanyang Technological University, Singapore', 'LILY Research Center, Nanyang Technological University, Singapore and ECE, University of British Columbia, Vancouver, Canada', 'LILY Research Center, Nanyang Technological University, Singapore and SCSE, Nanyang Technological University, Singapore', 'LKC School of Medicine, Nanyang Technological University, Singapore']","['Singapore', 'Singapore', 'Canada', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2201.04952,Fairness & Bias,Discrete Social Recommendation.,"The recommendation system, relying on historical observational data to model the complex relationships among the users and items, has achieved great success in real-world applications. Selection bias is one of the most important issues of the existing observational data based approaches, which is actually caused by multiple types of unobserved exposure strategies (e.g. promotions and holiday effects). Though various methods have been proposed to address this problem, they are mainly relying on the implicit debiasing techniques but not explicitly modeling the unobserved exposure strategies. By explicitly Reconstructing Exposure STrategies (REST in short), we formalize the recommendation problem as the counterfactual reasoning and propose the debiased social recommendation method. In REST, we assume that the exposure of an item is controlled by the latent exposure strategies, the user, and the item. Based on the above generation process, we first provide the theoretical guarantee of our method via identification analysis. Second, we employ a variational auto-encoder to reconstruct the latent exposure strategies, with the help of the social networks and the items. Third, we devise a counterfactual reasoning based recommendation algorithm by leveraging the recovered exposure strategies. Experiments on four real-world datasets, including three published datasets and one private WeChat Official Account dataset, demonstrate significant improvements over several state-of-the-art methods.",[],[],"['Ruichu Cai', 'Fengzhu Wu', 'Zijian Li', 'Jie Qiao', 'Wei Chen', 'Yuexing Hao', 'Hao Gu']","['School of Information Systems, Singapore Management University, Singapore and School of Computer Science and Technology, Zhejiang University, China', 'Department of Computer Science and Technology, Tsinghua University, China', 'School of Computer Science and Technology, Zhejiang University, China and Alibaba-Zhejiang University Joint Institute of Frontier Technologies, China', 'Department of Computer Science and Technology, Tsinghua University, China and Alibaba-Zhejiang University Joint Institute of Frontier Technologies, China', 'School of Computer Science and Technology, Zhejiang University, China', 'School of Information Systems, Singapore Management University, Singapore']","['China', 'China', 'China', 'China', 'China', 'Singapore']"
https://arxiv.org/abs/1811.00458,Fairness & Bias,Bias Reduction via End-to-End Shift Learning: Application to Citizen Science.,"Citizen science projects are successful at gathering rich datasets for various applications. However, the data collected by citizen scientists are often biased --- in particular, aligned more with the citizens' preferences than with scientific objectives. We propose the Shift Compensation Network (SCN), an end-to-end learning scheme which learns the shift from the scientific objectives to the biased data while compensating for the shift by re-weighting the training data. Applied to bird observational data from the citizen science project eBird, we demonstrate how SCN quantifies the data distribution shift and outperforms supervised learning models that do not address the data bias. Compared with competing models in the context of covariate shift, we further demonstrate the advantage of SCN in both its effectiveness and its capability of handling massive high-dimensional data.",[],[],"['Di Chen', 'Carla P. Gomes']","['Cornell University', 'Cornell University']",[]
https://arxiv.org/abs/2204.11910,Fairness & Bias,Selecting Compliant Agents for Opt-in Micro-Tolling.,"We introduce a new setting, optimize-and-estimate structured bandits. Here, a policy must select a batch of arms, each characterized by its own context, that would allow it to both maximize reward and maintain an accurate (ideally unbiased) population estimate of the reward. This setting is inherent to many public and private sector applications and often requires handling delayed feedback, small data, and distribution shifts. We demonstrate its importance on real data from the United States Internal Revenue Service (IRS). The IRS performs yearly audits of the tax base. Two of its most important objectives are to identify suspected misreporting and to estimate the ""tax gap"" -- the global difference between the amount paid and true amount owed. Based on a unique collaboration with the IRS, we cast these two processes as a unified optimize-and-estimate structured bandit. We analyze optimize-and-estimate approaches to the IRS problem and propose a novel mechanism for unbiased population estimation that achieves rewards comparable to baseline approaches. This approach has the potential to improve audit efficacy, while maintaining policy-relevant estimates of the tax gap. This has important social consequences given that the current tax gap is estimated at nearly half a trillion dollars. We suggest that this problem setting is fertile ground for further research and we highlight its interesting challenges. The results of this and related research are currently being incorporated into the continual improvement of the IRS audit selection methods.",[],[],"['Peter Henderson', 'Ben Chugg', 'Brandon Anderson', 'Kristen Altenburger', 'Alex Turk', 'John Guyton', 'Jacob Goldin', 'Daniel E. Ho']","['The University of Texas at Austin', 'Texas A & M University', 'The University of Texas at Austin', 'The University of Texas at Austin']",[]
https://arxiv.org/abs/1908.05429,Fairness & Bias,Adversarial Learning for Weakly-Supervised Social Network Alignment.,"Network alignment is a critical task to a wide variety of fields. Many existing works leverage on representation learning to accomplish this task without eliminating domain representation bias induced by domain-dependent features, which yield inferior alignment performance. This paper proposes a unified deep architecture (DANA) to obtain a domain-invariant representation for network alignment via an adversarial domain classifier. Specifically, we employ the graph convolutional networks to perform network embedding under the domain adversarial principle, given a small set of observed anchors. Then, the semi-supervised learning framework is optimized by maximizing a posterior probability distribution of observed anchors and the loss of a domain classifier simultaneously. We also develop a few variants of our model, such as, direction-aware network alignment, weight-sharing for directed networks and simplification of parameter space. Experiments on three real-world social network datasets demonstrate that our proposed approaches achieve state-of-the-art alignment results.",[],[],"['Huiting Hong', 'Xin Li', 'Yuangang Pan', 'Ivor Tsang']","['State Key Lab of Software Development Environment, Beihang University', 'College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics', 'Department of Electrical Computer Engineering, National University of Singapore', 'Tsinghua University and Computer Science Department, University of Illinois at Chicago', 'Hortonworks', 'State Key Lab of Software Development Environment, Beihang University', 'State Key Lab of Software Development Environment, Beihang University']",['Singapore']
https://arxiv.org/abs/1903.10598,Fairness & Bias,Learning Optimal and Fair Decision Trees for Non-Discriminative Decision-Making.,"In recent years, automated data-driven decision-making systems have enjoyed a tremendous success in a variety of fields (e.g., to make product recommendations, or to guide the production of entertainment). More recently, these algorithms are increasingly being used to assist socially sensitive decision-making (e.g., to decide who to admit into a degree program or to prioritize individuals for public housing). Yet, these automated tools may result in discriminative decision-making in the sense that they may treat individuals unfairly or unequally based on membership to a category or a minority, resulting in disparate treatment or disparate impact and violating both moral and ethical standards. This may happen when the training dataset is itself biased (e.g., if individuals belonging to a particular group have historically been discriminated upon). However, it may also happen when the training dataset is unbiased, if the errors made by the system affect individuals belonging to a category or minority differently (e.g., if misclassification rates for Blacks are higher than for Whites). In this paper, we unify the definitions of unfairness across classification and regression. We propose a versatile mixed-integer optimization framework for learning optimal and fair decision trees and variants thereof to prevent disparate treatment and/or disparate impact as appropriate. This translates to a flexible schema for designing fair and interpretable policies suitable for socially sensitive decision-making. We conduct extensive computational studies that show that our framework improves the state-of-the-art in the field (which typically relies on heuristics) to yield non-discriminative decisions at lower cost to overall accuracy.",[],[],"['Sina Aghaei', 'Mohammad Javad Azizi', 'Phebe Vayanos']","['CAIS Center for Artificial Intelligence in Society, University of Southern California, Los Angeles, CA', 'CAIS Center for Artificial Intelligence in Society, University of Southern California, Los Angeles, CA', 'CAIS Center for Artificial Intelligence in Society, University of Southern California, Los Angeles, CA']",[]
https://arxiv.org/abs/1902.06158,Fairness & Bias,Faster Gradient-Free Proximal Stochastic Methods for Nonconvex Nonsmooth Optimization.,"Proximal gradient method has been playing an important role to solve many machine learning tasks, especially for the nonsmooth problems. However, in some machine learning problems such as the bandit model and the black-box learning problem, proximal gradient method could fail because the explicit gradients of these problems are difficult or infeasible to obtain. The gradient-free (zeroth-order) method can address these problems because only the objective function values are required in the optimization. Recently, the first zeroth-order proximal stochastic algorithm was proposed to solve the nonconvex nonsmooth problems. However, its convergence rate is $O(\frac{1}{\sqrt{T}})$ for the nonconvex problems, which is significantly slower than the best convergence rate $O(\frac{1}{T})$ of the zeroth-order stochastic algorithm, where $T$ is the iteration number. To fill this gap, in the paper, we propose a class of faster zeroth-order proximal stochastic methods with the variance reduction techniques of SVRG and SAGA, which are denoted as ZO-ProxSVRG and ZO-ProxSAGA, respectively. In theoretical analysis, we address the main challenge that an unbiased estimate of the true gradient does not hold in the zeroth-order case, which was required in previous theoretical analysis of both SVRG and SAGA. Moreover, we prove that both ZO-ProxSVRG and ZO-ProxSAGA algorithms have $O(\frac{1}{T})$ convergence rates. Finally, the experimental results verify that our algorithms have a faster convergence rate than the existing zeroth-order proximal stochastic algorithm.",[],[],"['Feihu Huang', 'Bin Gu', 'Zhouyuan Huo', 'Songcan Chen', 'Heng Huang']","['College of Computer Science & Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China and Department of Electrical & Computer Engineering, University of Pittsburgh, PA', 'JDDGlobal.com', 'Department of Electrical & Computer Engineering, University of Pittsburgh, PA', 'College of Computer Science & Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China', 'Department of Electrical & Computer Engineering, University of Pittsburgh, PA and JDDGlobal.com']","['China', 'China']"
https://arxiv.org/abs/1811.03761,Fairness & Bias,RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets.,"In this paper, we propose a class of robust stochastic subgradient methods for distributed learning from heterogeneous datasets at presence of an unknown number of Byzantine workers. The Byzantine workers, during the learning process, may send arbitrary incorrect messages to the master due to data corruptions, communication failures or malicious attacks, and consequently bias the learned model. The key to the proposed methods is a regularization term incorporated with the objective function so as to robustify the learning task and mitigate the negative effects of Byzantine attacks. The resultant subgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation methods, justifying our acronym RSA used henceforth. In contrast to most of the existing algorithms, RSA does not rely on the assumption that the data are independent and identically distributed (i.i.d.) on the workers, and hence fits for a wider class of applications. Theoretically, we show that: i) RSA converges to a near-optimal solution with the learning error dependent on the number of Byzantine workers; ii) the convergence rate of RSA under Byzantine attacks is the same as that of the stochastic gradient descent method, which is free of Byzantine attacks. Numerically, experiments on real dataset corroborate the competitive performance of RSA and a complexity reduction compared to the state-of-the-art alternatives.",[],[],"['Liping Li', 'Wei Xu', 'Tianyi Chen', 'Georgios B. Giannakis', 'Qing Ling']","['Department of Automation, University of Science and Technology of China, Hefei, Anhui, China', 'Department of Automation, University of Science and Technology of China, Hefei, Anhui, China', 'Digital Technology Center, University of Minnesota, Twin Cities, Minneapolis, Minnesota', 'Digital Technology Center, University of Minnesota, Twin Cities, Minneapolis, Minnesota', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China']","['China', 'China', 'China']"
https://arxiv.org/abs/2302.06958,Fairness & Bias,Group Fairness for the Allocation of Indivisible Goods.,"Fair allocation of indivisible goods is a well-explored problem. Traditionally, research focused on individual fairness - are individual agents satisfied with their allotted share? - and group fairness - are groups of agents treated fairly? In this paper, we explore the coexistence of individual envy-freeness (i-EF) and its group counterpart, group weighted envy-freeness (g-WEF), in the allocation of indivisible goods. We propose several polynomial-time algorithms that provably achieve i-EF and g-WEF simultaneously in various degrees of approximation under three different conditions on the agents' (i) when agents have identical additive valuation functions, i-EFX and i-WEF1 can be achieved simultaneously; (ii) when agents within a group share a common valuation function, an allocation satisfying both i-EF1 and g-WEF1 exists; and (iii) when agents' valuations for goods within a group differ, we show that while maintaining i-EF1, we can achieve a 1/3-approximation to ex-ante g-WEF1. Our results thus provide a first step towards connecting individual and group fairness in the allocation of indivisible goods, in hopes of its useful application to domains requiring the reconciliation of diversity with individual demands.",[],[],"['Jonathan Scarlett', 'Nicholas Teh', 'Yair Zick']","['Duke University', 'Microsoft Research', 'University of Toronto', 'Microsoft Research']",[]
https://arxiv.org/abs/2302.03810,Fairness & Bias,An Equivalence between Wagering and Fair-Division Mechanisms.,"The prevalence and importance of algorithmic two-sided marketplaces has drawn attention to the issue of fairness in such settings. Algorithmic decisions are used in assigning students to schools, users to advertisers, and applicants to job interviews. These decisions should heed the preferences of individuals, and simultaneously be fair with respect to their merits (synonymous with fit, future performance, or need). Merits conditioned on observable features are always \emph{uncertain}, a fact that is exacerbated by the widespread use of machine learning algorithms to infer merit from the observables. As our key contribution, we carefully axiomatize a notion of individual fairness in the two-sided marketplace setting which respects the uncertainty in the merits; indeed, it simultaneously recognizes uncertainty as the primary potential cause of unfairness and an approach to address it. We design a linear programming framework to find fair utility-maximizing distributions over allocations, and we show that the linear program is robust to perturbations in the estimated parameters of the uncertain merit distributions, a key property in combining the approach with machine learning techniques.",[],[],"['Siddartha Devic', 'David Kempe', 'Vatsal Sharan', 'Aleksandra Korolova']","['Microsoft Research', 'Microsoft Research', 'Microsoft Research']",[]
https://arxiv.org/abs/2308.07414,Fairness & Bias,"""Reverse Gerrymandering"": Manipulation in Multi-Group Decision Making.","Gerrymandering, the deliberate manipulation of electoral district boundaries for political advantage, is a persistent issue in U.S. redistricting cycles. This paper introduces and analyzes a new phenomenon, 'votemandering'- a strategic blend of gerrymandering and targeted political campaigning, devised to gain more seats by circumventing fairness measures. It leverages accurate demographic and socio-political data to influence voter decisions, bolstered by advancements in technology and data analytics, and executes better-informed redistricting. Votemandering is established as a Mixed Integer Program (MIP) that performs fairness-constrained gerrymandering over multiple election rounds, via unit-specific variables for campaigns. To combat votemandering, we present a computationally efficient heuristic for creating and testing district maps that more robustly preserve voter preferences. We analyze the influence of various redistricting constraints and parameters on votemandering efficacy. We explore the interconnectedness of gerrymandering, substantial campaign budgets, and strategic campaigning, illustrating their collective potential to generate biased electoral maps. A Wisconsin State Senate redistricting case study substantiates our findings on real data, demonstrating how major parties can secure additional seats through votemandering. Our findings underscore the practical implications of these manipulations, stressing the need for informed policy and regulation to safeguard democratic processes.",[],[],"['Sanyukta Deshpande', 'Ian G Ludden', 'Sheldon H Jacobson']","['Ben-Gurion University of the Negev, Beersheba, Israel', 'The Hebrew University, of Jerusalem, Israel']","['Israel', 'Israel']"
https://arxiv.org/abs/1809.03057,Fairness & Bias,Variance Reduction in Monte Carlo Counterfactual Regret Minimization (VR-MCCFR) for Extensive Form Games Using Baselines.,"Learning strategies for imperfect information games from samples of interaction is a challenging problem. A common method for this setting, Monte Carlo Counterfactual Regret Minimization (MCCFR), can have slow long-term convergence rates due to high variance. In this paper, we introduce a variance reduction technique (VR-MCCFR) that applies to any sampling variant of MCCFR. Using this technique, per-iteration estimated values and updates are reformulated as a function of sampled values and state-action baselines, similar to their use in policy gradient reinforcement learning. The new formulation allows estimates to be bootstrapped from other estimates within the same episode, propagating the benefits of baselines along the sampled trajectory; the estimates remain unbiased even when bootstrapping from other estimates. Finally, we show that given a perfect baseline, the variance of the value estimates can be reduced to zero. Experimental evaluation shows that VR-MCCFR brings an order of magnitude speedup, while the empirical variance decreases by three orders of magnitude. The decreased variance allows for the first time CFR+ to be used with sampling, increasing the speedup to two orders of magnitude.",[],[],"['Martin Schmid', 'Neil Burch', 'Marc Lanctot', 'Matej Moravcik', 'Rudolf Kadlec', 'Michael Bowling']","['DeepMind', 'DeepMind', 'DeepMind', 'DeepMind', 'DeepMind', 'DeepMind and University of Alberta']",[]
https://arxiv.org/abs/0903.2908,Fairness & Bias,Evolving Solutions to Community-Structured Satisfiability Formulas.,"  The solution space of a K-satisfiability (K-SAT) formula is a collection of solution clusters, each of which contains all the solutions that are mutually reachable through a sequence of single-spin flips. Knowledge of the statistical property of solution clusters is valuable for a complete understanding of the solution space structure and the computational complexity of the random K-SAT problem. This paper explores single solution clusters of random 3- and 4-SAT formulas through unbiased and biased random walk processes and the replica-symmetric cavity method of statistical physics. We find that the giant connected component of the solution space has already formed many different communities when the constraint density of the formula is still lower than the solution space clustering transition point. Solutions of the same community are more similar with each other and more densely connected with each other than with the other solutions. The entropy density of a solution community is calculated using belief propagation and is found to be different for different communities of the same cluster. When the constraint density is beyond the clustering transition point, the same behavior is observed for the solution clusters reached by several stochastic search algorithms. Taking together, the results of this work suggests a refined picture on the evolution of the solution space structure of the random K-SAT problem; they may also be helpful for designing new heuristic algorithms.",[],[],"['Haijun Zhou', 'Hui Ma']","['Optimisation and Logistics, School of Computer Science, The University of Adelaide, Adelaide, Australia', 'Department of Computer Science, University of Minnesota Duluth, Duluth, MN']",['Australia']
https://arxiv.org/abs/1909.03013,Fairness & Bias,One-Network Adversarial Fairness.,"Fairness is becoming a rising concern w.r.t. machine learning model performance. Especially for sensitive fields such as criminal justice and loan decision, eliminating the prediction discrimination towards a certain group of population (characterized by sensitive features like race and gender) is important for enhancing the trustworthiness of model. In this paper, we present a new general framework to improve machine learning fairness. The goal of our model is to minimize the influence of sensitive feature from the perspectives of both the data input and the predictive model. In order to achieve this goal, we reformulate the data input by removing the sensitive information and strengthen model fairness by minimizing the marginal contribution of the sensitive feature. We propose to learn the non-sensitive input via sampling among features and design an adversarial network to minimize the dependence between the reformulated input and the sensitive information. Extensive experiments on three benchmark datasets suggest that our model achieve better results than related state-of-the-art methods with respect to both fairness metrics and prediction performance.",[],[],"['Xiaoqian Wang', 'Heng Huang']","['University of Cambridge, UK', 'MPI-IS, Germany', 'University of Cambridge, UK, Uber AI Labs', 'University of Cambridge, UK and The Alan Turing Institute, UK']","['UK', 'Germany', 'UK', 'UK']"
https://arxiv.org/abs/1901.00433,Fairness & Bias,Identification of Causal Effects in the Presence of Selection Bias.,"We prove the main rules of causal calculus (also called do-calculus) for i/o structural causal models (ioSCMs), a generalization of a recently proposed general class of non-/linear structural causal models that allow for cycles, latent confounders and arbitrary probability distributions. We also generalize adjustment criteria and formulas from the acyclic setting to the general one (i.e. ioSCMs). Such criteria then allow to estimate (conditional) causal effects from observational data that was (partially) gathered under selection bias and cycles. This generalizes the backdoor criterion, the selection-backdoor criterion and extensions of these to arbitrary ioSCMs. Together, our results thus enable causal reasoning in the presence of cycles, latent confounders and selection bias. Finally, we extend the ID algorithm for the identification of causal effects to ioSCMs.",[],[],"['Patrick Forré', 'Joris M. Mooij']","['Computer Science Department, Purdue University', 'Department of Computer Science, Iowa State University', 'Computer Science Department, Purdue University']",[]
https://arxiv.org/abs/1911.03903,Fairness & Bias,TransGate: Knowledge Graph Embedding with Shared Gate Structure.,"Knowledge Graph Completion (KGC) aims at automatically predicting missing links for large-scale knowledge graphs. A vast number of state-of-the-art KGC techniques have got published at top conferences in several research fields, including data mining, machine learning, and natural language processing. However, we notice that several recent papers report very high performance, which largely outperforms previous state-of-the-art methods. In this paper, we find that this can be attributed to the inappropriate evaluation protocol used by them and propose a simple evaluation protocol to address this problem. The proposed protocol is robust to handle bias in the model, which can substantially affect the final results. We conduct extensive experiments and report the performance of several existing methods using our protocol. The reproducible code has been made publicly available",[],[],"['Zhiqing Sun', 'Shikhar Vashishth', 'Soumya Sanyal', 'Partha Talukdar', 'Yiming Yang']","['Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China and State Key Laboratory of Information Security, Chinese Academy of Sciences, Beijing, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China and State Key Laboratory of Information Security, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China and State Key Laboratory of Information Security, Chinese Academy of Sciences, Beijing, China']","['China', 'China', 'China']"
https://arxiv.org/abs/1805.08877,Fairness & Bias,Adversarial Label Learning.,We consider the task of training classifiers without labels. We propose a weakly supervised method---adversarial label learning---that trains classifiers to perform well against an adversary that chooses labels for training data. The weak supervision constrains what labels the adversary can choose. The method therefore minimizes an upper bound of the classifier's error rate using projected primal-dual subgradient descent. Minimizing this bound protects against bias and dependencies in the weak supervision. Experiments on three real datasets show that our method can train without labels and outperforms other approaches for weakly supervised learning.,[],[],"['Chidubem Arachie', 'Bert Huang']","['Department of Computer Science, Virginia Tech', 'Department of Computer Science, Virginia Tech']",[]
https://arxiv.org/abs/1812.06227,Fairness & Bias,Balanced Linear Contextual Bandits.,"Contextual bandit algorithms are sensitive to the estimation method of the outcome model as well as the exploration method used, particularly in the presence of rich heterogeneity or complex outcome models, which can lead to difficult estimation problems along the path of learning. We develop algorithms for contextual bandits with linear payoffs that integrate balancing methods from the causal inference literature in their estimation to make it less prone to problems of estimation bias. We provide the first regret bound analyses for linear contextual bandits with balancing and show that our algorithms match the state of the art theoretical guarantees. We demonstrate the strong practical advantage of balanced contextual bandits on a large number of supervised learning datasets and on a synthetic example that simulates model misspecification and prejudice in the initial training data.",[],[],"['Maria Dimakopoulou', 'Zhengyuan Zhou', 'Susan Athey', 'Guido Imbens']","['Department of Management Science & Engineering, Stanford University', 'Department of Electrical Engineering, Stanford University', 'Graduate School of Business, Stanford University', 'Graduate School of Business, Stanford University']",[]
https://arxiv.org/abs/1811.04973,Fairness & Bias,Eliminating Latent Discrimination: Train Then Mask.,"How can we control for latent discrimination in predictive models? How can we provably remove it? Such questions are at the heart of algorithmic fairness and its impacts on society. In this paper, we define a new operational fairness criteria, inspired by the well-understood notion of omitted variable-bias in statistics and econometrics. Our notion of fairness effectively controls for sensitive features and provides diagnostics for deviations from fair decision making. We then establish analytical and algorithmic results about the existence of a fair classifier in the context of supervised learning. Our results readily imply a simple, but rather counter-intuitive, strategy for eliminating latent discrimination. In order to prevent other features proxying for sensitive features, we need to include sensitive features in the training phase, but exclude them in the test/evaluation phase while controlling for their effects. We evaluate the performance of our algorithm on several real-world datasets and show how fairness for these datasets can be improved with a very small loss in accuracy.",[],[],"['Soheil Ghili', 'Ehsan Kazemi', 'Amin Karbasi']","['School of Management, Yale University', 'Yale Institute for Network Science, Yale University', 'Yale Institute for Network Science, Yale University']",[]
https://arxiv.org/abs/2002.04337,Fairness & Bias,Gaussian-Induced Convolution for Graphs.,"Link prediction aims to reveal missing edges in a graph. We address this task with a Gaussian process that is transformed using simplified graph convolutions to better leverage the inductive bias of the domain. To scale the Gaussian process model to large graphs, we introduce a variational inducing point method that places pseudo inputs on a graph-structured domain. We evaluate our model on eight large graphs with up to thousands of nodes and report consistent improvements over existing Gaussian process models as well as competitive performance when compared to state-of-the-art graph neural network approaches.",[],[],"['Felix L. Opolka', 'Pietro Liò']","['PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China', 'PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China', 'PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China', 'PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/1902.02530,Fairness & Bias,DoPAMINE: Double-Sided Masked CNN for Pixel Adaptive Multiplicative Noise Despeckling.,"We propose DoPAMINE, a new neural network based multiplicative noise despeckling algorithm. Our algorithm is inspired by Neural AIDE (N-AIDE), which is a recently proposed neural adaptive image denoiser. While the original N-AIDE was designed for the additive noise case, we show that the same framework, i.e., adaptively learning a network for pixel-wise affine denoisers by minimizing an unbiased estimate of MSE, can be applied to the multiplicative noise case as well. Moreover, we derive a double-sided masked CNN architecture which can control the variance of the activation values in each layer and converge fast to high denoising performance during supervised training. In the experimental results, we show our DoPAMINE possesses high adaptivity via fine-tuning the network parameters based on the given noisy image and achieves significantly better despeckling results compared to SAR-DRN, a state-of-the-art CNN-based algorithm.",[],[],"['Sunghwan Joo', 'Sungmin Cha', 'Taesup Moon']","['Department of Electrical and Computer Engineering, Sungkyunkwan University', 'Department of Electrical and Computer Engineering, Sungkyunkwan University', 'Department of Electrical and Computer Engineering, Sungkyunkwan University']",[]
https://arxiv.org/abs/1906.12063,Fairness & Bias,Bias-Variance Trade-Off in Hierarchical Probabilistic Models Using Higher-Order Feature Interactions.,"Hierarchical probabilistic models are able to use a large number of parameters to create a model with a high representation power. However, it is well known that increasing the number of parameters also increases the complexity of the model which leads to a bias-variance trade-off. Although it is a classical problem, the bias-variance trade-off between hidden layers and higher-order interactions have not been well studied. In our study, we propose an efficient inference algorithm for the log-linear formulation of the higher-order Boltzmann machine using a combination of Gibbs sampling and annealed importance sampling. We then perform a bias-variance decomposition to study the differences in hidden layers and higher-order interactions. Our results have shown that using hidden layers and higher-order interactions have a comparable error with a similar order of magnitude and using higher-order interactions produce less variance for smaller sample size.",[],[],"['Simon Luo', 'Mahito Sugiyama']",[],[]
https://arxiv.org/abs/1811.07350,Fairness & Bias,Policy Optimization with Model-Based Explorations.,"Model-free reinforcement learning methods such as the Proximal Policy Optimization algorithm (PPO) have successfully applied in complex decision-making problems such as Atari games. However, these methods suffer from high variances and high sample complexity. On the other hand, model-based reinforcement learning methods that learn the transition dynamics are more sample efficient, but they often suffer from the bias of the transition estimation. How to make use of both model-based and model-free learning is a central problem in reinforcement learning. In this paper, we present a new technique to address the trade-off between exploration and exploitation, which regards the difference between model-free and model-based estimations as a measure of exploration value. We apply this new technique to the PPO algorithm and arrive at a new policy optimization method, named Policy Optimization with Model-based Explorations (POME). POME uses two components to predict the actions' target values: a model-free one estimated by Monte-Carlo sampling and a model-based one which learns a transition model and predicts the value of the next state. POME adds the error of these two target estimations as the additional exploration value for each state-action pair, i.e, encourages the algorithm to explore the states with larger target errors which are hard to estimate. We compare POME with PPO on Atari 2600 games, and it shows that POME outperforms PPO on 33 games out of 49 games.",[],[],"['Feiyang Pan', 'Qingpeng Cai', 'An-Xiang Zeng', 'Chun-Xiang Pan', 'Qing Da', 'Hualin He', 'Qing He', 'Pingzhong Tang']","['Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China and University of Chinese Academy of Sciences, Beijing, China', 'IIIS, Tsinghua University', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing, China and University of Chinese Academy of Sciences, Beijing, China', 'IIIS, Tsinghua University']","['China', 'China']"
https://arxiv.org/abs/2010.08830,Fairness & Bias,Trainable Undersampling for Class-Imbalance Learning.,"Imbalanced learning (IL), i.e., learning unbiased models from class-imbalanced data, is a challenging problem. Typical IL methods including resampling and reweighting were designed based on some heuristic assumptions. They often suffer from unstable performance, poor applicability, and high computational cost in complex tasks where their assumptions do not hold. In this paper, we introduce a novel ensemble IL framework named MESA. It adaptively resamples the training set in iterations to get multiple classifiers and forms a cascade ensemble model. MESA directly learns the sampling strategy from data to optimize the final metric beyond following random heuristics. Moreover, unlike prevailing meta-learning-based IL solutions, we decouple the model-training and meta-training in MESA by independently train the meta-sampler over task-agnostic meta-data. This makes MESA generally applicable to most of the existing learning models and the meta-sampler can be efficiently applied to new tasks. Extensive experiments on both synthetic and real-world tasks demonstrate the effectiveness, robustness, and transferability of MESA. Our code is available at this https URL.",[],[],"['Zhining Liu', 'Pengfei Wei', 'Jing Jiang', 'Wei Cao', 'Jiang Bian', 'Yi Chang']","['School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China', 'School of Computer Science, Shanghai Key Laboratory of Intelligent Information Processing, Fudan University, Shanghai Insitute of Intelligent Electroics & Systems, Shanghai, China']","['China', 'China', 'China', 'China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/1809.02403,Fairness & Bias,Deep Recurrent Survival Analysis.,"Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at fine-grained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three real-world tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.",[],[],"['Kan Ren', 'Jiarui Qin', 'Lei Zheng', 'Zhengyu Yang', 'Weinan Zhang', 'Lin Qiu', 'Yong Yu']","['APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University', 'APEX Data & Knowledge Management Lab, Shanghai Jiao Tong University']",[]
https://arxiv.org/abs/2002.10261,Fairness & Bias,Covariate Shift Adaptation on Learning from Positive and Unlabeled Data.,"Positive-unlabeled (PU) learning trains a binary classifier using only positive and unlabeled data. A common simplifying assumption is that the positive data is representative of the target positive class. This assumption rarely holds in practice due to temporal drift, domain shift, and/or adversarial manipulation. This paper shows that PU learning is possible even with arbitrarily non-representative positive data given unlabeled data from the source and target distributions. Our key insight is that only the negative class's distribution need be fixed. We integrate this into two statistically consistent methods to address arbitrary positive bias - one approach combines negative-unlabeled learning with unlabeled-unlabeled learning while the other uses a novel, recursive risk estimator. Experimental results demonstrate our methods' effectiveness across numerous real-world datasets and forms of positive bias, including disjoint positive class-conditional supports. Additionally, we propose a general, simplified approach to address PU risk estimation overfitting.",[],[],"['Zayd Hammoudeh', 'Daniel Lowd']","['NEC Corporation', 'Yahoo Japan Corporation']",['Japan']
https://arxiv.org/abs/2104.13323,Fairness & Bias,Network Structure and Transfer Behaviors Embedding via Deep Prediction Model.,"Network-structured data becomes ubiquitous in daily life and is growing at a rapid pace. It presents great challenges to feature engineering due to the high non-linearity and sparsity of the data. The local and global structure of the real-world networks can be reflected by dynamical transfer behaviors among nodes. This paper proposes a network embedding framework to capture the transfer behaviors on structured networks via deep prediction models. We first design a degree-weight biased random walk model to capture the transfer behaviors on the network. Then a deep network embedding method is introduced to preserve the transfer possibilities among the nodes. A network structure embedding layer is added into conventional deep prediction models, including Long Short-Term Memory Network and Recurrent Neural Network, to utilize the sequence prediction ability. To keep the local network neighborhood, we further perform a Laplacian supervised space optimization on the embedding feature representations. Experimental studies are conducted on various datasets including social networks, citation networks, biomedical network, collaboration network and language network. The results show that the learned representations can be effectively used as features in a variety of tasks, such as clustering, visualization, classification, reconstruction and link prediction, and achieve promising performance compared with state-of-the-arts.",[],[],"['Xin Sun', 'Zenghui Song', 'Yongbo Yu', 'Junyu Dong', 'Claudia Plant', 'Christian Boehm']","['Department of Computer Science and Technology, Ocean University of China, Qingdao, China', 'Department of Computer Science and Technology, Ocean University of China, Qingdao, China', 'Department of Computer Science and Technology, Ocean University of China, Qingdao, China', 'Department of Computer Science and Technology, Ocean University of China, Qingdao, China', 'Faculty of Computer Science, University of Vienna, Vienna, Austria and Data Science @ University of Vienna, Vienna, Austria', 'Ludwig-Maximilians-Universität München, Munich, Germany']","['China', 'China', 'China', 'China', 'Austria', 'Germany']"
https://arxiv.org/abs/2204.05903,Fairness & Bias,Theoretical Analysis of Label Distribution Learning.,"Person re-identification (Re-ID) is a critical technique in the video surveillance system, which has achieved significant success in the supervised setting. However, it is difficult to directly apply the supervised model to arbitrary unseen domains due to the domain gap between the available source domains and unseen target domains. In this paper, we propose a novel label distribution learning (LDL) method to address the generalizable multi-source person Re-ID task (i.e., there are multiple available source domains, and the testing domain is unseen during training), which aims to explore the relation of different classes and mitigate the domain-shift across different domains so as to improve the discrimination of the model and learn the domain-invariant feature, simultaneously. Specifically, during the training process, we produce the label distribution via the online manner to mine the relation information of different classes, thus it is beneficial for extracting the discriminative feature. Besides, for the label distribution of each class, we further revise it to give more and equal attention to the other domains that the class does not belong to, which can effectively reduce the domain gap across different domains and obtain the domain-invariant feature. Furthermore, we also give the theoretical analysis to demonstrate that the proposed method can effectively deal with the domain-shift issue. Extensive experiments on multiple benchmark datasets validate the effectiveness of the proposed method and show that the proposed method can outperform the state-of-the-art methods. Besides, further analysis also reveals the superiority of the proposed method.",[],[],"['Lei Qi', 'Jiaying Shen', 'Jiaqi Liu', 'Yinghuan Shi', 'Xin Geng']","['MOE Key Laboratory of Computer Network and Information Integration, School of Computer Science and Engineering, Southeast University, Nanjing, China', 'MOE Key Laboratory of Computer Network and Information Integration, School of Computer Science and Engineering, Southeast University, Nanjing, China']","['China', 'China']"
https://arxiv.org/abs/2305.11349,Fairness & Bias,Unsupervised Fake News Detection on Social Media: A Generative Approach.,"The emergence of social media as one of the main platforms for people to access news has enabled the wide dissemination of fake news. This has motivated numerous studies on automating fake news detection. Although there have been limited attempts at unsupervised fake news detection, their performance suffers due to not exploiting the knowledge from various modalities related to news records and due to the presence of various latent biases in the existing news datasets. To address these limitations, this work proposes an effective framework for unsupervised fake news detection, which first embeds the knowledge available in four modalities in news records and then proposes a novel noise-robust self-supervised learning technique to identify the veracity of news records from the multi-modal embeddings. Also, we propose a novel technique to construct news datasets minimizing the latent biases in existing news datasets. Following the proposed approach for dataset construction, we produce a Large-scale Unlabelled News Dataset consisting 419,351 news articles related to COVID-19, acronymed as LUND-COVID. We trained the proposed unsupervised framework using LUND-COVID to exploit the potential of large datasets, and evaluate it using a set of existing labelled datasets. Our results show that the proposed unsupervised framework largely outperforms existing unsupervised baselines for different tasks such as multi-modal fake news detection, fake news early detection and few-shot fake news detection, while yielding notable improvements for unseen domains during training.",[],[],"['Amila Silva', 'Ling Luo', 'Shanika Karunasekera', 'Christopher Leckie']",[],[]
https://arxiv.org/abs/2102.13597,Fairness & Bias,Evolution of Collective Fairness in Hybrid Populations of Humans and Agents.,"From social contracts to climate agreements, individuals engage in groups that must collectively reach decisions with varying levels of equality and fairness. These dilemmas also pervade Distributed Artificial Intelligence, in domains such as automated negotiation, conflict resolution or resource allocation. As evidenced by the well-known Ultimatum Game -- where a Proposer has to divide a resource with a Responder -- payoff-maximizing outcomes are frequently at odds with fairness. Eliciting equality in populations of self-regarding agents requires judicious interventions. Here we use knowledge about agents' social networks to implement fairness mechanisms, in the context of Multiplayer Ultimatum Games. We focus on network-based role assignment and show that preferentially attributing the role of Proposer to low-connected nodes increases the fairness levels in a population. We evaluate the effectiveness of low-degree Proposer assignment considering networks with different average connectivity, group sizes, and group voting rules when accepting proposals (e.g. majority or unanimity). We further show that low-degree Proposer assignment is efficient, not only optimizing fairness, but also the average payoff level in the population. Finally, we show that stricter voting rules (i.e., imposing an accepting consensus as requirement for collectives to accept a proposal) attenuates the unfairness that results from situations where high-degree nodes (hubs) are the natural candidates to play as Proposers. Our results suggest new routes to use role assignment and voting mechanisms to prevent unfair behaviors from spreading on complex networks.",[],[],"['Andreia Sofia Teixeira', 'Francisco C. Santos', 'Alexandre P. Francisco', 'Fernando P. Santos']","['NESC-ID and Instituto Superior Técnico, Universidade de Lisboa, IST-Taguspark, Porto Salvo, Portugal and Princeton University, Department of Ecology and Evolutionary Biology, NJ and ATP-group, Porto Salvo, Portugal', 'CBMA and Departamento de Matemática e Aplicações, Universidade do Minho, Braga, Portugal and ATP-group, Porto Salvo, Portugal', 'NESC-ID and Instituto Superior Técnico, Universidade de Lisboa, IST-Taguspark, Porto Salvo, Portugal', 'NESC-ID and Instituto Superior Técnico, Universidade de Lisboa, IST-Taguspark, Porto Salvo, Portugal and ATP-group, Porto Salvo, Portugal']","['Portugal', 'Portugal', 'Portugal', 'Portugal']"
https://arxiv.org/abs/2102.03980,Fairness & Bias,Multiagent Decision Making For Maritime Traffic Management.,"Crowd movement guidance has been a fascinating problem in various fields, such as easing traffic congestion in unusual events and evacuating people from an emergency-affected area. To grab the reins of crowds, there has been considerable demand for a decision support system that can answer a typical question: ``what will be the outcomes of each of the possible options in the current situation. In this paper, we consider the problem of estimating the effects of crowd movement guidance from past data. To cope with limited amount of available data biased by past decision-makers, we leverage two recent techniques in deep representation learning for spatial data analysis and causal inference. We use a spatial convolutional operator to extract effective spatial features of crowds from a small amount of data and use balanced representation learning based on the integral probability metrics to mitigate the selection bias and missing counterfactual outcomes. To evaluate the performance on estimating the treatment effects of possible guidance, we use a multi-agent simulator to generate realistic data on evacuation scenarios in a crowded theater, since there are no available datasets recording outcomes of all possible crowd movement guidance. The results of three experiments demonstrate that our proposed method reduces the estimation error by at most 56% from state-of-the-art methods.",[],[],"['Koh Takeuchi', 'Ryo Nishida', 'Hisashi Kashima', 'Masaki Onishi']","['School of Information Systems, Singapore Management University', 'School of Information Systems, Singapore Management University', 'School of Information Systems, Singapore Management University', 'School of Information Systems, Singapore Management University']","['Singapore', 'Singapore', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2010.13415,Fairness & Bias,Jointly Extracting Multiple Triplets with Multilayer Translation Constraints.,"Extracting entities and relations from unstructured text has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain. However, they usually involve sequential interrelated steps and suffer from the problem of exposure bias. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while immune from the exposure bias. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets.",[],[],"['Yucheng Wang', 'Bowen Yu', 'Yueyang Zhang', 'Tingwen Liu', 'Hongsong Zhu', 'Limin Sun']","['Key Laboratory of Science and Technology on Information System Engineering, National University of Defense Technology, China', 'Key Laboratory of Science and Technology on Information System Engineering, National University of Defense Technology, China and Collaborative Innovation Center of Geospatial Technology, China', 'School of Computer Science and Engineering, UNSW, Australia and College of Computer Science and Technology, DGUT, China', 'Key Laboratory of Science and Technology on Information System Engineering, National University of Defense Technology, China and Collaborative Innovation Center of Geospatial Technology, China']","['China', 'China', 'Australia', 'China']"
https://arxiv.org/abs/2305.16409,Fairness & Bias,Predicting and Analyzing Language Specificity in Social Media Posts.,"While existing work on studying bias in NLP focues on negative or pejorative language use, Govindarajan et al. (2023) offer a revised framing of bias in terms of intergroup social context, and its effects on language behavior. In this paper, we investigate if two pragmatic features (specificity and affect) systematically vary in different intergroup contexts -- thus connecting this new framing of bias to language output. Preliminary analysis finds modest correlations between specificity and affect of tweets with supervised intergroup relationship (IGR) labels. Counterfactual probing further reveals that while neural models finetuned for predicting IGR labels reliably use affect in classification, the model's usage of specificity is inconclusive. Code and data can be found at: this https URL",[],[],"['Venkata S Govindarajan', 'Kyle Mahowald', 'David I. Beaver', 'Junyi Jessy Li']","['Department of Mathematics, The University of Texas at Austin', 'Department of Mathematics, The University of Texas at Austin', 'Bloomberg LP', 'Department of Linguistics, The University of Texas at Austin']",[]
https://arxiv.org/abs/2202.00535,Fairness & Bias,Paraphrase Diversification Using Counterfactual Debiasing.,"Paraphrase generation is a fundamental and long-standing task in natural language processing. In this paper, we concentrate on two contributions to the task: (1) we propose Retrieval Augmented Prompt Tuning (RAPT) as a parameter-efficient method to adapt large pre-trained language models for paraphrase generation; (2) we propose Novelty Conditioned RAPT (NC-RAPT) as a simple model-agnostic method of using specialized prompt tokens for controlled paraphrase generation with varying levels of lexical novelty. By conducting extensive experiments on four datasets, we demonstrate the effectiveness of the proposed approaches for retaining the semantic content of the original text while inducing lexical novelty in the generation.",[],[],"['Jishnu Ray Chowdhury', 'Yong Zhuang', 'Shuyi Wang']","['Yonsei University and Clova AI Research, NAVER', 'Yonsei University', 'Clova AI Research, NAVER and Hong Kong University of Science and Technology', 'Korea University', 'Clova AI Research, NAVER', 'Clova AI Research, NAVER and Hong Kong University of Science and Technology', 'Clova AI Research, NAVER']","['Hong Kong', 'Hong Kong']"
https://arxiv.org/abs/1811.08982,Fairness & Bias,Unseen Word Representation by Aligning Heterogeneous Lexical Semantic Spaces.,"Conventional object detection models require large amounts of training data. In comparison, humans can recognize previously unseen objects by merely knowing their semantic description. To mimic similar behaviour, zero-shot object detection aims to recognize and localize 'unseen' object instances by using only their semantic information. The model is first trained to learn the relationships between visual and semantic domains for seen objects, later transferring the acquired knowledge to totally unseen objects. This setting gives rise to the need for correct alignment between visual and semantic concepts, so that the unseen objects can be identified using only their semantic attributes. In this paper, we propose a novel loss function called 'Polarity loss', that promotes correct visual-semantic alignment for an improved zero-shot object detection. On one hand, it refines the noisy semantic embeddings via metric learning on a 'Semantic vocabulary' of related concepts to establish a better synergy between visual and semantic domains. On the other hand, it explicitly maximizes the gap between positive and negative predictions to achieve better discrimination between seen, unseen and background objects. Our approach is inspired by embodiment theories in cognitive science, that claim human semantic understanding to be grounded in past experiences (seen objects), related linguistic concepts (word vocabulary) and visual perception (seen/unseen object images). We conduct extensive evaluations on MS-COCO and Pascal VOC datasets, showing significant improvements over state of the art.",[],[],"['Shafin Rahman', 'Salman Khan', 'Nick Barnes']","['Department of Theoretical and Applied Linguistics, University of Cambridge', 'Department of Theoretical and Applied Linguistics, University of Cambridge and School of Computer Engineering, Iran University of Science and Technology, Tehran, Iran', 'Apple, Cambridge, UK', 'Department of Computer Science, University of Cambridge', 'Department of Theoretical and Applied Linguistics, University of Cambridge']",['UK']
https://arxiv.org/abs/1811.06031,Fairness & Bias,A Hierarchical Multi-Task Approach for Learning Embeddings from Semantic Tasks.,"Much effort has been devoted to evaluate whether multi-task learning can be leveraged to learn rich representations that can be used in various Natural Language Processing (NLP) down-stream applications. However, there is still a lack of understanding of the settings in which multi-task learning has a significant effect. In this work, we introduce a hierarchical model trained in a multi-task learning setup on a set of carefully selected semantic tasks. The model is trained in a hierarchical fashion to introduce an inductive bias by supervising a set of low level tasks at the bottom layers of the model and more complex tasks at the top layers of the model. This model achieves state-of-the-art results on a number of tasks, namely Named Entity Recognition, Entity Mention Detection and Relation Extraction without hand-engineered features or external NLP tools like syntactic parsers. The hierarchical training supervision induces a set of shared semantic representations at lower layers of the model. We show that as we move from the bottom to the top layers of the model, the hidden states of the layers tend to represent more complex semantic information.",[],[],"['Victor Sanh', 'Thomas Wolf', 'Sebastian Ruder']","['Hugging Face, Brooklyn, New York', 'Hugging Face, Brooklyn, New York', 'Insight Research Centre, National University of Ireland, Galway, Ireland and Aylien Ltd., Dublin, Ireland']",['Ireland']
https://arxiv.org/abs/2102.02114,Fairness & Bias,Better Fine-Tuning via Instance Weighting for Text Classification.,"Classification is an essential and fundamental task in machine learning, playing a cardinal role in the field of natural language processing (NLP) and computer vision (CV). In a supervised learning setting, labels are always needed for the classification task. Especially for deep neural models, a large amount of high-quality labeled data are required for training. However, when a new domain comes out, it is usually hard or expensive to acquire the labels. Transfer learning could be an option to transfer the knowledge from a source domain to a target domain. A challenge is that these two domains can be different, either on the feature distribution, or the class distribution for the nature of the samples. In this work, we evaluate some existing transfer learning approaches on detecting the bias of imbalanced classes including traditional and deep models. Besides, we propose an approach to bridge the gap of the domain class imbalance issue.",[],[],['Irene Li'],"['Department of Control and Systems Engineering, Nanjing University, Nanjing, China', 'Tencent AI Lab, Shenzhen, China', 'Tencent AI Lab, Shenzhen, China', 'Tencent AI Lab, Shenzhen, China']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/1811.07078,Fairness & Bias,An Affect-Rich Neural Conversational Model with Biased Attention and Weighted Cross-Entropy Loss.,"Affect conveys important implicit information in human communication. Having the capability to correctly express affect during human-machine conversations is one of the major milestones in artificial intelligence. In recent years, extensive research on open-domain neural conversational models has been conducted. However, embedding affect into such models is still under explored. In this paper, we propose an end-to-end affect-rich open-domain neural conversational model that produces responses not only appropriate in syntax and semantics, but also with rich affect. Our model extends the Seq2Seq model and adopts VAD (Valence, Arousal and Dominance) affective notations to embed each word with affects. In addition, our model considers the effect of negators and intensifiers via a novel affective attention mechanism, which biases attention towards affect-rich words in input sentences. Lastly, we train our model with an affect-incorporated objective function to encourage the generation of affect-rich words in the output responses. Evaluations based on both perplexity and human evaluations show that our model outperforms the state-of-the-art baseline model of comparable size in producing natural and affect-rich responses.",[],[],"['Peixiang Zhong', 'Di Wang', 'Chunyan Miao']","['Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University, Singapore and Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore', 'Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University, Singapore', 'Joint NTU-UBC Research Centre of Excellence in Active Living for the Elderly, Nanyang Technological University, Singapore and Alibaba-NTU Singapore Joint Research Institute, Nanyang Technological University, Singapore and School of Computer Science and Engineering, Nanyang Technological University, Singapore']","['Singapore', 'Singapore', 'Singapore']"
https://arxiv.org/abs/2101.01169,Fairness & Bias,Efficient Temporal Planning Using Metastates.,"Astounding results from Transformer models on natural language tasks have intrigued the vision community to study their application to computer vision problems. Among their salient benefits, Transformers enable modeling long dependencies between input sequence elements and support parallel processing of sequence as compared to recurrent networks e.g., Long short-term memory (LSTM). Different from convolutional networks, Transformers require minimal inductive biases for their design and are naturally suited as set-functions. Furthermore, the straightforward design of Transformers allows processing multiple modalities (e.g., images, videos, text and speech) using similar processing blocks and demonstrates excellent scalability to very large capacity networks and huge datasets. These strengths have led to exciting progress on a number of vision tasks using Transformer networks. This survey aims to provide a comprehensive overview of the Transformer models in the computer vision discipline. We start with an introduction to fundamental concepts behind the success of Transformers i.e., self-attention, large-scale pre-training, and bidirectional encoding. We then cover extensive applications of transformers in vision including popular recognition tasks (e.g., image classification, object detection, action recognition, and segmentation), generative modeling, multi-modal tasks (e.g., visual-question answering, visual reasoning, and visual grounding), video processing (e.g., activity recognition, video forecasting), low-level vision (e.g., image super-resolution, image enhancement, and colorization) and 3D analysis (e.g., point cloud classification and segmentation). We compare the respective advantages and limitations of popular techniques both in terms of architectural design and their experimental value. Finally, we provide an analysis on open research directions and possible future works.",[],[],"['Salman Khan', 'Muzammal Naseer', 'Munawar Hayat', 'Syed Waqas Zamir', 'Fahad Shahbaz Khan', 'Mubarak Shah']","[""Department of Informatics, King's College London, UK"", ""Department of Informatics, King's College London, UK"", 'Department of Mechanical & Industrial Engineering, University of Toronto, Canada']","['UK', 'UK', 'Canada']"
https://arxiv.org/abs/1802.08139,Fairness & Bias,Path-Specific Counterfactual Fairness.,"We consider the problem of learning fair decision systems in complex scenarios in which a sensitive attribute might affect the decision along both fair and unfair pathways. We introduce a causal approach to disregard effects along unfair pathways that simplifies and generalizes previous literature. Our method corrects observations adversely affected by the sensitive attribute, and uses these to form a decision. This avoids disregarding fair information, and does not require an often intractable computation of the path-specific effect. We leverage recent developments in deep learning and approximate inference to achieve a solution that is widely applicable to complex, non-linear scenarios.",[],[],"['Silvia Chiappa', 'Thomas P. S. Gillam']",[],[]
https://arxiv.org/abs/2204.00379,Fairness & Bias,Dual Semi-Supervised Learning for Facial Action Unit Recognition.,"Automatic facial action unit (AU) recognition is a challenging task due to the scarcity of manual annotations. To alleviate this problem, a large amount of efforts has been dedicated to exploiting various weakly supervised methods which leverage numerous unlabeled data. However, many aspects with regard to some unique properties of AUs, such as the regional and relational characteristics, are not sufficiently explored in previous works. Motivated by this, we take the AU properties into consideration and propose two auxiliary AU related tasks to bridge the gap between limited annotations and the model performance in a self-supervised manner via the unlabeled data. Specifically, to enhance the discrimination of regional features with AU relation embedding, we design a task of RoI inpainting to recover the randomly cropped AU patches. Meanwhile, a single image based optical flow estimation task is proposed to leverage the dynamic change of facial muscles and encode the motion information into the global feature representation. Based on these two self-supervised auxiliary tasks, local features, mutual relation and motion cues of AUs are better captured in the backbone network. Furthermore, by incorporating semi-supervised learning, we propose an end-to-end trainable framework named weakly supervised regional and temporal learning (WSRTL) for AU recognition. Extensive experiments on BP4D and DISFA demonstrate the superiority of our method and new state-of-the-art performances are achieved.",[],[],"['Jingwei Yan', 'Jingjing Wang', 'Qiang Li', 'Chunmao Wang', 'Shiliang Pu']","['Key Lab of Computing and Communication Software of Anhui Province, School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui, P.R. China', 'Key Lab of Computing and Communication Software of Anhui Province, School of Computer Science and Technology, University of Science and Technology of China, Hefei, Anhui, P.R. China']","['China', 'China']"
https://arxiv.org/abs/1811.05253,Fairness & Bias,Hierarchical Attention Network for Image Captioning.,"Automatically generating the descriptions of an image, i.e., image captioning, is an important and fundamental topic in artificial intelligence, which bridges the gap between computer vision and natural language processing. Based on the successful deep learning models, especially the CNN model and Long Short-Term Memories (LSTMs) with attention mechanism, we propose a hierarchical attention model by utilizing both of the global CNN features and the local object features for more effective feature representation and reasoning in image captioning. The generative adversarial network (GAN), together with a reinforcement learning (RL) algorithm, is applied to solve the exposure bias problem in RNN-based supervised training for language problems. In addition, through the automatic measurement of the consistency between the generated caption and the image content by the discriminator in the GAN framework and RL optimization, we make the finally generated sentences more accurate and natural. Comprehensive experiments show the improved performance of the hierarchical attention mechanism and the effectiveness of our RL-based optimization method. Our model achieves state-of-the-art results on several important metrics in the MSCOCO dataset, using only greedy inference.",[],[],"['Shiyang Yan', 'Yuan Xie', 'Fangyu Wu', 'Jeremy S. Smith', 'Wenjin Lu', 'Bailing Zhang']","['School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China', 'School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China', 'School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China']","['China', 'China', 'China']"
https://arxiv.org/abs/1908.01308,Fairness & Bias,What and Where the Themes Dominate in Image.,"Aesthetic quality assessment (AQA) is a challenging task due to complex aesthetic factors. Currently, it is common to conduct AQA using deep neural networks that require fixed-size inputs. Existing methods mainly transform images by resizing, cropping, and padding or employ adaptive pooling to alternately capture the aesthetic features from fixed-size inputs. However, these transformations potentially damage aesthetic features. To address this issue, we propose a simple but effective method to accomplish full-resolution image AQA by combining image padding with region of image (RoM) pooling. Padding turns inputs into the same size. RoM pooling pools image features and discards extra padded features to eliminate the side effects of padding. In addition, the image aspect ratios are encoded and fused with visual features to remedy the shape information loss of RoM pooling. Furthermore, we observe that the same image may receive different aesthetic evaluations under different themes, which we call theme criterion bias. Hence, a theme-aware model that uses theme information to guide model predictions is proposed. Finally, we design an attention-based feature fusion module to effectively utilize both the shape and theme information. Extensive experiments prove the effectiveness of the proposed method over state-of-the-art methods.",[],[],"['Gengyun Jia', 'Peipei Li', 'Ran He']","['National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and School of Artificial Intelligence, University of Chinese Academy of Sciences', 'National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences', 'National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences and School of Artificial Intelligence, University of Chinese Academy of Sciences', 'National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences']",[]
https://arxiv.org/abs/2012.05057,Fairness & Bias,Learning a Visual Tracker from a Single Movie without Annotation.,"In this paper, we focus on the self-supervised learning of visual correspondence using unlabeled videos in the wild. Our method simultaneously considers intra- and inter-video representation associations for reliable correspondence estimation. The intra-video learning transforms the image contents across frames within a single video via the frame pair-wise affinity. To obtain the discriminative representation for instance-level separation, we go beyond the intra-video analysis and construct the inter-video affinity to facilitate the contrastive transformation across different videos. By forcing the transformation consistency between intra- and inter-video levels, the fine-grained correspondence associations are well preserved and the instance-level feature discrimination is effectively reinforced. Our simple framework outperforms the recent self-supervised correspondence methods on a range of visual tasks including video object tracking (VOT), video object segmentation (VOS), pose keypoint tracking, etc. It is worth mentioning that our method also surpasses the fully-supervised affinity representation (e.g., ResNet) and performs competitively against the recent fully-supervised algorithms designed for the specific tasks (e.g., VOT and VOS).",[],[],"['Ning Wang', 'Wengang Zhou', 'Houqiang Li']","['Department of Computing, The Hong Kong Polytechnic University, Hong Kong', 'Department of Computing, The Hong Kong Polytechnic University, Hong Kong', 'Department of Computing, The Hong Kong Polytechnic University, Hong Kong']","['Hong Kong', 'Hong Kong', 'Hong Kong']"
https://arxiv.org/abs/2207.14465,Fairness & Bias,Towards Optimal Fine Grained Retrieval via Decorrelated Centralized Loss with Normalize-Scale Layer.,"Fine-grained object retrieval aims to learn discriminative representation to retrieve visually similar objects. However, existing top-performing works usually impose pairwise similarities on the semantic embedding spaces or design a localization sub-network to continually fine-tune the entire model in limited data scenarios, thus resulting in convergence to suboptimal solutions. In this paper, we develop Fine-grained Retrieval Prompt Tuning (FRPT), which steers a frozen pre-trained model to perform the fine-grained retrieval task from the perspectives of sample prompting and feature adaptation. Specifically, FRPT only needs to learn fewer parameters in the prompt and adaptation instead of fine-tuning the entire model, thus solving the issue of convergence to suboptimal solutions caused by fine-tuning the entire model. Technically, a discriminative perturbation prompt (DPP) is introduced and deemed as a sample prompting process, which amplifies and even exaggerates some discriminative elements contributing to category prediction via a content-aware inhomogeneous sampling operation. In this way, DPP can make the fine-grained retrieval task aided by the perturbation prompts close to the solved task during the original pre-training. Thereby, it preserves the generalization and discrimination of representation extracted from input samples. Besides, a category-specific awareness head is proposed and regarded as feature adaptation, which removes the species discrepancies in features extracted by the pre-trained model using category-guided instance normalization. And thus, it makes the optimized features only include the discrepancies among subcategories. Extensive experiments demonstrate that our FRPT with fewer learnable parameters achieves the state-of-the-art performance on three widely-used fine-grained datasets.",[],[],"['Shijie Wang', 'Jianlong Chang', 'Zhihui Wang', 'Haojie Li', 'Wanli Ouyang', 'Qi Tian']","['Fujian Key Laboratory of Sensing and Computing for Smart City, Department of Cognitive Science, School of Information Science and Engineering, Xiamen University', 'Fujian Key Laboratory of Sensing and Computing for Smart City, Department of Cognitive Science, School of Information Science and Engineering, Xiamen University and Peng Cheng Laboratory, China', 'Fujian Key Laboratory of Sensing and Computing for Smart City, Department of Cognitive Science, School of Information Science and Engineering, Xiamen University', 'Beihang University', 'Tencent Youtu Lab, Tencent Technology (Shanghai) Co., Ltd', 'Tencent Youtu Lab, Tencent Technology (Shanghai) Co., Ltd']",['China']
https://arxiv.org/abs/2209.08312,Fairness & Bias,Artificial Intelligence Competencies for Data Science Undergraduate Curricula.,"Machine learning (ML) algorithms are gaining increased importance in many academic and industrial applications, and such algorithms are, accordingly, becoming common components in computer science curricula. Learning ML is challenging not only due to its complex mathematical and algorithmic aspects, but also due to a) the complexity of using correctly these algorithms in the context of real-life situations and b) the understanding of related social and ethical issues. Cognitive biases are phenomena of the human brain that may cause erroneous perceptions and irrational decision-making processes. As such, they have been researched thoroughly in the context of cognitive psychology and decision making; they do, however, have important implications for computer science education as well. One well-known cognitive bias, first described by Kahneman and Tversky, is the base rate neglect bias, according to which humans fail to consider the base rate of the underlying phenomena when evaluating conditional probabilities. In this paper, we explore the expression of the base rate neglect bias in ML education. Specifically, we show that about one third of students in an Introduction to ML course, from varied backgrounds (computer science students and teachers, data science, engineering, social science and digital humanities), fail to correctly evaluate ML algorithm performance due to the base rate neglect bias. This failure rate should alert educators and promote the development of new pedagogical methods for teaching ML algorithm performance.",[],[],"['Koby Mike', 'Orit Hazzan']","['Williams College, Williamstown, MA', 'Intel Corporation, Chandler, AZ']",[]
https://arxiv.org/abs/1812.09359,Fairness & Bias,NeuroX: A Toolkit for Analyzing Individual Neurons in Neural Networks.,"We present a toolkit to facilitate the interpretation and understanding of neural network models. The toolkit provides several methods to identify salient neurons with respect to the model itself or an external task. A user can visualize selected neurons, ablate them to measure their effect on the model accuracy, and manipulate them to control the behavior of the model at the test time. Such an analysis has a potential to serve as a springboard in various research directions, such as understanding the model, better architectural choices, model distillation and controlling data biases.",[],[],"['Fahim Dalvi', 'Avery Nortonsmith', 'D. Anthony Bau', 'Yonatan Belinkov', 'Hassan Sajjad', 'Nadir Durrani', 'James Glass']",[],[]
https://arxiv.org/abs/2207.08943,Fairness & Bias,QADiver: Interactive Framework for Diagnosing QA Models.,"Many recent neural models have shown remarkable empirical results in Machine Reading Comprehension, but evidence suggests sometimes the models take advantage of dataset biases to predict and fail to generalize on out-of-sample data. While many other approaches have been proposed to address this issue from the computation perspective such as new architectures or training procedures, we believe a method that allows researchers to discover biases, and adjust the data or the models in an earlier stage will be beneficial. Thus, we introduce MRCLens, a toolkit that detects whether biases exist before users train the full model. For the convenience of introducing the toolkit, we also provide a categorization of common biases in MRC.",[],[],"['Yifan Zhong', 'Haohan Wang', 'Eric P. Xing']","['Yonsei University and Clova AI Research, NAVER Corp.', 'Clova AI Research, NAVER Corp.', 'Yonsei University']",[]
https://arxiv.org/abs/2010.15363,Fairness & Bias,Counterfactual Reasoning in Observational Studies.,"The general aim of the recommender system is to provide personalized suggestions to users, which is opposed to suggesting popular items. However, the normal training paradigm, i.e., fitting a recommender model to recover the user behavior data with pointwise or pairwise loss, makes the model biased towards popular items. This results in the terrible Matthew effect, making popular items be more frequently recommended and become even more popular. Existing work addresses this issue with Inverse Propensity Weighting (IPW), which decreases the impact of popular items on the training and increases the impact of long-tail items. Although theoretically sound, IPW methods are highly sensitive to the weighting strategy, which is notoriously difficult to tune. In this work, we explore the popularity bias issue from a novel and fundamental perspective -- cause-effect. We identify that popularity bias lies in the direct effect from the item node to the ranking score, such that an item's intrinsic property is the cause of mistakenly assigning it a higher ranking score. To eliminate popularity bias, it is essential to answer the counterfactual question that what the ranking score would be if the model only uses item property. To this end, we formulate a causal graph to describe the important cause-effect relations in the recommendation process. During training, we perform multi-task learning to achieve the contribution of each cause; during testing, we perform counterfactual inference to remove the effect of item popularity. Remarkably, our solution amends the learning process of recommendation which is agnostic to a wide range of models -- it can be easily implemented in existing methods. We demonstrate it on Matrix Factorization (MF) and LightGCN [20]. Experiments on five real-world datasets demonstrate the effectiveness of our method.",[],[],"['Tianxin Wei', 'Fuli Feng', 'Jiawei Chen', 'Ziwei Wu', 'Jinfeng Yi', 'Xiangnan He']",[],[]
https://arxiv.org/abs/2106.13746,Fairness & Bias,Learning Flexible Latent Representations via Encapsulated Variational Encoders.,"We explain why directly changing the prior can be a surprisingly ineffective mechanism for incorporating inductive biases into VAEs, and introduce a simple and effective alternative approach: Intermediary Latent Space VAEs(InteL-VAEs). InteL-VAEs use an intermediary set of latent variables to control the stochasticity of the encoding process, before mapping these in turn to the latent representation using a parametric function that encapsulates our desired inductive bias(es). This allows us to impose properties like sparsity or clustering on learned representations, and incorporate human knowledge into the generative model. Whereas changing the prior only indirectly encourages behavior through regularizing the encoder, InteL-VAEs are able to directly enforce desired characteristics. Moreover, they bypass the computation and encoder design issues caused by non-Gaussian priors, while allowing for additional flexibility through training of the parametric mapping function. We show that these advantages, in turn, lead to both better generative models and better representations being learned.",[],[],"['Ning Miao', 'Emile Mathieu', 'N. Siddharth', 'Yee Whye Teh', 'Tom Rainforth']","['Department of Computational Science, Kobe University, Japan', 'Department of Computational Science, Kobe University, Japan', 'Department of Computational Science, Kobe University, Japan']","['Japan', 'Japan', 'Japan']"
https://arxiv.org/abs/1901.08558,Fairness & Bias,Building Human-Machine Trust via Interpretability.,"Decisions by Machine Learning (ML) models have become ubiquitous. Trusting these decisions requires understanding how algorithms take them. Hence interpretability methods for ML are an active focus of research. A central problem in this context is that both the quality of interpretability methods as well as trust in ML predictions are difficult to measure. Yet evaluations, comparisons and improvements of trust and interpretability require quantifiable measures. Here we propose a quantitative measure for the quality of interpretability methods. Based on that we derive a quantitative measure of trust in ML decisions. Building on previous work we propose to measure intuitive understanding of algorithmic decisions using the information transfer rate at which humans replicate ML model predictions. We provide empirical evidence from crowdsourcing experiments that the proposed metric robustly differentiates interpretability methods. The proposed metric also demonstrates the value of interpretability for ML assisted human decision making: in our experiments providing explanations more than doubled productivity in annotation tasks. However unbiased human judgement is critical for doctors, judges, policy makers and others. Here we derive a trust metric that identifies when human decisions are overly biased towards ML predictions. Our results complement existing qualitative work on trust and interpretability by quantifiable measures that can serve as objectives for further improving methods in this field of research.",[],[],"['Philipp Schmidt', 'Felix Biessmann']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']",[]
https://arxiv.org/abs/2108.09098,Fairness & Bias,A Fuzzy Set Based Approach for Rating Bias.,"The need to measure bias encoded in tabular data that are used to solve pattern recognition problems is widely recognized by academia, legislators and enterprises alike. In previous work, we proposed a bias quantification measure, called fuzzy-rough uncer-tainty, which relies on the fuzzy-rough set theory. The intuition dictates that protected features should not change the fuzzy-rough boundary regions of a decision class significantly. The extent to which this happens is a proxy for bias expressed as uncertainty in adecision-making context. Our measure's main advantage is that it does not depend on any machine learning prediction model but adistance function. In this paper, we extend our study by exploring the existence of bias encoded implicitly in non-protected featuresas defined by the correlation between protected and unprotected attributes. This analysis leads to four scenarios that domain experts should evaluate before deciding how to tackle bias. In addition, we conduct a sensitivity analysis to determine the fuzzy operatorsand distance function that best capture change in the boundary regions.",[],[],"['Gonzalo Nápoles', 'Lisa Koutsoviti Koumeri']","['Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China and School of Cyber Security, University of Chinese Academy of Sciences, Beijing, China and University of Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China and University of Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China']","['China', 'China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/2109.00883,Fairness & Bias,Jointly Multiple Hash Learning.,"In recent years, cross-media hashing technique has attracted increasing attention for its high computation efficiency and low storage cost. However, the existing approaches still have some limitations, which need to be explored. 1) A fixed hash length (e.g., 16bits or 32bits) is predefined before learning the binary codes. Therefore, these models need to be retrained when the hash length changes, that consumes additional computation power, reducing the scalability in practical applications. 2) Existing cross-modal approaches only explore the information in the original multimedia data to perform the hash learning, without exploiting the semantic information contained in the learned hash codes. To this end, we develop a novel Multiple hash cOdes jOint learNing method (MOON) for cross-media retrieval. Specifically, the developed MOON synchronously learns the hash codes with multiple lengths in a unified framework. Besides, to enhance the underlying discrimination, we combine the clues from the multimodal data, semantic labels and learned hash codes for hash learning. As far as we know, the proposed MOON is the first work to simultaneously learn different length hash codes without retraining in cross-media retrieval. Experiments on several databases show that our MOON can achieve promising performance, outperforming some recent competitive shallow and deep methods.",[],[],"['Donglin Zhang', 'Xiao-Jun Wu', 'He-Feng Yin', 'Josef Kittler']","['School of Computer Science and Technology, Shandong University, Jinan, P.R. China', 'School of Computer Science and Technology, Shandong Jianzhu University, Jinan, P.R. China', 'School of Computer Science and Technology, Shandong University, Jinan, P.R. China', 'School of Software, Shandong University, Jinan, P.R. China']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/2110.13409,Fairness & Bias,MIGAN: Malware Image Synthesis Using GANs.,"Malware authors apply different techniques of control flow obfuscation, in order to create new malware variants to avoid detection. Existing Siamese neural network (SNN)-based malware detection methods fail to correctly classify different malware families when such obfuscated malware samples are present in the training dataset, resulting in high false-positive rates. To address this issue, we propose a novel task-aware few-shot-learning-based Siamese Neural Network that is resilient against the presence of malware variants affected by such control flow obfuscation techniques. Using the average entropy features of each malware family as inputs, in addition to the image features, our model generates the parameters for the feature layers, to more accurately adjust the feature embedding for different malware families, each of which has obfuscated malware variants. In addition, our proposed method can classify malware classes, even if there are only one or a few training samples available. Our model utilizes few-shot learning with the extracted features of a pre-trained network (e.g., VGG-16), to avoid the bias typically associated with a model trained with a limited number of training samples. Our proposed approach is highly effective in recognizing unique malware signatures, thus correctly classifying malware samples that belong to the same malware family, even in the presence of obfuscated malware variants. Our experimental results, validated by N-way on N-shot learning, show that our model is highly effective in classification accuracy, exceeding a rate \textgreater 91\%, compared to other similar methods.",[],[],"['Jinting Zhu', 'Julian Jang-Jaccard', 'Amardeep Singh', 'Paul A. Watters', 'Seyit Camtepe']","['Indian Institute of Information, Technology, Sri City, AP, India', 'Cisco Systems, San Jose, California', 'Cisco Systems, San Jose, California']",['India']
https://arxiv.org/abs/2202.11345,Fairness & Bias,Incorporating Context-Relevant Knowledge into Convolutional Neural Networks for Short Text Classification.,"In the short text, the extremely short length, feature sparsity, and high ambiguity pose huge challenges to classification tasks. Recently, as an effective method for tuning Pre-trained Language Models for specific downstream tasks, prompt-learning has attracted a vast amount of attention and research. The main intuition behind the prompt-learning is to insert the template into the input and convert the text classification tasks into equivalent cloze-style tasks. However, most prompt-learning methods expand label words manually or only consider the class name for knowledge incorporating in cloze-style prediction, which will inevitably incur omissions and bias in short text classification tasks. In this paper, we propose a simple short text classification approach that makes use of prompt-learning based on knowledgeable expansion. Taking the special characteristics of short text into consideration, the method can consider both the short text itself and class name during expanding label words space. Specifically, the top $N$ concepts related to the entity in the short text are retrieved from the open Knowledge Graph like Probase, and we further refine the expanded label words by the distance calculation between selected concepts and class labels. Experimental results show that our approach obtains obvious improvement compared with other fine-tuning, prompt-learning, and knowledgeable prompt-tuning methods, outperforming the state-of-the-art by up to 6 Accuracy points on three well-known datasets.",[],[],"['Yi Zhu', 'Xinke Zhou', 'Jipeng Qiang', 'Yun Li', 'Yunhao Yuan', 'Xindong Wu']","['South China University of Technology, Guangzhou, China', 'South China University of Technology, Guangzhou, China']","['China', 'China']"
https://arxiv.org/abs/2007.12804,Fairness & Bias,Towards Gene Function Prediction via Multi-Networks Representation Learning.,"Protein function prediction may be framed as predicting subgraphs (with certain closure properties) of a directed acyclic graph describing the hierarchy of protein functions. Graph neural networks (GNNs), with their built-in inductive bias for relational data, are hence naturally suited for this task. However, in contrast with most GNN applications, the graph is not related to the input, but to the label space. Accordingly, we propose Tail-GNNs, neural networks which naturally compose with the output space of any neural network for multi-task prediction, to provide relationally-reinforced labels. For protein function prediction, we combine a Tail-GNN with a dilated convolutional network which learns representations of the protein sequence, making significant improvement in F_1 score and demonstrating the ability of Tail-GNNs to learn useful representations of labels and exploit them in real-world problem solving.",[],[],"['Stefan Spalević', 'Petar Veličković', 'Jovana Kovačević', 'Mladen Nikolić']","[""School of Computer Science, Northwestern Polytechnical University, Xi'an, China and School of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China"", ""School of Computer Science, Northwestern Polytechnical University, Xi'an, China"", ""School of Computer Science, Northwestern Polytechnical University, Xi'an, China""]","['China', 'China', 'China']"
https://arxiv.org/abs/2311.13447,Privacy & Data Governance,Differentially Private Empirical Risk Minimization with Smooth Non-Convex Loss Functions: A Non-Stationary View.,"We study private empirical risk minimization (ERM) problem for losses satisfying the $(\gamma,\kappa)$-Kurdyka-Łojasiewicz (KL) condition. The Polyak-Łojasiewicz (PL) condition is a special case of this condition when $\kappa=2$. Specifically, we study this problem under the constraint of $\rho$ zero-concentrated differential privacy (zCDP). When $\kappa\in[1,2]$ and the loss function is Lipschitz and smooth over a sufficiently large region, we provide a new algorithm based on variance reduced gradient descent that achieves the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ on the excess empirical risk, where $n$ is the dataset size and $d$ is the dimension. We further show that this rate is nearly optimal. When $\kappa \geq 2$ and the loss is instead Lipschitz and weakly convex, we show it is possible to achieve the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ with a private implementation of the proximal point method. When the KL parameters are unknown, we provide a novel modification and analysis of the noisy gradient descent algorithm and show that this algorithm achieves a rate of $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{\frac{2\kappa}{4-\kappa}}\big)$ adaptively, which is nearly optimal when $\kappa = 2$. We further show that, without assuming the KL condition, the same gradient descent algorithm can achieve fast convergence to a stationary point when the gradient stays sufficiently large during the run of the algorithm. Specifically, we show that this algorithm can approximate stationary points of Lipschitz, smooth (and possibly nonconvex) objectives with rate as fast as $\tilde{O}\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)$ and never worse than $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^{1/2}\big)$. The latter rate matches the best known rate for methods that do not rely on variance reduction.",[],[],"['Michael Menart', 'Enayat Ullah', 'Raman Arora', 'Raef Bassily', 'Cristóbal Guzmán']","['Deparment of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, New York', 'Deparment of Computer Science and Engineering, State University of New York at Buffalo, Buffalo, New York']",[]
https://arxiv.org/abs/1811.05072,Privacy & Data Governance,Private Model Compression via Knowledge Distillation.,"The soaring demand for intelligent mobile applications calls for deploying powerful deep neural networks (DNNs) on mobile devices. However, the outstanding performance of DNNs notoriously relies on increasingly complex models, which in turn is associated with an increase in computational expense far surpassing mobile devices' capacity. What is worse, app service providers need to collect and utilize a large volume of users' data, which contain sensitive information, to build the sophisticated DNN models. Directly deploying these models on public mobile devices presents prohibitive privacy risk. To benefit from the on-device deep learning without the capacity and privacy concerns, we design a private model compression framework RONA. Following the knowledge distillation paradigm, we jointly use hint learning, distillation learning, and self learning to train a compact and fast neural network. The knowledge distilled from the cumbersome model is adaptively bounded and carefully perturbed to enforce differential privacy. We further propose an elegant query sample selection method to reduce the number of queries and control the privacy loss. A series of empirical evaluations as well as the implementation on an Android mobile device show that RONA can not only compress cumbersome models efficiently but also provide a strong privacy guarantee. For example, on SVHN, when a meaningful $(9.83,10^{-6})$-differential privacy is guaranteed, the compact model trained by RONA can obtain 20$\times$ compression ratio and 19$\times$ speed-up with merely 0.97% accuracy loss.",[],[],"['Ji Wang', 'Weidong Bao', 'Lichao Sun', 'Xiaomin Zhu', 'Bokai Cao', 'Philip S. Yu']","['College of Systems Engineering, National University of Defense Technology, Changsha, China', 'College of Systems Engineering, National University of Defense Technology, Changsha, China', 'Department of Computer Science, University of Illinois at Chicago, Chicago', 'College of Systems Engineering, National University of Defense Technology, Changsha, China and State Key Laboratory of High Performance Computing, National University of Defense Technology, Changsha, China', 'Facebook Inc., Menlo Park', 'Department of Computer Science, University of Illinois at Chicago, Chicago and Institute for Data Science, Tsinghua University, Beijing, China']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/1902.07535,Privacy & Data Governance,Complex Moment-Based Supervised Eigenmap for Dimensionality Reduction.,"In this paper, we propose a data collaboration analysis method for distributed datasets. The proposed method is a centralized machine learning while training datasets and models remain distributed over some institutions. Recently, data became large and distributed with decreasing costs of data collection. If we can centralize these distributed datasets and analyse them as one dataset, we expect to obtain novel insight and achieve a higher prediction performance compared with individual analyses on each distributed dataset. However, it is generally difficult to centralize the original datasets due to their huge data size or regarding a privacy-preserving problem. To avoid these difficulties, we propose a data collaboration analysis method for distributed datasets without sharing the original datasets. The proposed method centralizes only intermediate representation constructed individually instead of the original dataset.",[],[],"['Akira Imakura', 'Tetsuya Sakurai']","['University of Tsukuba, Tsukuba, Ibaraki, Japan', 'University of Tsukuba, Tsukuba, Ibaraki, Japan', 'University of Tsukuba, Tsukuba, Ibaraki, Japan', 'University of Tsukuba, Tsukuba, Ibaraki, Japan']","['Japan', 'Japan', 'Japan', 'Japan']"
https://arxiv.org/abs/2207.13897,Privacy & Data Governance,"Collaborative, Dynamic and Diversified User Profiling.","Owing to its nature of scalability and privacy by design, federated learning (FL) has received increasing interest in decentralized deep learning. FL has also facilitated recent research on upscaling and privatizing personalized recommendation services, using on-device data to learn recommender models locally. These models are then aggregated globally to obtain a more performant model, while maintaining data privacy. Typically, federated recommender systems (FRSs) do not consider the lack of resources and data availability at the end-devices. In addition, they assume that the interaction data between users and items is i.i.d. and stationary across end-devices, and that all local recommender models can be directly averaged without considering the user's behavioral diversity. However, in real scenarios, recommendations have to be made on end-devices with sparse interaction data and limited resources. Furthermore, users' preferences are heterogeneous and they frequently visit new items. This makes their personal preferences highly skewed, and the straightforwardly aggregated model is thus ill-posed for such non-i.i.d. data. In this paper, we propose Resource Efficient Federated Recommender System (ReFRS) to enable decentralized recommendation with dynamic and diversified user preferences. On the device side, ReFRS consists of a lightweight self-supervised local model built upon the variational autoencoder for learning a user's temporal preference from a sequence of interacted items. On the server side, ReFRS utilizes a semantic sampler to adaptively perform model aggregation within each identified user cluster. The clustering module operates in an asynchronous and dynamic manner to support efficient global model update and cope with shifting user interests. As a result, ReFRS achieves superior performance in terms of both accuracy and scalability, as demonstrated by comparative experiments.",[],[],"['Mubashir Imran', 'Hongzhi Yin', 'Tong Chen', 'Nguyen Quoc Viet Hung', 'Alexander Zhou', 'Kai Zheng']",[],[]
https://arxiv.org/abs/2012.13085,Security,Graph Convolutional Networks Meet Markov Random Fields: Semi-Supervised Community Detection in Attribute Networks.,"Semi-supervised node classification on graph-structured data has many applications such as fraud detection, fake account and review detection, user's private attribute inference in social networks, and community detection. Various methods such as pairwise Markov Random Fields (pMRF) and graph neural networks were developed for semi-supervised node classification. pMRF is more efficient than graph neural networks. However, existing pMRF-based methods are less accurate than graph neural networks, due to a key limitation that they assume a heuristics-based constant edge potential for all edges. In this work, we aim to address the key limitation of existing pMRF-based methods. In particular, we propose to learn edge potentials for pMRF. Our evaluation results on various types of graph datasets show that our optimized pMRF-based method consistently outperforms existing graph neural networks in terms of both accuracy and efficiency. Our results highlight that previous work may have underestimated the power of pMRF for semi-supervised node classification.",[],[],"['Binghui Wang', 'Jinyuan Jia', 'Neil Zhenqiang Gong']",[],[]
https://arxiv.org/abs/1806.00081,Security,Resisting Adversarial Attacks Using Gaussian Mixture Variational Autoencoders.,"Susceptibility of deep neural networks to adversarial attacks poses a major theoretical and practical challenge. All efforts to harden classifiers against such attacks have seen limited success. Two distinct categories of samples to which deep networks are vulnerable, ""adversarial samples"" and ""fooling samples"", have been tackled separately so far due to the difficulty posed when considered together. In this work, we show how one can address them both under one unified framework. We tie a discriminative model with a generative model, rendering the adversarial objective to entail a conflict. Our model has the form of a variational autoencoder, with a Gaussian mixture prior on the latent vector. Each mixture component of the prior distribution corresponds to one of the classes in the data. This enables us to perform selective classification, leading to the rejection of adversarial samples instead of misclassification. Our method inherently provides a way of learning a selective classifier in a semi-supervised scenario as well, which can resist adversarial attacks. We also show how one can reclassify the rejected adversarial samples.",[],[],"['Partha Ghosh', 'Arpan Losalka', 'Michael J Black']","['Max Planck Institute of Intelligent Systems', 'IBM Research AI', 'Max Planck Institute of Intelligent Systems']",[]
https://arxiv.org/abs/2204.11910,Security,Selecting Compliant Agents for Opt-in Micro-Tolling.,"We introduce a new setting, optimize-and-estimate structured bandits. Here, a policy must select a batch of arms, each characterized by its own context, that would allow it to both maximize reward and maintain an accurate (ideally unbiased) population estimate of the reward. This setting is inherent to many public and private sector applications and often requires handling delayed feedback, small data, and distribution shifts. We demonstrate its importance on real data from the United States Internal Revenue Service (IRS). The IRS performs yearly audits of the tax base. Two of its most important objectives are to identify suspected misreporting and to estimate the ""tax gap"" -- the global difference between the amount paid and true amount owed. Based on a unique collaboration with the IRS, we cast these two processes as a unified optimize-and-estimate structured bandit. We analyze optimize-and-estimate approaches to the IRS problem and propose a novel mechanism for unbiased population estimation that achieves rewards comparable to baseline approaches. This approach has the potential to improve audit efficacy, while maintaining policy-relevant estimates of the tax gap. This has important social consequences given that the current tax gap is estimated at nearly half a trillion dollars. We suggest that this problem setting is fertile ground for further research and we highlight its interesting challenges. The results of this and related research are currently being incorporated into the continual improvement of the IRS audit selection methods.",[],[],"['Peter Henderson', 'Ben Chugg', 'Brandon Anderson', 'Kristen Altenburger', 'Alex Turk', 'John Guyton', 'Jacob Goldin', 'Daniel E. Ho']","['The University of Texas at Austin', 'Texas A & M University', 'The University of Texas at Austin', 'The University of Texas at Austin']",[]
https://arxiv.org/abs/1904.10637,Security,Who Blames Whom in a Crisis? Detecting Blame Ties from News Articles Using Neural Networks.,"Blame games tend to follow major disruptions, be they financial crises, natural disasters or terrorist attacks. To study how the blame game evolves and shapes the dominant crisis narratives is of great significance, as sense-making processes can affect regulatory outcomes, social hierarchies, and cultural norms. However, it takes tremendous time and efforts for social scientists to manually examine each relevant news article and extract the blame ties (A blames B). In this study, we define a new task, Blame Tie Extraction, and construct a new dataset related to the United States financial crisis (2007-2010) from The New York Times, The Wall Street Journal and USA Today. We build a Bi-directional Long Short-Term Memory (BiLSTM) network for contexts where the entities appear in and it learns to automatically extract such blame ties at the document level. Leveraging the large unsupervised model such as GloVe and ELMo, our best model achieves an F1 score of 70% on the test set for blame tie extraction, making it a useful tool for social scientists to extract blame ties more efficiently.",[],[],"['Shuailong Liang', 'Olivia Nicol', 'Yue Zhang']",[],[]
https://arxiv.org/abs/2111.04647,Security,Image Aesthetic Assessment Assisted by Attributes through Adversarial Learning.,"The aesthetic quality of an image is defined as the measure or appreciation of the beauty of an image. Aesthetics is inherently a subjective property but there are certain factors that influence it such as, the semantic content of the image, the attributes describing the artistic aspect, the photographic setup used for the shot, etc. In this paper we propose a method for the automatic prediction of the aesthetics of an image that is based on the analysis of the semantic content, the artistic style and the composition of the image. The proposed network includes: a pre-trained network for semantic features extraction (the Backbone); a Multi Layer Perceptron (MLP) network that relies on the Backbone features for the prediction of image attributes (the AttributeNet); a self-adaptive Hypernetwork that exploits the attributes prior encoded into the embedding generated by the AttributeNet to predict the parameters of the target network dedicated to aesthetic estimation (the AestheticNet). Given an image, the proposed multi-network is able to predict: style and composition attributes, and aesthetic score distribution. Results on three benchmark datasets demonstrate the effectiveness of the proposed method, while the ablation study gives a better understanding of the proposed network.",[],[],"['Luigi Celona', 'Marco Leonardi', 'Paolo Napoletano', 'Alessandro Rozza']","['Key Lab of Computing and Communication Software of Anhui Province, School of Computer Science and Technology', 'Key Lab of Computing and Communication Software of Anhui Province, School of Computer Science and Technology and Key Lab of Computing and Communication Software of Anhui Province, School of Data Science, University of Science and Technology of China, Hefei, Anhui, P.R. China', 'Key Lab of Computing and Communication Software of Anhui Province, School of Data Science, University of Science and Technology of China, Hefei, Anhui, P.R. China']","['China', 'China']"
https://arxiv.org/abs/1805.11770,Security,AutoZOOM: Autoencoder-Based Zeroth Order Optimization Method for Attacking Black-Box Neural Networks.,"Recent studies have shown that adversarial examples in state-of-the-art image classifiers trained by deep neural networks (DNN) can be easily generated when the target model is transparent to an attacker, known as the white-box setting. However, when attacking a deployed machine learning service, one can only acquire the input-output correspondences of the target model; this is the so-called black-box attack setting. The major drawback of existing black-box attacks is the need for excessive model queries, which may give a false sense of model robustness due to inefficient query designs. To bridge this gap, we propose a generic framework for query-efficient black-box attacks. Our framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order Optimization Method, has two novel building blocks towards efficient black-box attacks: (i) an adaptive random gradient estimation strategy to balance query counts and distortion, and (ii) an autoencoder that is either trained offline with unlabeled data or a bilinear resizing operation for attack acceleration. Experimental results suggest that, by applying AutoZOOM to a state-of-the-art black-box attack (ZOO), a significant reduction in model queries can be achieved without sacrificing the attack success rate and the visual quality of the resulting adversarial examples. In particular, when compared to the standard ZOO method, AutoZOOM can consistently reduce the mean query counts in finding successful adversarial examples (or reaching the same distortion level) by at least 93% on MNIST, CIFAR-10 and ImageNet datasets, leading to novel insights on adversarial robustness.",[],[],"['Chun-Chen Tu', 'Paishun Ting', 'Pin-Yu Chen', 'Sijia Liu', 'Huan Zhang', 'Jinfeng Yi', 'Cho-Jui Hsieh', 'Shin-Ming Cheng']",[],[]
https://arxiv.org/abs/2108.01998,Security,Deep Latent Generative Models for Energy Disaggregation.,"Energy disaggregation, also known as non-intrusive load monitoring (NILM), challenges the problem of separating the whole-home electricity usage into appliance-specific individual consumptions, which is a typical application of data analysis. {NILM aims to help households understand how the energy is used and consequently tell them how to effectively manage the energy, thus allowing energy efficiency which is considered as one of the twin pillars of sustainable energy policy (i.e., energy efficiency and renewable energy).} Although NILM is unidentifiable, it is widely believed that the NILM problem can be addressed by data science. Most of the existing approaches address the energy disaggregation problem by conventional techniques such as sparse coding, non-negative matrix factorization, and hidden Markov model. Recent advances reveal that deep neural networks (DNNs) can get favorable performance for NILM since DNNs can inherently learn the discriminative signatures of the different appliances. In this paper, we propose a novel method named adversarial energy disaggregation (AED) based on DNNs. We introduce the idea of adversarial learning into NILM, which is new for the energy disaggregation task. Our method trains a generator and multiple discriminators via an adversarial fashion. The proposed method not only learns shard representations for different appliances, but captures the specific multimode structures of each appliance. Extensive experiments on real-world datasets verify that our method can achieve new state-of-the-art performance.",[],[],"['Zhekai Du', 'Jingjing Li', 'Lei Zhu', 'Ke Lu', 'Heng Tao Shen']","['SUNY Binghamton', 'SUNY Binghamton', 'SUNY Binghamton']",[]
https://arxiv.org/abs/2209.14262,Security,Connecting the Digital and Physical World: Improving the Robustness of Adversarial Attacks.,"Over the past decade, deep learning has revolutionized conventional tasks that rely on hand-craft feature extraction with its strong feature learning capability, leading to substantial enhancements in traditional tasks. However, deep neural networks (DNNs) have been demonstrated to be vulnerable to adversarial examples crafted by malicious tiny noise, which is imperceptible to human observers but can make DNNs output the wrong result. Existing adversarial attacks can be categorized into digital and physical adversarial attacks. The former is designed to pursue strong attack performance in lab environments while hardly remaining effective when applied to the physical world. In contrast, the latter focus on developing physical deployable attacks, thus exhibiting more robustness in complex physical environmental conditions. Recently, with the increasing deployment of the DNN-based system in the real world, strengthening the robustness of these systems is an emergency, while exploring physical adversarial attacks exhaustively is the precondition. To this end, this paper reviews the evolution of physical adversarial attacks against DNN-based computer vision tasks, expecting to provide beneficial information for developing stronger physical adversarial attacks. Specifically, we first proposed a taxonomy to categorize the current physical adversarial attacks and grouped them. Then, we discuss the existing physical attacks and focus on the technique for improving the robustness of physical attacks under complex physical environmental conditions. Finally, we discuss the issues of the current physical adversarial attacks to be solved and give promising directions.",[],[],"['Donghua Wang', 'Wen Yao', 'Tingsong Jiang', 'Guijian Tang', 'Xiaoqian Chen']","['Virginia Tech', 'Virginia Tech', 'Massachusetts Institute of Technology', 'Virginia Tech', 'Virginia Tech']",[]
https://arxiv.org/abs/1911.05706,Security,A Memetic Approach for Sequential Security Games on a Plane with Moving Targets.,"The paper introduces a generic approach to solving Sequential Security Games (SGs) which utilizes Evolutionary Algorithms. Formulation of the method (named EASG) is general and largely game-independent, which allows for its application to a wide range of SGs with just little adjustments addressing game specificity. Comprehensive experiments performed on 3 different types of games (with 300 instances in total) demonstrate robustness and stability of EASG, manifested by repeatable achieving optimal or near-optimal solutions in the vast majority of the cases. The main advantage of EASG is time efficiency. The method scales visibly better than state-of-the-art approaches and consequently can be applied to SG instances which are beyond capabilities of the existing methods. Furthermore, due to anytime characteristics, EASG is very well suited for time-critical applications, as the method can be terminated at any moment and still provide a reasonably good solution - the best one found so far.",[],[],"['Adam Żychowski', 'Jacek Mańdziuk']","['Warsaw University of Technology, Faculty of Mathematics and Information Science, Warsaw, Poland', 'Warsaw University of Technology, Faculty of Mathematics and Information Science, Warsaw, Poland', 'Warsaw University of Technology, Faculty of Mathematics and Information Science, Warsaw, Poland', 'Warsaw University of Technology, Faculty of Mathematics and Information Science, Warsaw, Poland', 'Nanyang Technlogical University School of Computer Science and Engineering, Singapore']","['Poland', 'Poland', 'Poland', 'Poland', 'Singapore']"
https://arxiv.org/abs/2304.01168,Security,Crash to Not Crash: Learn to Identify Dangerous Vehicles Using a Simulator.,"Safety is the primary priority of autonomous driving. Nevertheless, no published dataset currently supports the direct and explainable safety evaluation for autonomous driving. In this work, we propose DeepAccident, a large-scale dataset generated via a realistic simulator containing diverse accident scenarios that frequently occur in real-world driving. The proposed DeepAccident dataset includes 57K annotated frames and 285K annotated samples, approximately 7 times more than the large-scale nuScenes dataset with 40k annotated samples. In addition, we propose a new task, end-to-end motion and accident prediction, which can be used to directly evaluate the accident prediction ability for different autonomous driving algorithms. Furthermore, for each scenario, we set four vehicles along with one infrastructure to record data, thus providing diverse viewpoints for accident scenarios and enabling V2X (vehicle-to-everything) research on perception and prediction tasks. Finally, we present a baseline V2X model named V2XFormer that demonstrates superior performance for motion and accident prediction and 3D object detection compared to the single-vehicle model.",[],[],"['Tianqi Wang', 'Sukmin Kim', 'Wenxuan Ji', 'Enze Xie', 'Chongjian Ge', 'Junsong Chen', 'Zhenguo Li', 'Ping Luo']","['School of Electrical Engineering, KAIST, Daejeon, South Korea', 'School of Electrical Engineering, KAIST, Daejeon, South Korea', 'School of Electrical Engineering, KAIST, Daejeon, South Korea', 'School of Electrical Engineering, KAIST, Daejeon, South Korea']",[]
https://arxiv.org/abs/1908.05429,Security,Adversarial Learning for Weakly-Supervised Social Network Alignment.,"Network alignment is a critical task to a wide variety of fields. Many existing works leverage on representation learning to accomplish this task without eliminating domain representation bias induced by domain-dependent features, which yield inferior alignment performance. This paper proposes a unified deep architecture (DANA) to obtain a domain-invariant representation for network alignment via an adversarial domain classifier. Specifically, we employ the graph convolutional networks to perform network embedding under the domain adversarial principle, given a small set of observed anchors. Then, the semi-supervised learning framework is optimized by maximizing a posterior probability distribution of observed anchors and the loss of a domain classifier simultaneously. We also develop a few variants of our model, such as, direction-aware network alignment, weight-sharing for directed networks and simplification of parameter space. Experiments on three real-world social network datasets demonstrate that our proposed approaches achieve state-of-the-art alignment results.",[],[],"['Huiting Hong', 'Xin Li', 'Yuangang Pan', 'Ivor Tsang']","['State Key Lab of Software Development Environment, Beihang University', 'College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics', 'Department of Electrical Computer Engineering, National University of Singapore', 'Tsinghua University and Computer Science Department, University of Illinois at Chicago', 'Hortonworks', 'State Key Lab of Software Development Environment, Beihang University', 'State Key Lab of Software Development Environment, Beihang University']",['Singapore']
https://arxiv.org/abs/2009.09774,Security,Perceptual-Sensitive GAN for Generating Adversarial Patches.,"Deep neural networks have been shown vulnerable toadversarial patches, where exotic patterns can resultin models wrong prediction. Nevertheless, existing ap-proaches to adversarial patch generation hardly con-sider the contextual consistency between patches andthe image background, causing such patches to be eas-ily detected and adversarial attacks to fail. On the otherhand, these methods require a large amount of data fortraining, which is computationally expensive. To over-come these challenges, we propose an approach to gen-erate adversarial yet inconspicuous patches with onesingle image. In our approach, adversarial patches areproduced in a coarse-to-fine way with multiple scalesof generators and discriminators. Contextual informa-tion is encoded during the Min-Max training to makepatches consistent with surroundings. The selection ofpatch location is based on the perceptual sensitivity ofvictim models. Through extensive experiments, our ap-proach shows strong attacking ability in both the white-box and black-box setting. Experiments on saliency de-tection and user evaluation indicate that our adversar-ial patches can evade human observations, demonstratethe inconspicuousness of our approach. Lastly, we showthat our approach preserves the attack ability in thephysical world.",[],[],"['Jinqi Luo', 'Tao Bai', 'Jun Zhao']","['State Key Laboratory of Software Development Environment, Beihang University, China', 'State Key Laboratory of Software Development Environment, Beihang University, China', 'State Key Laboratory of Software Development Environment, Beihang University, China', 'State Key Laboratory of Software Development Environment, Beihang University, China', 'State Key Laboratory of Software Development Environment, Beihang University, China', 'Department of Computer Science and Technology, University of Cambridge, UK', 'UBTECH Sydney AI Centre, SIT, FEIT, University of Sydney, Australia']","['China', 'China', 'China', 'China', 'China', 'UK', 'Australia']"
https://arxiv.org/abs/1908.01262,Security,DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing.,"Security vulnerabilities play a vital role in network security system. Fuzzing technology is widely used as a vulnerability discovery technology to reduce damage in advance. However, traditional fuzzing techniques have many challenges, such as how to mutate input seed files, how to increase code coverage, and how to effectively bypass verification. Machine learning technology has been introduced as a new method into fuzzing test to alleviate these challenges. This paper reviews the research progress of using machine learning technology for fuzzing test in recent years, analyzes how machine learning improve the fuzz process and results, and sheds light on future work in fuzzing. Firstly, this paper discusses the reasons why machine learning techniques can be used for fuzzing scenarios and identifies six different stages in which machine learning have been used. Then this paper systematically study the machine learning based fuzzing models from selection of machine learning algorithm, pre-processing methods, datasets, evaluation metrics, and hyperparameters setting. Next, this paper assesses the performance of the machine learning models based on the frequently used evaluation metrics. The results of the evaluation prove that machine learning technology has an acceptable capability of categorize predictive for fuzzing. Finally, the comparison on capability of discovering vulnerabilities between traditional fuzzing tools and machine learning based fuzzing tools is analyzed. The results depict that the introduction of machine learning technology can improve the performance of fuzzing. However, there are still some limitations, such as unbalanced training samples and difficult to extract the characteristics related to vulnerabilities.",[],[],"['Yan Wang', 'Peng Jia', 'Luping Liu', 'Jiayong Liu']","['College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA', 'College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA', 'College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA', 'College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA']",[]
https://arxiv.org/abs/1809.01852,Security,GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination.,"Recent progress in deep learning is revolutionizing the healthcare domain including providing solutions to medication recommendations, especially recommending medication combination for patients with complex health conditions. Existing approaches either do not customize based on patient health history, or ignore existing knowledge on drug-drug interactions (DDI) that might lead to adverse outcomes. To fill this gap, we propose the Graph Augmented Memory Networks (GAMENet), which integrates the drug-drug interactions knowledge graph by a memory module implemented as a graph convolutional networks, and models longitudinal patient records as the query. It is trained end-to-end to provide safe and personalized recommendation of medication combination. We demonstrate the effectiveness and safety of GAMENet by comparing with several state-of-the-art methods on real EHR data. GAMENet outperformed all baselines in all effectiveness measures, and also achieved 3.60% DDI rate reduction from existing EHR data.",[],[],"['Junyuan Shang', 'Cao Xiao', 'Tengfei Ma', 'Hongyan Li', 'Jimeng Sun']","['Key Laboratory of Machine Perception, Ministry of Education, Beijing, China and School of EECS, Peking University, Beijing, China', 'IBM Research', 'IBM Research', 'Key Laboratory of Machine Perception, Ministry of Education, Beijing, China and School of EECS, Peking University, Beijing, China', 'Georgia Institute of Technology']","['China', 'China', 'Georgia']"
https://arxiv.org/abs/2201.07224,Security,Optimal Interdiction of Urban Criminals with the Aid of Real-Time Information.,"How resources are deployed to secure critical targets in networks can be modelled by Network Security Games (NSGs). While recent advances in deep learning (DL) provide a powerful approach to dealing with large-scale NSGs, DL methods such as NSG-NFSP suffer from the problem of data inefficiency. Furthermore, due to centralized control, they cannot scale to scenarios with a large number of resources. In this paper, we propose a novel DL-based method, NSGZero, to learn a non-exploitable policy in NSGs. NSGZero improves data efficiency by performing planning with neural Monte Carlo Tree Search (MCTS). Our main contributions are threefold. First, we design deep neural networks (DNNs) to perform neural MCTS in NSGs. Second, we enable neural MCTS with decentralized control, making NSGZero applicable to NSGs with many resources. Third, we provide an efficient learning paradigm, to achieve joint training of the DNNs in NSGZero. Compared to state-of-the-art algorithms, our method achieves significantly better data efficiency and scalability.",[],[],"['Wanqi Xue', 'Bo An', 'Chai Kiat Yeo']","['School of Computer Science and Engineering, Nanyang Technological University, Singapore', 'School of Computer Science and Engineering, Nanyang Technological University, Singapore', 'School of Computer Science and Engineering, Nanyang Technological University, Singapore', 'Department of Electronics and Computer Science, University of Southampton, UK', 'Departments of Computing and Electrical and Electronic Engineering, Imperial College, UK']","['Singapore', 'Singapore', 'Singapore', 'UK', 'UK']"
https://arxiv.org/abs/1803.01798,Security,One-Class Adversarial Nets for Fraud Detection.,"Many online applications, such as online social networks or knowledge bases, are often attacked by malicious users who commit different types of actions such as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most of the fraud detection approaches require a training dataset that contains records of both benign and malicious users. However, in practice, there are often no or very few records of malicious users. In this paper, we develop one-class adversarial nets (OCAN) for fraud detection using training data with only benign users. OCAN first uses LSTM-Autoencoder to learn the representations of benign users from their sequences of online activities. It then detects malicious users by training a discriminator with a complementary GAN model that is different from the regular GAN model. Experimental results show that our OCAN outperforms the state-of-the-art one-class classification models and achieves comparable performance with the latest multi-source LSTM model that requires both benign and malicious users in the training phase.",[],[],"['Panpan Zheng', 'Shuhan Yuan', 'Xintao Wu', 'Jun Li', 'Aidong Lu']","['University of Arkansas', 'University of Arkansas', 'University of Arkansas', 'University of Oregon', 'University of North Carolina at Charlotte']",[]
https://arxiv.org/abs/2108.06228,Security,DeepDPM: Dynamic Population Mapping via Deep Neural Network.,"Fine-grained population distribution data is of great importance for many applications, e.g., urban planning, traffic scheduling, epidemic modeling, and risk control. However, due to the limitations of data collection, including infrastructure density, user privacy, and business security, such fine-grained data is hard to collect and usually, only coarse-grained data is available. Thus, obtaining fine-grained population distribution from coarse-grained distribution becomes an important problem. To tackle this problem, existing methods mainly rely on sufficient fine-grained ground truth for training, which is not often available for the majority of cities. That limits the applications of these methods and brings the necessity to transfer knowledge between data-sufficient source cities to data-scarce target cities. In knowledge transfer scenario, we employ single reference fine-grained ground truth in target city, which is easy to obtain via remote sensing or questionnaire, as the ground truth to inform the large-scale urban structure and support the knowledge transfer in target city. By this approach, we transform the fine-grained population mapping problem into a one-shot transfer learning problem. In this paper, we propose a novel one-shot transfer learning framework PSRNet to transfer spatial-temporal knowledge across cities from the view of network structure, the view of data, and the view of optimization. Experiments on real-life datasets of 4 cities demonstrate that PSRNet has significant advantages over 8 state-of-the-art baselines by reducing RMSE and MAE by more than 25%. Our code and datasets are released in Github (this https URL).",[],[],"['Erzhuo Shao', 'Jie Feng', 'Yingheng Wang', 'Tong Xia', 'Yong Li']","['Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China', 'Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China', 'Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China', 'Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China', 'Beijing National Research Center for Information Science and Technology, Department of Electronic Engineering, Tsinghua University, Beijing, China']","['China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/1811.02483,Security,Deep Reinforcement Learning for Green Security Games with Real-Time Information.,"Green Security Games (GSGs) have been proposed and applied to optimize patrols conducted by law enforcement agencies in green security domains such as combating poaching, illegal logging and overfishing. However, real-time information such as footprints and agents' subsequent actions upon receiving the information, e.g., rangers following the footprints to chase the poacher, have been neglected in previous work. To fill the gap, we first propose a new game model GSG-I which augments GSGs with sequential movement and the vital element of real-time information. Second, we design a novel deep reinforcement learning-based algorithm, DeDOL, to compute a patrolling strategy that adapts to the real-time information against a best-responding attacker. DeDOL is built upon the double oracle framework and the policy-space response oracle, solving a restricted game and iteratively adding best response strategies to it through training deep Q-networks. Exploring the game structure, DeDOL uses domain-specific heuristic strategies as initial strategies and constructs several local modes for efficient and parallelized training. To our knowledge, this is the first attempt to use Deep Q-Learning for security games.",[],[],"['Yufei Wang', 'Zheyuan Ryan Shi', 'Lantao Yu', 'Yi Wu', 'Rohit Singh', 'Lucas Joppa', 'Fei Fang']","['Peking University', 'Carnegie Mellon University', 'Stanford University', 'University of California, Berkeley', 'World Wild Fund for Nature', 'Microsoft Research', 'Carnegie Mellon University']",[]
https://arxiv.org/abs/1811.03761,Security,RSA: Byzantine-Robust Stochastic Aggregation Methods for Distributed Learning from Heterogeneous Datasets.,"In this paper, we propose a class of robust stochastic subgradient methods for distributed learning from heterogeneous datasets at presence of an unknown number of Byzantine workers. The Byzantine workers, during the learning process, may send arbitrary incorrect messages to the master due to data corruptions, communication failures or malicious attacks, and consequently bias the learned model. The key to the proposed methods is a regularization term incorporated with the objective function so as to robustify the learning task and mitigate the negative effects of Byzantine attacks. The resultant subgradient-based algorithms are termed Byzantine-Robust Stochastic Aggregation methods, justifying our acronym RSA used henceforth. In contrast to most of the existing algorithms, RSA does not rely on the assumption that the data are independent and identically distributed (i.i.d.) on the workers, and hence fits for a wider class of applications. Theoretically, we show that: i) RSA converges to a near-optimal solution with the learning error dependent on the number of Byzantine workers; ii) the convergence rate of RSA under Byzantine attacks is the same as that of the stochastic gradient descent method, which is free of Byzantine attacks. Numerically, experiments on real dataset corroborate the competitive performance of RSA and a complexity reduction compared to the state-of-the-art alternatives.",[],[],"['Liping Li', 'Wei Xu', 'Tianyi Chen', 'Georgios B. Giannakis', 'Qing Ling']","['Department of Automation, University of Science and Technology of China, Hefei, Anhui, China', 'Department of Automation, University of Science and Technology of China, Hefei, Anhui, China', 'Digital Technology Center, University of Minnesota, Twin Cities, Minneapolis, Minnesota', 'Digital Technology Center, University of Minnesota, Twin Cities, Minneapolis, Minnesota', 'School of Data and Computer Science, Sun Yat-Sen University, Guangzhou, Guangdong, China']","['China', 'China', 'China']"
https://arxiv.org/abs/2101.11855,Security,The Pure Price of Anarchy of Pool Block Withholding Attacks in Bitcoin Mining.,"Pool block withholding attack is performed among mining pools in digital cryptocurrencies, such as Bitcoin. Instead of mining honestly, pools can be incentivized to infiltrate their own miners into other pools. These infiltrators report partial solutions but withhold full solutions, share block rewards but make no contribution to block mining. The block withholding attack among mining pools can be modeled as a non-cooperative game called ""the miner's dilemm"", which reduces effective mining power in the system and leads to potential systemic instability in the blockchain. However, existing literature on the game-theoretic properties of this attack only gives a preliminary analysis, e.g., an upper bound of 3 for the pure price of anarchy (PPoA) in this game, with two pools involved and no miner betraying. Pure price of anarchy is a measurement of how much mining power is wasted in the miner's dilemma game. Further tightening its upper bound will bring us more insight into the structure of this game, so as to design mechanisms to reduce the systemic loss caused by mutual attacks. In this paper, we give a tight bound of (1, 2] for the pure price of anarchy. Moreover, we show the tight bound holds in a more general setting, in which infiltrators may betray.We also prove the existence and uniqueness of pure Nash equilibrium in this setting. Inspired by experiments on the game among three mining pools, we conjecture that similar results hold in the N-player miner's dilemma game (N>=2).",[],[],"['Qian Wang', 'Yurong Chen']",[],[]
https://arxiv.org/abs/1809.07893,Security,Solving Large Extensive-Form Games with Strategy Constraints.,"Extensive-form games are a common model for multiagent interactions with imperfect information. In two-player zero-sum games, the typical solution concept is a Nash equilibrium over the unconstrained strategy set for each player. In many situations, however, we would like to constrain the set of possible strategies. For example, constraints are a natural way to model limited resources, risk mitigation, safety, consistency with past observations of behavior, or other secondary objectives for an agent. In small games, optimal strategies under linear constraints can be found by solving a linear program; however, state-of-the-art algorithms for solving large games cannot handle general constraints. In this work we introduce a generalized form of Counterfactual Regret Minimization that provably finds optimal strategies under any feasible set of convex constraints. We demonstrate the effectiveness of our algorithm for finding strategies that mitigate risk in security games, and for opponent modeling in poker games when given only partial observations of private information.",[],[],"['Trevor Davis', 'Kevin Waugh', 'Michael Bowling']","['Department of Computing Science, University of Alberta', 'DeepMind', 'DeepMind and Department of Computing Science, University of Alberta']",[]
https://arxiv.org/abs/1811.03823,Security,On the Inducibility of Stackelberg Equilibrium for Security Games.,"Strong Stackelberg equilibrium (SSE) is the standard solution concept of Stackelberg security games. As opposed to the weak Stackelberg equilibrium (WSE), the SSE assumes that the follower breaks ties in favor of the leader and this is widely acknowledged and justified by the assertion that the defender can often induce the attacker to choose a preferred action by making an infinitesimal adjustment to her strategy. Unfortunately, in security games with resource assignment constraints, the assertion might not be valid; it is possible that the defender cannot induce the desired outcome. As a result, many results claimed in the literature may be overly optimistic. To remedy, we first formally define the utility guarantee of a defender strategy and provide examples to show that the utility of SSE can be higher than its utility guarantee. Second, inspired by the analysis of leader's payoff by Von Stengel and Zamir (2004), we provide the solution concept called the inducible Stackelberg equilibrium (ISE), which owns the highest utility guarantee and always exists. Third, we show the conditions when ISE coincides with SSE and the fact that in general case, SSE can be extremely worse with respect to utility guarantee. Moreover, introducing the ISE does not invalidate existing algorithmic results as the problem of computing an ISE polynomially reduces to that of computing an SSE. We also provide an algorithmic implementation for computing ISE, with which our experiments unveil the empirical advantage of the ISE over the SSE.",[],[],"['Qingyu Guo', 'Jiarui Gan', 'Fei Fang', 'Long Tran-Thanh', 'Milind Tambe', 'Bo An']","['School of Computer Science and Engineering, Nanyang Technological University', 'Department of Computer Science, University of Oxford', 'School of Computer Science, Carnegie Mellon University', 'Department of Electronics and Computer Science, University of Southampton', 'Center for Artificial Intelligence in Society, University of Southern California', 'School of Computer Science and Engineering, Nanyang Technological University']",[]
https://arxiv.org/abs/2301.02543,Security,Cooperation Enforcement and Collusion Resistance in Repeated Public Goods Games.,"In a stochastic Stackelberg asymmetric security game, the strong Stackelberg equilibrium (SSE) strategy is a popular option for the defender to get the highest utility against an attacker with the best response (BR) strategy. However, the attacker may be a boundedly rational player, who adopts a combination of the BR strategy and a fixed stubborn one. In such a condition, the SSE strategy may not maintain the defensive performance due to the stubborn element. In this paper, we focus on how the defender can adopt the unilateral-control zero-determinate (ZD) strategy to confront the boundedly rational attacker. At first, we verify the existence of ZD strategies for the defender. We then investigate the performance of the defender's ZD strategy against a boundedly rational attacker, with a comparison of the SSE strategy. Specifically, when the attacker's strategy is close to the BR strategy, the ZD strategy admits a bounded loss for the defender compared with the SSE strategy. Conversely, when the attacker's strategy is close to the stubborn strategy, the ZD strategy can bring higher defensive performance for the defender than the SSE strategy does.",[],[],"['Zhaoyang Cheng', 'Guanpu Chen', 'Yiguang Hong']","['Shanghai Jiao Tong University', 'University of Electronic Science and Technology of China']",['China']
https://arxiv.org/abs/1811.03871,Security,Quasi-Perfect Stackelberg Equilibrium.,"Equilibrium refinements are important in extensive-form (i.e., tree-form) games, where they amend weaknesses of the Nash equilibrium concept by requiring sequential rationality and other beneficial properties. One of the most attractive refinement concepts is quasi-perfect equilibrium. While quasi-perfection has been studied in extensive-form games, it is poorly understood in Stackelberg settings---that is, settings where a leader can commit to a strategy---which are important for modeling, for example, security games. In this paper, we introduce the axiomatic definition of quasi-perfect Stackelberg equilibrium. We develop a broad class of game perturbation schemes that lead to them in the limit. Our class of perturbation schemes strictly generalizes prior perturbation schemes introduced for the computation of (non-Stackelberg) quasi-perfect equilibria. Based on our perturbation schemes, we develop a branch-and-bound algorithm for computing a quasi-perfect Stackelberg equilibrium. It leverages a perturbed variant of the linear program for computing a Stackelberg extensive-form correlated equilibrium. Experiments show that our algorithm can be used to find an approximate quasi-perfect Stackelberg equilibrium in games with thousands of nodes.",[],[],"['Alberto Marchesi', 'Gabriele Farina', 'Christian Kroer', 'Nicola Gatti', 'Tuomas Sandholm']","['Politecnico di Milano, Milan, Italy', 'Carnegie Mellon University, Pittsburgh, PA', 'Carnegie Mellon University, Pittsburgh, PA', 'Politecnico di Milano, Milan, Italy', 'Carnegie Mellon University, Pittsburgh, PA']","['Italy', 'Italy']"
https://arxiv.org/abs/1906.09687,Security,Deception in Finitely Repeated Security Games.,"Advanced Persistent Threats (APTs) have recently emerged as a significant security challenge for a cyber-physical system due to their stealthy, dynamic and adaptive nature. Proactive dynamic defenses provide a strategic and holistic security mechanism to increase the costs of attacks and mitigate the risks. This work proposes a dynamic game framework to model a long-term interaction between a stealthy attacker and a proactive defender. The stealthy and deceptive behaviors are captured by the multi-stage game of incomplete information, where each player has his own private information unknown to the other. Both players act strategically according to their beliefs which are formed by the multi-stage observation and learning. The perfect Bayesian Nash equilibrium provides a useful prediction of both players' policies because no players benefit from unilateral deviations from the equilibrium. We propose an iterative algorithm to compute the perfect Bayesian Nash equilibrium and use the Tennessee Eastman process as a benchmark case study. Our numerical experiment corroborates the analytical results and provides further insights into the design of proactive defense-in-depth strategies.",[],[],"['Linan Huang', 'Quanyan Zhu']","['University of Oregon', 'University of Michigan', 'University of Michigan', 'University of Michigan']",[]
https://arxiv.org/abs/1808.05537,Security,Distributionally Adversarial Attack.,"Recent work on adversarial attack has shown that Projected Gradient Descent (PGD) Adversary is a universal first-order adversary, and the classifier adversarially trained by PGD is robust against a wide range of first-order attacks. It is worth noting that the original objective of an attack/defense model relies on a data distribution $p(\mathbf{x})$, typically in the form of risk maximization/minimization, e.g., $\max/\min\mathbb{E}_{p(\mathbf(x))}\mathcal{L}(\mathbf{x})$ with $p(\mathbf{x})$ some unknown data distribution and $\mathcal{L}(\cdot)$ a loss function. However, since PGD generates attack samples independently for each data sample based on $\mathcal{L}(\cdot)$, the procedure does not necessarily lead to good generalization in terms of risk optimization. In this paper, we achieve the goal by proposing distributionally adversarial attack (DAA), a framework to solve an optimal {\em adversarial-data distribution}, a perturbed distribution that satisfies the $L_\infty$ constraint but deviates from the original data distribution to increase the generalization risk maximally. Algorithmically, DAA performs optimization on the space of potential data distributions, which introduces direct dependency between all data points when generating adversarial samples. DAA is evaluated by attacking state-of-the-art defense models, including the adversarially-trained models provided by {\em MIT MadryLab}. Notably, DAA ranks {\em the first place} on MadryLab's white-box leaderboards, reducing the accuracy of their secret MNIST model to $88.79\%$ (with $l_\infty$ perturbations of $\epsilon = 0.3$) and the accuracy of their secret CIFAR model to $44.71\%$ (with $l_\infty$ perturbations of $\epsilon = 8.0$). Code for the experiments is released on \url{this https URL}.",[],[],"['Tianhang Zheng', 'Changyou Chen', 'Kui Ren']","['State University of New York at Buffalo', 'State University of New York at Buffalo', 'State University of New York at Buffalo and Zhejiang University']",[]
https://arxiv.org/abs/2008.03297,Security,On the Time Complexity of Algorithm Selection Hyper-Heuristics for Multimodal Optimisation.,"Cyber-security garnered significant attention due to the increased dependency of individuals and organizations on the Internet and their concern about the security and privacy of their online activities. Several previous machine learning (ML)-based network intrusion detection systems (NIDSs) have been developed to protect against malicious online behavior. This paper proposes a novel multi-stage optimized ML-based NIDS framework that reduces computational complexity while maintaining its detection performance. This work studies the impact of oversampling techniques on the models' training sample size and determines the minimal suitable training sample size. Furthermore, it compares between two feature selection techniques, information gain and correlation-based, and explores their effect on detection performance and time complexity. Moreover, different ML hyper-parameter optimization techniques are investigated to enhance the NIDS's performance. The performance of the proposed framework is evaluated using two recent intrusion detection datasets, the CICIDS 2017 and the UNSW-NB 2015 datasets. Experimental results show that the proposed model significantly reduces the required training sample size (up to 74%) and feature set size (up to 50%). Moreover, the model performance is enhanced with hyper-parameter optimization with detection accuracies over 99% for both datasets, outperforming recent literature works by 1-2% higher accuracy and 1-2% lower false alarm rate.",[],[],"['MohammadNoor Injadat', 'Abdallah Moubayed', 'Ali Bou Nassif', 'Abdallah Shami']","['Rigorous Research, Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom', 'Rigorous Research, Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom', 'Rigorous Research, Department of Computer Science, The University of Sheffield, Sheffield, United Kingdom']","['United Kingdom', 'United Kingdom', 'United Kingdom']"
https://arxiv.org/abs/1302.1228,Security,Making Money from What You Know - How to Sell Information?,"This work tried to detect the existence of a relationship between the graphic signals - or patterns - observed day by day in the Brazilian stock market and the trends which happen after these signals, within a period of 8 years, for a number of securities. The results obtained from this study show evidence of the existence of such a relationship, suggesting the validity of the Technical Analysis as an instrument to predict the trend of security prices in the Brazilian stock market within that period.",[],[],['Marco Antonio Penteado'],"['The University of Texas at Austin, Austin, Texas', 'Shanghai University of Finance and Economics, Shanghai, China', 'Bar-Ilan University, Ramat Gan, Israel', 'Tsinghua University, Beijing, China']","['China', 'Israel', 'China']"
https://arxiv.org/abs/2111.06721,Security,Counterfactual Randomization: Rescuing Experimental Studies from Obscured Confounding.,"This paper serves to introduce the reader to the field of multi-agent reinforcement learning (MARL) and its intersection with methods from the study of causality. We highlight key challenges in MARL and discuss these in the context of how causal methods may assist in tackling them. We promote moving toward a 'causality first' perspective on MARL. Specifically, we argue that causality can offer improved safety, interpretability, and robustness, while also providing strong theoretical guarantees for emergent behaviour. We discuss potential solutions for common challenges, and use this context to motivate future research directions.",[],[],"['St John Grimbly', 'Jonathan Shock', 'Arnu Pretorius']","['Department of Computer Science, Loyola Marymount University, Los Angeles, CA', 'Department of Computer Science, Purdue University, West Lafayette, IN']",[]
https://arxiv.org/abs/2001.03886,Security,CycleEmotionGAN: Emotional Semantic Consistency Preserved CycleGAN for Adapting Image Emotions.,"Existing domain adaptation methods on visual sentiment classification typically are investigated under the single-source scenario, where the knowledge learned from a source domain of sufficient labeled data is transferred to the target domain of loosely labeled or unlabeled data. However, in practice, data from a single source domain usually have a limited volume and can hardly cover the characteristics of the target domain. In this paper, we propose a novel multi-source domain adaptation (MDA) method, termed Multi-source Sentiment Generative Adversarial Network (MSGAN), for visual sentiment classification. To handle data from multiple source domains, it learns to find a unified sentiment latent space where data from both the source and target domains share a similar distribution. This is achieved via cycle consistent adversarial learning in an end-to-end manner. Extensive experiments conducted on four benchmark datasets demonstrate that MSGAN significantly outperforms the state-of-the-art MDA approaches for visual sentiment classification.",[],[],"['Chuang Lin', 'Sicheng Zhao', 'Lei Meng', 'Tat-Seng Chua']","['University of California, Berkeley', 'Harbin Institute of Technology, China and Didi Chuxing, China', 'Didi Chuxing, China', 'Cornell University', 'Tsinghua University, China', 'University of California, Berkeley', 'Tsinghua University, China', 'University of California, Berkeley']","['China', 'China', 'China', 'China']"
https://arxiv.org/abs/2003.05311,Security,Certifying the True Error: Machine Learning in Coq with Verified Generalization Guarantees.,"Increasingly sophisticated mathematical modelling processes from Machine Learning are being used to analyse complex data. However, the performance and explainability of these models within practical critical systems requires a rigorous and continuous verification of their safe utilisation. Working towards addressing this challenge, this paper presents a principled novel safety argument framework for critical systems that utilise deep neural networks. The approach allows various forms of predictions, e.g., future reliability of passing some demands, or confidence on a required reliability level. It is supported by a Bayesian analysis using operational data and the recent verification and validation techniques for deep learning. The prediction is conservative -- it starts with partial prior knowledge obtained from lifecycle activities and then determines the worst-case prediction. Open challenges are also identified.",[],[],"['Xingyu Zhao', 'Alec Banks', 'James Sharp', 'Valentin Robu', 'David Flynn', 'Michael Fisher', 'Xiaowei Huang']","['Ohio University, Athens, OH', 'Ohio University, Athens, OH']",[]
https://arxiv.org/abs/2204.13305,Security,Complexity of Abstract Argumentation under a Claim-Centric View.,"In this paper, we study the effect of preferences in abstract argumentation under a claim-centric perspective. Recent work has revealed that semantical and computational properties can change when reasoning is performed on claim-level rather than on the argument-level, while under certain natural restrictions (arguments with the same claims have the same outgoing attacks) these properties are conserved. We now investigate these effects when, in addition, preferences have to be taken into account and consider four prominent reductions to handle preferences between arguments. As we shall see, these reductions give rise to different classes of claim-augmented argumentation frameworks, and behave differently in terms of semantic properties and computational complexity. This strengthens the view that the actual choice for handling preferences has to be taken with care.",[],[],"['Michael Bernreiter', 'Wolfgang Dvorak', 'Anna Rapberger', 'Stefan Woltran']","['TU Wien, Vienna, Austria', 'TU Wien, Vienna, Austria']","['Austria', 'Austria']"
https://arxiv.org/abs/2210.03561,Security,Attacking Data Transforming Learners at Training Time.,"As powerful tools for representation learning on graphs, graph neural networks (GNNs) have facilitated various applications from drug discovery to recommender systems. Nevertheless, the effectiveness of GNNs is immensely challenged by issues related to data quality, such as distribution shift, abnormal features and adversarial attacks. Recent efforts have been made on tackling these issues from a modeling perspective which requires additional cost of changing model architectures or re-training model parameters. In this work, we provide a data-centric view to tackle these issues and propose a graph transformation framework named GTrans which adapts and refines graph data at test time to achieve better performance. We provide theoretical analysis on the design of the framework and discuss why adapting graph data works better than adapting the model. Extensive experiments have demonstrated the effectiveness of GTrans on three distinct scenarios for eight benchmark datasets where suboptimal data is presented. Remarkably, GTrans performs the best in most cases with improvements up to 2.8%, 8.2% and 3.8% over the best baselines on three experimental settings. Code is released at this https URL.",[],[],"['Wei Jin', 'Tong Zhao', 'Jiayuan Ding', 'Yozen Liu', 'Jiliang Tang', 'Neil Shah']",[],[]
https://arxiv.org/abs/1812.05083,Security,Adversarial Learning of Semantic Relevance in Text to Image Synthesis.,"We describe a new approach that improves the training of generative adversarial nets (GANs) for synthesizing diverse images from a text input. Our approach is based on the conditional version of GANs and expands on previous work leveraging an auxiliary task in the discriminator. Our generated images are not limited to certain classes and do not suffer from mode collapse while semantically matching the text input. A key to our training methods is how to form positive and negative training examples with respect to the class label of a given image. Instead of selecting random training examples, we perform negative sampling based on the semantic distance from a positive example in the class. We evaluate our approach using the Oxford-102 flower dataset, adopting the inception score and multi-scale structural similarity index (MS-SSIM) metrics to assess discriminability and diversity of the generated images. The empirical results indicate greater diversity in the generated images, especially when we gradually select more negative training examples closer to a positive example in the semantic space.",[],[],"['Miriam Cha', 'Youngjune L. Gwon', 'H.T. Kung']","['John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA', 'John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA', 'John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA']",[]
https://arxiv.org/abs/2110.12308,Security,Deep Neural Network Quantization via Layer-Wise Optimization Using Limited Training Data.,"Neural networks are getting better accuracy with higher energy and computational cost. After quantization, the cost can be greatly saved, and the quantized models are more hardware friendly with acceptable accuracy loss. On the other hand, recent research has found that neural networks are vulnerable to adversarial attacks, and the robustness of a neural network model can only be improved with defense methods, such as adversarial training. In this work, we find that adversarially-trained neural networks are more vulnerable to quantization loss than plain models. To minimize both the adversarial and the quantization losses simultaneously and to make the quantized model robust, we propose a layer-wise adversarial-aware quantization method, using the Lipschitz constant to choose the best quantization parameter settings for a neural network. We theoretically derive the losses and prove the consistency of our metric selection. The experiment results show that our method can effectively and efficiently improve the robustness of quantized adversarially-trained neural networks.",[],[],"['Chang Song', 'Riya Ranjan', 'Hai Li']","['Hanyang Technological University', 'Hanyang Technological University', 'Hanyang Technological University']",[]
https://arxiv.org/abs/1903.08792,Security,End-to-End Safe Reinforcement Learning through Barrier Functions for Safety-Critical Continuous Control Tasks.,"Reinforcement Learning (RL) algorithms have found limited success beyond simulated applications, and one main reason is the absence of safety guarantees during the learning process. Real world systems would realistically fail or break before an optimal controller can be learned. To address this issue, we propose a controller architecture that combines (1) a model-free RL-based controller with (2) model-based controllers utilizing control barrier functions (CBFs) and (3) on-line learning of the unknown system dynamics, in order to ensure safety during learning. Our general framework leverages the success of RL algorithms to learn high-performance controllers, while the CBF-based controllers both guarantee safety and guide the learning process by constraining the set of explorable polices. We utilize Gaussian Processes (GPs) to model the system dynamics and its uncertainties. Our novel controller synthesis algorithm, RL-CBF, guarantees safety with high probability during the learning process, regardless of the RL algorithm used, and demonstrates greater policy exploration efficiency. We test our algorithm on (1) control of an inverted pendulum and (2) autonomous car-following with wireless vehicle-to-vehicle communication, and show that our algorithm attains much greater sample efficiency in learning than other state-of-the-art algorithms and maintains safety during the entire learning process.",[],[],"['Richard Cheng', 'Gabor Orosz', 'Richard M. Murray', 'Joel W. Burdick']","['California Institute of Technology', 'University of Michigan, Ann Arbor', 'California Institute of Technology', 'California Institute of Technology']",[]
https://arxiv.org/abs/2309.11196,Security,Inverse Abstraction of Neural Networks Using Symbolic Interpolation.,"Artificial intelligence (AI) has been advancing at a fast pace and it is now poised for deployment in a wide range of applications, such as autonomous systems, medical diagnosis and natural language processing. Early adoption of AI technology for real-world applications has not been without problems, particularly for neural networks, which may be unstable and susceptible to adversarial examples. In the longer term, appropriate safety assurance techniques need to be developed to reduce potential harm due to avoidable system failures and ensure trustworthiness. Focusing on certification and explainability, this paper provides an overview of techniques that have been developed to ensure safety of AI decisions and discusses future challenges.",[],[],"['Marta Kwiatkowska', 'Xiyue Zhang']","['Computing and Mathematical Sciences, California Institute of Technology', 'Computer Science and Engineering, University of California, San Diego', 'Computing and Mathematical Sciences, California Institute of Technology']",[]
https://arxiv.org/abs/2307.09858,Security,Towards Reliable Learning for High Stakes Applications.,"Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis. Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution. While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis? How can we quantify the uncertainty in the learning process and enable reliable rare category analysis? To answer these questions, we start by investigating miscalibration in existing RCA methods. Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confident in predicting majority classes. Motivated by the observation, we propose a novel individual calibration framework, named CALIRARE, for alleviating the unique challenges of RCA, thus enabling reliable rare category analysis. In particular, to quantify the uncertainties in RCA, we develop a node-level uncertainty quantification algorithm to model the overlapping support regions with high uncertainty; to handle the rarity of minority classes in miscalibration calculation, we generalize the distribution-based calibration metric to the instance level and propose the first individual calibration measurement on graphs named Expected Individual Calibration Error (EICE). We perform extensive experimental evaluations on real-world datasets, including rare category characterization and model calibration tasks, which demonstrate the significance of our proposed framework.",[],[],"['Longfeng Wu', 'Bowen Lei', 'Dongkuan Xu', 'Dawei Zhou']","['Alibaba Group', 'ECNU', 'BUPT']",[]
https://arxiv.org/abs/1805.05532,Security,Knowledge Distillation with Adversarial Samples Supporting Decision Boundary.,"Many recent works on knowledge distillation have provided ways to transfer the knowledge of a trained network for improving the learning process of a new one, but finding a good technique for knowledge distillation is still an open problem. In this paper, we provide a new perspective based on a decision boundary, which is one of the most important component of a classifier. The generalization performance of a classifier is closely related to the adequacy of its decision boundary, so a good classifier bears a good decision boundary. Therefore, transferring information closely related to the decision boundary can be a good attempt for knowledge distillation. To realize this goal, we utilize an adversarial attack to discover samples supporting a decision boundary. Based on this idea, to transfer more accurate information about the decision boundary, the proposed algorithm trains a student classifier based on the adversarial samples supporting the decision boundary. Experiments show that the proposed method indeed improves knowledge distillation and achieves the state-of-the-arts performance.",[],[],"['Byeongho Heo', 'Minsik Lee', 'Sangdoo Yun', 'Jin Young Choi']","['Department of ECE, ASRI, Seoul National University, Korea', 'Division of EE, Hanyang University, Korea', 'Clova AI Research, NAVER Corp, Korea', 'Department of ECE, ASRI, Seoul National University, Korea']",[]
https://arxiv.org/abs/2208.08002,Security,Model-Free IRL Using Maximum Likelihood Estimation.,"Automated vehicles are gradually entering people's daily life to provide a comfortable driving experience for the users. The generic and user-agnostic automated vehicles have limited ability to accommodate the different driving styles of different users. This limitation not only impacts users' satisfaction but also causes safety concerns. Learning from user demonstrations can provide direct insights regarding users' driving preferences. However, it is difficult to understand a driver's preference with limited data. In this study, we use a model-free inverse reinforcement learning method to study drivers' characteristics in the car-following scenario from a naturalistic driving dataset, and show this method is capable of representing users' preferences with reward functions. In order to predict the driving styles for drivers with limited data, we apply Gaussian Mixture Models and compute the similarity of a specific driver to the clusters of drivers. We design a personalized adaptive cruise control (P-ACC) system through a partially observable Markov decision process (POMDP) model. The reward function with the model to mimic drivers' driving style is integrated, with a constraint on the relative distance to ensure driving safety. Prediction of the driving styles achieves 85.7% accuracy with the data of less than 10 car-following events. The model-based experimental driving trajectories demonstrate that the P-ACC system can provide a personalized driving experience.",[],[],"['Shili Sheng', 'Erfan Pakdamanian', 'Kyungtae Han', 'Ziran Wang', 'Lu Feng']","['THINC Lab, Dept. of Computer Science; University of Georgia; Athens, GA', 'THINC Lab, Dept. of Computer Science; University of Georgia; Athens, GA', 'School of Computing Sciences & Computer Engineering; University of Southern Mississippi; Hattiesburg, MS']","['Georgia', 'Georgia']"
https://arxiv.org/abs/2109.06795,Security,Robust Multi-Agent Reinforcement Learning via Minimax Deep Deterministic Policy Gradient.,"In a multirobot system, a number of cyber-physical attacks (e.g., communication hijack, observation perturbations) can challenge the robustness of agents. This robustness issue worsens in multiagent reinforcement learning because there exists the non-stationarity of the environment caused by simultaneously learning agents whose changing policies affect the transition and reward functions. In this paper, we propose a minimax MARL approach to infer the worst-case policy update of other agents. As the minimax formulation is computationally intractable to solve, we apply the convex relaxation of neural networks to solve the inner minimization problem. Such convex relaxation enables robustness in interacting with peer agents that may have significantly different behaviors and also achieves a certified bound of the original optimization problem. We evaluate our approach on multiple mixed cooperative-competitive tasks and show that our method outperforms the previous state of the art approaches on this topic.",[],[],"['Chuangchuang Sun', 'Dong-Ki Kim', 'Jonathan P. How']","['Carnegie Mellon University', 'University of California, Berkeley', 'Tsinghua University', 'Tsinghua University', 'Carnegie Mellon University', 'University of California, Berkeley']",[]
https://arxiv.org/abs/1809.03063,Security,The Curse of Concentration in Robust Learning: Evasion and Poisoning Attacks from Concentration of Measure.,"Many modern machine learning classifiers are shown to be vulnerable to adversarial perturbations of the instances. Despite a massive amount of work focusing on making classifiers robust, the task seems quite challenging. In this work, through a theoretical study, we investigate the adversarial risk and robustness of classifiers and draw a connection to the well-known phenomenon of concentration of measure in metric measure spaces. We show that if the metric probability space of the test instance is concentrated, any classifier with some initial constant error is inherently vulnerable to adversarial perturbations. One class of concentrated metric probability spaces are the so-called Levy families that include many natural distributions. In this special case, our attacks only need to perturb the test instance by at most $O(\sqrt n)$ to make it misclassified, where $n$ is the data dimension. Using our general result about Levy instance spaces, we first recover as special case some of the previously proved results about the existence of adversarial examples. However, many more Levy families are known (e.g., product distribution under the Hamming distance) for which we immediately obtain new attacks that find adversarial examples of distance $O(\sqrt n)$. Finally, we show that concentration of measure for product spaces implies the existence of forms of ""poisoning"" attacks in which the adversary tampers with the training data with the goal of degrading the classifier. In particular, we show that for any learning algorithm that uses $m$ training examples, there is an adversary who can increase the probability of any ""bad property"" (e.g., failing on a particular test instance) that initially happens with non-negligible probability to $\approx 1$ by substituting only $\tilde{O}(\sqrt m)$ of the examples with other (still correctly labeled) examples.",[],[],"['Saeed Mahloujifar', 'Dimitrios I. Diochnos', 'Mohammad Mahmoody']","['University of Virginia', 'University of Virginia', 'University of Virginia']",[]
https://arxiv.org/abs/1812.02425,Security,MEAL: Multi-Model Ensemble via Adversarial Learning.,"Often the best performing deep neural models are ensembles of multiple base-level networks. Unfortunately, the space required to store these many networks, and the time required to execute them at test-time, prohibits their use in applications where test sets are large (e.g., ImageNet). In this paper, we present a method for compressing large, complex trained ensembles into a single network, where knowledge from a variety of trained deep neural networks (DNNs) is distilled and transferred to a single DNN. In order to distill diverse knowledge from different trained (teacher) models, we propose to use adversarial-based learning strategy where we define a block-wise training loss to guide and optimize the predefined student network to recover the knowledge in teacher models, and to promote the discriminator network to distinguish teacher vs. student features simultaneously. The proposed ensemble method (MEAL) of transferring distilled knowledge with adversarial learning exhibits three important advantages: (1) the student network that learns the distilled knowledge with discriminators is optimized better than the original model; (2) fast inference is realized by a single forward pass, while the performance is even better than traditional ensembles from multi-original models; (3) the student network can learn the distilled knowledge from a teacher model that has arbitrary structures. Extensive experiments on CIFAR-10/100, SVHN and ImageNet datasets demonstrate the effectiveness of our MEAL method. On ImageNet, our ResNet-50 based MEAL achieves top-1/5 21.79%/5.99% val error, which outperforms the original model by 2.06%/1.14%. Code and models are available at: this https URL",[],[],"['Zhiqiang Shen', 'Zhankui He', 'Xiangyang Xue']","['Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China and Beckman Institute, University of Illinois at Urbana-Champaign, IL', 'School of Data Science, Fudan University, Shanghai, China', 'Shanghai Key Laboratory of Intelligent Information Processing, School of Computer Science, Fudan University, Shanghai, China']","['China', 'China', 'China']"
https://arxiv.org/abs/1712.06924,Security,Safe Policy Improvement with Baseline Bootstrapping in Factored Environments.,"This paper considers Safe Policy Improvement (SPI) in Batch Reinforcement Learning (Batch RL): from a fixed dataset and without direct access to the true environment, train a policy that is guaranteed to perform at least as well as the baseline policy used to collect the data. Our approach, called SPI with Baseline Bootstrapping (SPIBB), is inspired by the knows-what-it-knows paradigm: it bootstraps the trained policy with the baseline when the uncertainty is high. Our first algorithm, $\Pi_b$-SPIBB, comes with SPI theoretical guarantees. We also implement a variant, $\Pi_{\leq b}$-SPIBB, that is even more efficient in practice. We apply our algorithms to a motivational stochastic gridworld domain and further demonstrate on randomly generated MDPs the superiority of SPIBB with respect to existing algorithms, not only in safety but also in mean performance. Finally, we implement a model-free version of SPIBB and show its benefits on a navigation task with deep RL implementation called SPIBB-DQN, which is, to the best of our knowledge, the first RL algorithm relying on a neural network representation able to train efficiently and reliably from batch data, without any interaction with the environment.",[],[],"['Romain Laroche', 'Paul Trichelair', 'Rémi Tachet des Combes']","['Delft University of Technology, The Netherlands', 'Delft University of Technology, The Netherlands']","['Netherlands', 'Netherlands']"
https://arxiv.org/abs/1905.01281,Security,Predicting Urban Dispersal Events: A Two-Stage Framework through Deep Survival Analysis on Mobility Data.,"Urban dispersal events are processes where an unusually large number of people leave the same area in a short period. Early prediction of dispersal events is important in mitigating congestion and safety risks and making better dispatching decisions for taxi and ride-sharing fleets. Existing work mostly focuses on predicting taxi demand in the near future by learning patterns from historical data. However, they fail in case of abnormality because dispersal events with abnormally high demand are non-repetitive and violate common assumptions such as smoothness in demand change over time. Instead, in this paper we argue that dispersal events follow a complex pattern of trips and other related features in the past, which can be used to predict such events. Therefore, we formulate the dispersal event prediction problem as a survival analysis problem. We propose a two-stage framework (DILSA), where a deep learning model combined with survival analysis is developed to predict the probability of a dispersal event and its demand volume. We conduct extensive case studies and experiments on the NYC Yellow taxi dataset from 2014-2016. Results show that DILSA can predict events in the next 5 hours with F1-score of 0.7 and with average time error of 18 minutes. It is orders of magnitude better than the state-ofthe-art deep learning approaches for taxi demand prediction.",[],[],"['Amin Vahedian', 'Xun Zhou', 'Ling Tong', 'W. Nick Street', 'Yanhua Li']",[],[]
https://arxiv.org/abs/2009.08559,Security,How Does Knowledge of the AUC Constrain the Set of Possible Ground-Truth Labelings?,"Membership Inference Attacks exploit the vulnerabilities of exposing models trained on customer data to queries by an adversary. In a recently proposed implementation of an auditing tool for measuring privacy leakage from sensitive datasets, more refined aggregates like the Log-Loss scores are exposed for simulating inference attacks as well as to assess the total privacy leakage based on the adversary's predictions. In this paper, we prove that this additional information enables the adversary to infer the membership of any number of datapoints with full accuracy in a single query, causing complete membership privacy breach. Our approach obviates any attack model training or access to side knowledge with the adversary. Moreover, our algorithms are agnostic to the model under attack and hence, enable perfect membership inference even for models that do not memorize or overfit. In particular, our observations provide insight into the extent of information leakage from statistical aggregates and how they can be exploited.",[],[],"['Abhinav Aggarwal', 'Zekun Xu', 'Oluwaseyi Feyisetan', 'Nathanael Teissier']","['Department of Computer Science, Worcester Polytechnic Institute, Worcester, MA']",[]
https://arxiv.org/abs/2004.09579,Security,Weighted Oblique Decision Trees.,"Increasing the penetration of variable generation has a substantial effect on the operational reliability of power systems. The higher level of uncertainty that stems from this variability makes it more difficult to determine whether a given operating condition will be secure or insecure. Data-driven techniques provide a promising way to identify security rules that can be embedded in economic dispatch model to keep power system operating states secure. This paper proposes using a sparse weighted oblique decision tree to learn accurate, understandable, and embeddable security rules that are linear and can be extracted as sparse matrices using a recursive algorithm. These matrices can then be easily embedded as security constraints in power system economic dispatch calculations using the Big-M method. Tests on several large datasets with high renewable energy penetration demonstrate the effectiveness of the proposed method. In particular, the sparse weighted oblique decision tree outperforms the state-of-art weighted oblique decision tree while keeping the security rules simple. When embedded in the economic dispatch, these rules significantly increase the percentage of secure states and reduce the average solution time.",[],[],"['Qingchun Hou', 'Ning Zhang', 'Daniel S. Kirschen', 'Ershun Du', 'Yaohua Cheng', 'Chongqing Kang']",[],[]
https://arxiv.org/abs/1810.11783,Security,RecurJac: An Efficient Recursive Algorithm for Bounding Jacobian Matrix of Neural Networks and Its Applications.,"The Jacobian matrix (or the gradient for single-output networks) is directly related to many important properties of neural networks, such as the function landscape, stationary points, (local) Lipschitz constants and robustness to adversarial attacks. In this paper, we propose a recursive algorithm, RecurJac, to compute both upper and lower bounds for each element in the Jacobian matrix of a neural network with respect to network's input, and the network can contain a wide range of activation functions. As a byproduct, we can efficiently obtain a (local) Lipschitz constant, which plays a crucial role in neural network robustness verification, as well as the training stability of GANs. Experiments show that (local) Lipschitz constants produced by our method is of better quality than previous approaches, thus providing better robustness verification results. Our algorithm has polynomial time complexity, and its computation time is reasonable even for relatively large networks. Additionally, we use our bounds of Jacobian matrix to characterize the landscape of the neural network, for example, to determine whether there exist stationary points in a local neighborhood. Source code available at \url{this http URL}.",[],[],"['Huan Zhang', 'Pengchuan Zhang', 'Cho-Jui Hsieh']","['UCLA', 'Microsoft Research AI', 'UCLA']",[]
https://arxiv.org/abs/1810.03806,Security,The Adversarial Attack and Detection under the Fisher Information Metric.,"Many deep learning models are vulnerable to the adversarial attack, i.e., imperceptible but intentionally-designed perturbations to the input can cause incorrect output of the networks. In this paper, using information geometry, we provide a reasonable explanation for the vulnerability of deep learning models. By considering the data space as a non-linear space with the Fisher information metric induced from a neural network, we first propose an adversarial attack algorithm termed one-step spectral attack (OSSA). The method is described by a constrained quadratic form of the Fisher information matrix, where the optimal adversarial perturbation is given by the first eigenvector, and the model vulnerability is reflected by the eigenvalues. The larger an eigenvalue is, the more vulnerable the model is to be attacked by the corresponding eigenvector. Taking advantage of the property, we also propose an adversarial detection method with the eigenvalues serving as characteristics. Both our attack and detection algorithms are numerically optimized to work efficiently on large datasets. Our evaluations show superior performance compared with other methods, implying that the Fisher information is a promising approach to investigate the adversarial attacks and defenses.",[],[],"['Chenxiao Zhao', 'P. Thomas Fletcher', 'Mixue Yu', 'Yaxin Peng', 'Guixu Zhang', 'Chaomin Shen']",[],[]
https://arxiv.org/abs/1811.08929,Security,Self-Adversarially Learned Bayesian Sampling.,"Scalable Bayesian sampling is playing an important role in modern machine learning, especially in the fast-developed unsupervised-(deep)-learning models. While tremendous progresses have been achieved via scalable Bayesian sampling such as stochastic gradient MCMC (SG-MCMC) and Stein variational gradient descent (SVGD), the generated samples are typically highly correlated. Moreover, their sample-generation processes are often criticized to be inefficient. In this paper, we propose a novel self-adversarial learning framework that automatically learns a conditional generator to mimic the behavior of a Markov kernel (transition kernel). High-quality samples can be efficiently generated by direct forward passes though a learned generator. Most importantly, the learning process adopts a self-learning paradigm, requiring no information on existing Markov kernels, e.g., knowledge of how to draw samples from them. Specifically, our framework learns to use current samples, either from the generator or pre-provided training data, to update the generator such that the generated samples progressively approach a target distribution, thus it is called self-learning. Experiments on both synthetic and real datasets verify advantages of our framework, outperforming related methods in terms of both sampling efficiency and sample quality.",[],[],"['Yang Zhao', 'Jianyi Zhang', 'Changyou Chen']","['State University of New York at Buffalo', 'Fudan University', 'State University of New York at Buffalo']",[]
https://arxiv.org/abs/1907.09708,Security,Understanding VAEs in Fisher-Shannon Plane.,"Graph structured data provide two-fold information: graph structures and node attributes. Numerous graph-based algorithms rely on both information to achieve success in supervised tasks, such as node classification and link prediction. However, node attributes could be missing or incomplete, which significantly deteriorates the performance. The task of node attribute generation aims to generate attributes for those nodes whose attributes are completely unobserved. This task benefits many real-world problems like profiling, node classification and graph data augmentation. To tackle this task, we propose a deep adversarial learning based method to generate node attributes; called node attribute neural generator (NANG). NANG learns a unifying latent representation which is shared by both node attributes and graph structures and can be translated to different modalities. We thus use this latent representation as a bridge to convert information from one modality to another. We further introduce practical applications to quantify the performance of node attribute generation. Extensive experiments are conducted on four real-world datasets and the empirical results show that node attributes generated by the proposed method are high-qualitative and beneficial to other applications. The datasets and codes are available online.",[],[],"['Xu Chen', 'Siheng Chen', 'Huangjie Zheng', 'Jiangchao Yao', 'Kenan Cui', 'Ya Zhang', 'Ivor W. Tsang']","['Cooperative Medianet Innovation Center, Shanghai Jiao Tong University', 'Cooperative Medianet Innovation Center, Shanghai Jiao Tong University and University of Technology Sydney', 'Cooperative Medianet Innovation Center, Shanghai Jiao Tong University', 'University of Technology Sydney', 'Cooperative Medianet Innovation Center, Shanghai Jiao Tong University']",[]
https://arxiv.org/abs/1902.08832,Security,Re-Evaluating ADEM: A Deeper Look at Scoring Dialogue Responses.,"Automatically evaluating the quality of dialogue responses for unstructured domains is a challenging problem. ADEM(Lowe et al. 2017) formulated the automatic evaluation of dialogue systems as a learning problem and showed that such a model was able to predict responses which correlate significantly with human judgements, both at utterance and system level. Their system was shown to have beaten word-overlap metrics such as BLEU with large margins. We start with the question of whether an adversary can game the ADEM model. We design a battery of targeted attacks at the neural network based ADEM evaluation system and show that automatic evaluation of dialogue systems still has a long way to go. ADEM can get confused with a variation as simple as reversing the word order in the text! We report experiments on several such adversarial scenarios that draw out counterintuitive scores on the dialogue responses. We take a systematic look at the scoring function proposed by ADEM and connect it to linear system theory to predict the shortcomings evident in the system. We also devise an attack that can fool such a system to rate a response generation system as favorable. Finally, we allude to future research directions of using the adversarial attacks to design a truly automated dialogue evaluation system.",[],[],"['Ananya B. Sai', 'Mithun Das Gupta', 'Mitesh M. Khapra', 'Mukundhan Srinivasan']","['Department of Computer Science and Engineering, Indian Institute of Technology, Madras and Robert Bosch Center for Data Sciences and AI (RBC-DS AI), Indian Institute of Technology, Madras and NVIDIA, India', 'Microsoft, India', 'Department of Computer Science and Engineering, Indian Institute of Technology, Madras and Robert Bosch Center for Data Sciences and AI (RBC-DS AI), Indian Institute of Technology, Madras', 'NVIDIA, India']","['India', 'India', 'India', 'India']"
https://arxiv.org/abs/1812.05407,Security,Abstractive Text Summarization by Incorporating Reader Comments.,"In neural abstractive summarization field, conventional sequence-to-sequence based models often suffer from summarizing the wrong aspect of the document with respect to the main aspect. To tackle this problem, we propose the task of reader-aware abstractive summary generation, which utilizes the reader comments to help the model produce better summary about the main aspect. Unlike traditional abstractive summarization task, reader-aware summarization confronts two main challenges: (1) Comments are informal and noisy; (2) jointly modeling the news document and the reader comments is challenging. To tackle the above challenges, we design an adversarial learning model named reader-aware summary generator (RASG), which consists of four components: (1) a sequence-to-sequence based summary generator; (2) a reader attention module capturing the reader focused aspects; (3) a supervisor modeling the semantic gap between the generated summary and reader focused aspects; (4) a goal tracker producing the goal for each generation step. The supervisor and the goal tacker are used to guide the training of our framework in an adversarial manner. Extensive experiments are conducted on our large-scale real-world text summarization dataset, and the results show that RASG achieves the state-of-the-art performance in terms of both automatic metrics and human evaluations. The experimental results also demonstrate the effectiveness of each module in our framework. We release our large-scale dataset for further research.",[],[],"['Shen Gao', 'Xiuying Chen', 'Piji Li', 'Zhaochun Ren', 'Lidong Bing', 'Dongyan Zhao', 'Rui Yan']",[],[]
https://arxiv.org/abs/2105.09045,Security,Improving Hypernymy Prediction via Taxonomy Enhanced Adversarial Learning.,"Deep neural networks such as BERT have made great progress in relation classification. Although they can achieve good performance, it is still a question of concern whether these models recognize the directionality of relations, especially when they may lack interpretability. To explore the question, a novel evaluation task, called Relation Direction Recognition (RDR), is proposed to explore whether models learn the directionality of relations. Three metrics for RDR are introduced to measure the degree to which models recognize the directionality of relations. Several state-of-the-art models are evaluated on RDR. Experimental results on a real-world dataset indicate that there are clear gaps among them in recognizing the directionality of relations, even though these models obtain similar performance in the traditional metric (e.g. Macro-F1). Finally, some suggestions are discussed to enhance models to recognize the directionality of relations from the perspective of model design or training.",[],[],"['Shengfei Lyu', 'Xingyu Wu', 'Jinlong Li', 'Qiuju Chen', 'Huanhuan Chen']","['School of Computer Science and Software Engineering, East China Normal University', 'School of Computer Science and Software Engineering, East China Normal University', 'School of Data Science and Engineering, East China Normal University']","['China', 'China', 'China']"
https://arxiv.org/abs/2106.14611,Security,A Deep Reinforcement Learning Based Multi-Step Coarse to Fine Question Answering (MSCQA) System.,"Most of the existing spoken language understanding systems can perform only semantic frame parsing based on a single-round user query. They cannot take users' feedback to update/add/remove slot values through multiround interactions with users. In this paper, we introduce a novel multi-step spoken language understanding system based on adversarial learning that can leverage the multiround user's feedback to update slot values. We perform two experiments on the benchmark ATIS dataset and demonstrate that the new system can improve parsing performance by at least $2.5\%$ in terms of F1, with only one round of feedback. The improvement becomes even larger when the number of feedback rounds increases. Furthermore, we also compare the new system with state-of-the-art dialogue state tracking systems and demonstrate that the new interactive system can perform better on multiround spoken language understanding tasks in terms of slot- and sentence-level accuracy.",[],[],"['Yu Wang', 'Yilin Shen', 'Hongxia Jin']","['Samsung Research America', 'Samsung Research America']",[]
https://arxiv.org/abs/1904.03830,Security,Temporal Planning with Temporal Metric Trajectory Constraints.,"This paper investigates a hybrid compositional approach to optimal mission planning for multi-rotor Unmanned Aerial Vehicles (UAVs). We consider a time critical search and rescue scenario with two quadrotors in a constrained environment. Metric Temporal Logic (MTL) is used to formally describe the task specifications. In order to capture the various modes of UAV operation, we utilize a hybrid model for the system with linearized dynamics around different operating points. We divide the mission into several sub-tasks by exploiting the invariant nature of various task specifications i.e., the mutual independence of safety and timing constraints along the way, and the different modes (i,e., dynamics) of the robot. For each sub-task, we translate the MTL formulae into linear constraints, and solve the associated optimal control problem for desired path using a Mixed Integer Linear Program (MILP) solver. The complete path is constructed by the composition of individual optimal sub-paths. We show that the resulting trajectory satisfies the task specifications, and the proposed approach leads to significant reduction in computational complexity of the problem, making it possible to implement in real-time.",[],[],"['Usman A. Fiaz', 'John S. Baras']","['Fondazione Bruno Kessler, Trento, Italy', 'Fondazione Bruno Kessler, Trento, Italy']","['Italy', 'Italy']"
https://arxiv.org/abs/2102.05289,Security,Robustness Guarantees for Bayesian Inference with Gaussian Processes.,"We consider adversarial training of deep neural networks through the lens of Bayesian learning, and present a principled framework for adversarial training of Bayesian Neural Networks (BNNs) with certifiable guarantees. We rely on techniques from constraint relaxation of non-convex optimisation problems and modify the standard cross-entropy error model to enforce posterior robustness to worst-case perturbations in $\epsilon$-balls around input points. We illustrate how the resulting framework can be combined with methods commonly employed for approximate inference of BNNs. In an empirical investigation, we demonstrate that the presented approach enables training of certifiably robust models on MNIST, FashionMNIST and CIFAR-10 and can also be beneficial for uncertainty calibration. Our method is the first to directly train certifiable BNNs, thus facilitating their deployment in safety-critical applications.",[],[],"['Matthew Wicker', 'Luca Laurenti', 'Andrea Patane', 'Zhoutong Chen', 'Zheng Zhang', 'Marta Kwiatkowska']","['Microsoft Research Cambridge', 'University of Oxford', 'University of Oxford', 'University of Oxford']",[]
https://arxiv.org/abs/2303.03757,Security,Improving Full-Body Pose Estimation from a Small Sensor Set Using Artificial Neural Networks and a Kalman Filter.,"Inertial sensors are widely utilized in smartphones, drones, robots, and IoT devices, playing a crucial role in enabling ubiquitous and reliable localization. Inertial sensor-based positioning is essential in various applications, including personal navigation, location-based security, and human-device interaction. However, low-cost MEMS inertial sensors' measurements are inevitably corrupted by various error sources, leading to unbounded drifts when integrated doubly in traditional inertial navigation algorithms, subjecting inertial positioning to the problem of error drifts. In recent years, with the rapid increase in sensor data and computational power, deep learning techniques have been developed, sparking significant research into addressing the problem of inertial positioning. Relevant literature in this field spans across mobile computing, robotics, and machine learning. In this article, we provide a comprehensive review of deep learning-based inertial positioning and its applications in tracking pedestrians, drones, vehicles, and robots. We connect efforts from different fields and discuss how deep learning can be applied to address issues such as sensor calibration, positioning error drift reduction, and multi-sensor fusion. This article aims to attract readers from various backgrounds, including researchers and practitioners interested in the potential of deep learning-based techniques to solve inertial positioning problems. Our review demonstrates the exciting possibilities that deep learning brings to the table and provides a roadmap for future research in this field.",[],[],"['Changhao Chen', 'Xianfei Pan']","['Department of Biomedical Signals & Systems, Technical Medical Centre, University of Twente, Enschede, The Netherlands', 'Xsens Technologies B.V., Enschede, The Netherlands', 'Xsens Technologies B.V., Enschede, The Netherlands', 'Department of Biomedical Signals & Systems, Technical Medical Centre, University of Twente, Enschede, The Netherlands', 'Department of Biomedical Signals & Systems, Technical Medical Centre, University of Twente, Enschede, The Netherlands']","['Netherlands', 'Netherlands', 'Netherlands', 'Netherlands', 'Netherlands']"
https://arxiv.org/abs/1812.02576,Security,That's Mine! Learning Ownership Relations and Norms for Robots.,"The ability for autonomous agents to learn and conform to human norms is crucial for their safety and effectiveness in social environments. While recent work has led to frameworks for the representation and inference of simple social rules, research into norm learning remains at an exploratory stage. Here, we present a robotic system capable of representing, learning, and inferring ownership relations and norms. Ownership is represented as a graph of probabilistic relations between objects and their owners, along with a database of predicate-based norms that constrain the actions permissible on owned objects. To learn these norms and relations, our system integrates (i) a novel incremental norm learning algorithm capable of both one-shot learning and induction from specific examples, (ii) Bayesian inference of ownership relations in response to apparent rule violations, and (iii) percept-based prediction of an object's likely owners. Through a series of simulated and real-world experiments, we demonstrate the competence and flexibility of the system in performing object manipulation tasks that require a variety of norms to be followed, laying the groundwork for future research into the acquisition and application of social norms.",[],[],"['Zhi-Xuan Tan', 'Jake Brawer', 'Brian Scassellati']","['Department of Computer Science, Yale University, New Haven, CT and A*STAR Artificial Intelligence Initiative, Agency for Science, Technology and Research (A*STAR), Singapore', 'Department of Computer Science, Yale University, New Haven, CT', 'A*STAR Artificial Intelligence Initiative, Agency for Science, Technology and Research (A*STAR), Singapore']","['Singapore', 'Singapore']"
https://arxiv.org/abs/1812.04128,Security,Probabilistic Model Checking of Robots Deployed in Extreme Environments.,"Robots are increasingly used to carry out critical missions in extreme environments that are hazardous for humans. This requires a high degree of operational autonomy under uncertain conditions, and poses new challenges for assuring the robot's safety and reliability. In this paper, we develop a framework for probabilistic model checking on a layered Markov model to verify the safety and reliability requirements of such robots, both at pre-mission stage and during runtime. Two novel estimators based on conservative Bayesian inference and imprecise probability model with sets of priors are introduced to learn the unknown transition parameters from operational data. We demonstrate our approach using data from a real-world deployment of unmanned underwater vehicles in extreme environments.",[],[],"['Xingyu Zhao', 'Valentin Robu', 'David Flynn', 'Fateme Dinmohammadi', 'Michael Fisher', 'Matt Webster']","['School of Engineering & Physical Sciences, Heriot-Watt University, Edinburgh, U.K.', 'School of Engineering & Physical Sciences, Heriot-Watt University, Edinburgh, U.K. and Center for Collective Intelligence, Massachusetts Institute of Technology, Cambridge MA', 'School of Engineering & Physical Sciences, Heriot-Watt University, Edinburgh, U.K.', 'School of Engineering & Physical Sciences, Heriot-Watt University, Edinburgh, U.K.', 'Department of Computer Science, University of Liverpool, Liverpool, U.K.', 'Department of Computer Science, University of Liverpool, Liverpool, U.K.']",[]
https://arxiv.org/abs/1811.06186,Security,GaitSet: Regarding Gait as a Set for Cross-View Gait Recognition.,"As a unique biometric feature that can be recognized at a distance, gait has broad applications in crime prevention, forensic identification and social security. To portray a gait, existing gait recognition methods utilize either a gait template, where temporal information is hard to preserve, or a gait sequence, which must keep unnecessary sequential constraints and thus loses the flexibility of gait recognition. In this paper we present a novel perspective, where a gait is regarded as a set consisting of independent frames. We propose a new network named GaitSet to learn identity information from the set. Based on the set perspective, our method is immune to permutation of frames, and can naturally integrate frames from different videos which have been filmed under different scenarios, such as diverse viewing angles, different clothes/carrying conditions. Experiments show that under normal walking conditions, our single-model method achieves an average rank-1 accuracy of 95.0% on the CASIA-B gait dataset and an 87.1% accuracy on the OU-MVLP gait dataset. These results represent new state-of-the-art recognition accuracy. On various complex scenarios, our model exhibits a significant level of robustness. It achieves accuracies of 87.2% and 70.4% on CASIA-B under bag-carrying and coat-wearing walking conditions, respectively. These outperform the existing best methods by a large margin. The method presented can also achieve a satisfactory accuracy with a small number of frames in a test sample, e.g., 82.5% on CASIA-B with only 7 frames. The source code has been released at this https URL.",[],[],"['Hanqing Chao', 'Yiwei He', 'Junping Zhang', 'Jianfeng Feng']",[],[]
https://arxiv.org/abs/1907.10843,Security,Learning Resolution-Invariant Deep Representations for Person Re-Identification.,"Person re-identification (re-ID) solves the task of matching images across cameras and is among the research topics in vision community. Since query images in real-world scenarios might suffer from resolution loss, how to solve the resolution mismatch problem during person re-ID becomes a practical problem. Instead of applying separate image super-resolution models, we propose a novel network architecture of Resolution Adaptation and re-Identification Network (RAIN) to solve cross-resolution person re-ID. Advancing the strategy of adversarial learning, we aim at extracting resolution-invariant representations for re-ID, while the proposed model is learned in an end-to-end training fashion. Our experiments confirm that the use of our model can recognize low-resolution query images, even if the resolution is not seen during training. Moreover, the extension of our model for semi-supervised re-ID further confirms the scalability of our proposed method for real-world scenarios and applications.",[],[],"['Yun-Chun Chen', 'Yu-Jhe Li', 'Xiaofei Du', 'Yu-Chiang Frank Wang']","['Department of Electrical Engineering, National Taiwan University', 'Department of Electrical Engineering, National Taiwan University and MOST Joint Research Center for AI Technology and All Vista Healthcare', 'Umbo Computer Vision', 'Department of Electrical Engineering, National Taiwan University and MOST Joint Research Center for AI Technology and All Vista Healthcare']",[]
https://arxiv.org/abs/1904.12181,Security,Non-Local Context Encoder: Robust Biomedical Image Segmentation against Adversarial Attacks.,"Recent progress in biomedical image segmentation based on deep convolutional neural networks (CNNs) has drawn much attention. However, its vulnerability towards adversarial samples cannot be overlooked. This paper is the first one that discovers that all the CNN-based state-of-the-art biomedical image segmentation models are sensitive to adversarial perturbations. This limits the deployment of these methods in safety-critical biomedical fields. In this paper, we discover that global spatial dependencies and global contextual information in a biomedical image can be exploited to defend against adversarial attacks. To this end, non-local context encoder (NLCE) is proposed to model short- and long range spatial dependencies and encode global contexts for strengthening feature activations by channel-wise attention. The NLCE modules enhance the robustness and accuracy of the non-local context encoding network (NLCEN), which learns robust enhanced pyramid feature representations with NLCE modules, and then integrates the information across different levels. Experiments on both lung and skin lesion segmentation datasets have demonstrated that NLCEN outperforms any other state-of-the-art biomedical image segmentation methods against adversarial attacks. In addition, NLCE modules can be applied to improve the robustness of other CNN-based biomedical image segmentation methods.",[],[],"['Xiang He', 'Sibei Yang', 'Guanbin Li?', 'Haofeng Li', 'Huiyou Chang', 'Yizhou Yu']","['School of Data and Computer Science, Sun Yat-sen University, China', 'The University of Hong Kong, Hong Kong', 'School of Data and Computer Science, Sun Yat-sen University, China', 'The University of Hong Kong, Hong Kong', 'School of Data and Computer Science, Sun Yat-sen University, China', 'Deepwise AI Lab, China']","['China', 'Hong Kong', 'China', 'Hong Kong', 'China', 'China']"
https://arxiv.org/abs/1711.06232,Security,A Novel Framework for Robustness Analysis of Visual QA Models.,"Deep neural networks have been playing an essential role in many computer vision tasks including Visual Question Answering (VQA). Until recently, the study of their accuracy was the main focus of research but now there is a trend toward assessing the robustness of these models against adversarial attacks by evaluating their tolerance to varying noise levels. In VQA, adversarial attacks can target the image and/or the proposed main question and yet there is a lack of proper analysis of the later. In this work, we propose a flexible framework that focuses on the language part of VQA that uses semantically relevant questions, dubbed basic questions, acting as controllable noise to evaluate the robustness of VQA models. We hypothesize that the level of noise is positively correlated to the similarity of a basic question to the main question. Hence, to apply noise on any given main question, we rank a pool of basic questions based on their similarity by casting this ranking task as a LASSO optimization problem. Then, we propose a novel robustness measure, R_score, and two large-scale basic question datasets (BQDs) in order to standardize robustness analysis for VQA models.",[],[],"['Jia-Hong Huang', 'Cuong Duc Dao', 'Modar Alfadly', 'Bernard Ghanem']","['King Abdullah University of Science and Technology and National Taiwan University', 'King Abdullah University of Science and Technology', 'King Abdullah University of Science and Technology', 'King Abdullah University of Science and Technology']",[]
https://arxiv.org/abs/2012.01884,Security,Attentive Temporal Pyramid Network for Dynamic Scene Classification.,"Predicting human motion behavior in a crowd is important for many applications, ranging from the natural navigation of autonomous vehicles to intelligent security systems of video surveillance. All the previous works model and predict the trajectory with a single resolution, which is rather inefficient and difficult to simultaneously exploit the long-range information (e.g., the destination of the trajectory), and the short-range information (e.g., the walking direction and speed at a certain time) of the motion behavior. In this paper, we propose a temporal pyramid network for pedestrian trajectory prediction through a squeeze modulation and a dilation modulation. Our hierarchical framework builds a feature pyramid with increasingly richer temporal information from top to bottom, which can better capture the motion behavior at various tempos. Furthermore, we propose a coarse-to-fine fusion strategy with multi-supervision. By progressively merging the top coarse features of global context to the bottom fine features of rich local context, our method can fully exploit both the long-range and short-range information of the trajectory. Experimental results on several benchmarks demonstrate the superiority of our method.",[],[],"['Rongqin Liang', 'Yuanman Li', 'Xia Li', 'yi tang', 'Jiantao Zhou', 'Wenbin Zou']","['School of Electronics and Information Engineering, Beihang University, Beijing, China and Lancaster University, Lancaster, UK and Key Laboratory of Advanced technology of Near Space Information System (Beihang University), Ministry of Industry and Information Technology of China and Beijing Advanced Innovation Center for Big Data-Based Precision Medicine', 'School of Electronics and Information Engineering, Beihang University, Beijing, China and Key Laboratory of Advanced technology of Near Space Information System (Beihang University), Ministry of Industry and Information Technology of China and Beijing Advanced Innovation Center for Big Data-Based Precision Medicine', 'School of Electronics and Information Engineering, Beihang University, Beijing, China and Key Laboratory of Advanced technology of Near Space Information System (Beihang University), Ministry of Industry and Information Technology of China and Beijing Advanced Innovation Center for Big Data-Based Precision Medicine', 'Lancaster University, Lancaster, LAI, UK']","['China', 'China', 'China', 'UK']"
https://arxiv.org/abs/1904.09146,Security,SuperVAE: Superpixelwise Variational Autoencoder for Salient Object Detection.,"As an essential problem in computer vision, salient object detection (SOD) has attracted an increasing amount of research attention over the years. Recent advances in SOD are predominantly led by deep learning-based solutions (named deep SOD). To enable in-depth understanding of deep SOD, in this paper, we provide a comprehensive survey covering various aspects, ranging from algorithm taxonomy to unsolved issues. In particular, we first review deep SOD algorithms from different perspectives, including network architecture, level of supervision, learning paradigm, and object-/instance-level detection. Following that, we summarize and analyze existing SOD datasets and evaluation metrics. Then, we benchmark a large group of representative SOD models, and provide detailed analyses of the comparison results. Moreover, we study the performance of SOD algorithms under different attribute settings, which has not been thoroughly explored previously, by constructing a novel SOD dataset with rich attribute annotations covering various salient object types, challenging factors, and scene categories. We further analyze, for the first time in the field, the robustness of SOD models to random input perturbations and adversarial attacks. We also look into the generalization and difficulty of existing SOD datasets. Finally, we discuss several open issues of SOD and outline future research directions.",[],[],"['Wenguan Wang', 'Qiuxia Lai', 'Huazhu Fu', 'Jianbing Shen', 'Haibin Ling', 'Ruigang Yang']","['State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China']","['China', 'China', 'China']"
https://arxiv.org/abs/2107.13114,Security,Meta Learning for Image Captioning.,"Image Captioning is a task that combines computer vision and natural language processing, where it aims to generate descriptive legends for images. It is a two-fold process relying on accurate image understanding and correct language understanding both syntactically and semantically. It is becoming increasingly difficult to keep up with the latest research and findings in the field of image captioning due to the growing amount of knowledge available on the topic. There is not, however, enough coverage of those findings in the available review papers. We perform in this paper a run-through of the current techniques, datasets, benchmarks and evaluation metrics used in image captioning. The current research on the field is mostly focused on deep learning-based methods, where attention mechanisms along with deep reinforcement and adversarial learning appear to be in the forefront of this research topic. In this paper, we review recent methodologies such as UpDown, OSCAR, VIVO, Meta Learning and a model that uses conditional generative adversarial nets. Although the GAN-based model achieves the highest score, UpDown represents an important basis for image captioning and OSCAR and VIVO are more useful as they use novel object captioning. This review paper serves as a roadmap for researchers to keep up to date with the latest contributions made in the field of image caption generation.",[],[],"['Ahmed Elhagry', 'Karima Kadaoui']","['School of Remote Sensing and Information Engineering, Wuhan University, China', 'School of Remote Sensing and Information Engineering, Wuhan University, China', 'Tencent Media Lab, Palo Alto, CA']","['China', 'China']"
https://arxiv.org/abs/1911.06968,Security,Distribution Consistency Based Covariance Metric Networks for Few-Shot Learning.,"This paper investigates a new challenging problem called defensive few-shot learning in order to learn a robust few-shot model against adversarial attacks. Simply applying the existing adversarial defense methods to few-shot learning cannot effectively solve this problem. This is because the commonly assumed sample-level distribution consistency between the training and test sets can no longer be met in the few-shot setting. To address this situation, we develop a general defensive few-shot learning (DFSL) framework to answer the following two key questions: (1) how to transfer adversarial defense knowledge from one sample distribution to another? (2) how to narrow the distribution gap between clean and adversarial examples under the few-shot setting? To answer the first question, we propose an episode-based adversarial training mechanism by assuming a task-level distribution consistency to better transfer the adversarial defense knowledge. As for the second question, within each few-shot task, we design two kinds of distribution consistency criteria to narrow the distribution gap between clean and adversarial examples from the feature-wise and prediction-wise perspectives, respectively. Extensive experiments demonstrate that the proposed framework can effectively make the existing few-shot models robust against adversarial attacks. Code is available at this https URL.",[],[],"['Wenbin Li', 'Lei Wang', 'Xingxing Zhang', 'Lei Qi', 'Jing Huo', 'Yang Gao', 'Jiebo Luo']","['National Key Laboratory for Novel Software Technology, Nanjing University, China', 'Northwestern Polytechnical University, China', 'National Key Laboratory for Novel Software Technology, Nanjing University, China', 'University of Wollongong, Australia', 'National Key Laboratory for Novel Software Technology, Nanjing University, China', 'University of Rochester']","['China', 'China', 'China', 'Australia', 'China']"
https://arxiv.org/abs/1903.01078,Security,Unsupervised Cross-Spectral Stereo Matching by Learning to Synthesize.,"Unsupervised cross-spectral stereo matching aims at recovering disparity given cross-spectral image pairs without any supervision in the form of ground truth disparity or depth. The estimated depth provides additional information complementary to individual semantic features, which can be helpful for other vision tasks such as tracking, recognition and detection. However, there are large appearance variations between images from different spectral bands, which is a challenge for cross-spectral stereo matching. Existing deep unsupervised stereo matching methods are sensitive to the appearance variations and do not perform well on cross-spectral data. We propose a novel unsupervised cross-spectral stereo matching framework based on image-to-image translation. First, a style adaptation network transforms images across different spectral bands by cycle consistency and adversarial learning, during which appearance variations are minimized. Then, a stereo matching network is trained with image pairs from the same spectra using view reconstruction loss. At last, the estimated disparity is utilized to supervise the spectral-translation network in an end-to-end way. Moreover, a novel style adaptation network F-cycleGAN is proposed to improve the robustness of spectral translation. Our method can tackle appearance variations and enhance the robustness of unsupervised cross-spectral stereo matching. Experimental results show that our method achieves good performance without using depth supervision or explicit semantic information.",[],[],"['Mingyang Liang', 'Xiaoyang Guo', 'Hongsheng Li', 'Xiaogang Wang', 'You Song']","['Beihang University, Beijing, China and Sense Time Research', 'The Chinese University of Hong Kong, Hong Kong, China', 'The Chinese University of Hong Kong, Hong Kong, China', 'The Chinese University of Hong Kong, Hong Kong, China', 'Beihang University, Beijing, China']","['China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/1903.02155,Security,Semantic Adversarial Network with Multi-Scale Pyramid Attention for Video Classification.,"Two-stream architecture have shown strong performance in video classification task. The key idea is to learn spatio-temporal features by fusing convolutional networks spatially and temporally. However, there are some problems within such architecture. First, it relies on optical flow to model temporal information, which are often expensive to compute and store. Second, it has limited ability to capture details and local context information for video data. Third, it lacks explicit semantic guidance that greatly decrease the classification performance. In this paper, we proposed a new two-stream based deep framework for video classification to discover spatial and temporal information only from RGB frames, moreover, the multi-scale pyramid attention (MPA) layer and the semantic adversarial learning (SAL) module is introduced and integrated in our framework. The MPA enables the network capturing global and local feature to generate a comprehensive representation for video, and the SAL can make this representation gradually approximate to the real video semantics in an adversarial manner. Experimental results on two public benchmarks demonstrate our proposed methods achieves state-of-the-art results on standard video datasets.",[],[],"['De Xie', 'Cheng Deng', 'Hao Wang', 'Chao Li', 'Dapeng Tao']","[""School of Electronic Engineering, Xidian University, Xi'an, China"", ""School of Electronic Engineering, Xidian University, Xi'an, China"", ""School of Electronic Engineering, Xidian University, Xi'an, China"", ""School of Electronic Engineering, Xidian University, Xi'an, China"", 'School of Information Science and Engineering, Yunnan University, Kunming, China']","['China', 'China', 'China', 'China', 'China']"
https://arxiv.org/abs/2201.07417,Security,Remote Management of Boundary Protection Devices with Information Restrictions.,"Advances of emerging Information and Communications Technology (ICT) technologies push the boundaries of what is possible and open up new markets for innovative ICT products and services. The adoption of ICT products and systems with security properties depends on consumers' confidence and markets' trust in the security functionalities and whether the assurance measures applied to these products meet the inherent security requirements. Such confidence and trust are primarily gained through the rigorous development of security requirements, validation criteria, evaluation, and certification. Common Criteria for Information Technology Security Evaluation (often referred to as Common Criteria or CC) is an international standard (ISO/IEC 15408) for cyber security certification. In this paper, we conduct a systematic review of the CC standards and its adoptions. Adoption barriers of the CC are also investigated based on the analysis of current trends in security evaluation. Specifically, we share the experiences and lessons gained through the recent Development of Australian Cyber Criteria Assessment (DACCA) project that promotes the CC among stakeholders in ICT security products related to specification, development, evaluation, certification and approval, procurement, and deployment. Best practices on developing Protection Profiles, recommendations, and future directions for trusted cybersecurity advancement are presented.",[],[],"['Nan Sun', 'Chang-Tsun Li', 'Hin Chan', 'Ba Dung Le', 'MD Zahidul Islam', 'Leo Yu Zhang', 'MD Rafiqul Islam', 'Warren Armstrong']","['BBN Technologies, Cambridge, MA', 'BBN Technologies, Cambridge, MA', 'BBN Technologies, Cambridge, MA', 'Air Force Research Lab, Rome, New York']",[]
https://arxiv.org/abs/2008.08753,Security,Logistic Regression on Homomorphic Encrypted Data at Scale.,"Logistic Regression (LR) is the most widely used machine learning model in industry for its efficiency, robustness, and interpretability. Due to the problem of data isolation and the requirement of high model performance, many applications in industry call for building a secure and efficient LR model for multiple parties. Most existing work uses either Homomorphic Encryption (HE) or Secret Sharing (SS) to build secure LR. HE based methods can deal with high-dimensional sparse features, but they incur potential security risks. SS based methods have provable security, but they have efficiency issue under high-dimensional sparse features. In this paper, we first present CAESAR, which combines HE and SS to build secure large-scale sparse logistic regression model and achieves both efficiency and security. We then present the distributed implementation of CAESAR for scalability requirement. We have deployed CAESAR in a risk control task and conducted comprehensive experiments. Our experimental results show that CAESAR improves the state-of-the-art model by around 130 times.",[],[],"['Chaochao Chen', 'Jun Zhou', 'Li Wang', 'Xibin Wu', 'Wenjing Fang', 'Jin Tan', 'Lei Wang', 'Alex X. Liu', 'Hao Wang', 'Cheng Hong']","['Seoul National University, Seoul, South Korea', 'Seoul National University, Seoul, South Korea', 'Seoul National University, Seoul, South Korea', 'University of Illinois, Urbana-Champaign, IL']",[]
https://arxiv.org/abs/1810.04755,Security,Leveraging Textual Specifications for Grammar-Based Fuzzing of Network Protocols.,Grammar-based fuzzing is a technique used to find software vulnerabilities by injecting well-formed inputs generated following rules that encode application semantics. Most grammar-based fuzzers for network protocols rely on human experts to manually specify these rules. In this work we study automated learning of protocol rules from textual specifications (i.e. RFCs). We evaluate the automatically extracted protocol rules by applying them to a state-of-the-art fuzzer for transport protocols and show that it leads to a smaller number of test cases while finding the same attacks as the system that uses manually specified rules.,[],[],"['Samuel Jero', 'Maria Leonor Pacheco', 'Dan Goldwasser', 'Cristina Nita-Rotaru']","['Purdue University', 'Purdue University', 'Purdue University', 'Northeastern University']",[]
https://arxiv.org/abs/2205.11740,Security,VPDS: An AI-Based Automated Vehicle Occupancy and Violation Detection System.,"The workplace influences the safety, health, and productivity of workers at multiple levels. To protect and promote total worker health, smart hardware, and software tools have emerged for the identification, elimination, substitution, and control of occupational hazards. Wearable devices enable constant monitoring of individual workers and the environment, whereas connected worker solutions provide contextual information and decision support. Here, the recent trends in commercial workplace technologies to monitor and manage occupational risks, injuries, accidents, and diseases are reviewed. Workplace safety wearables for safe lifting, ergonomics, hazard identification, sleep monitoring, fatigue management, and heat and cold stress are discussed. Examples of workplace productivity wearables for asset tracking, augmented reality, gesture and motion control, brain wave sensing, and work stress management are given. Workplace health wearables designed for work-related musculoskeletal disorders, functional movement disorders, respiratory hazards, cardiovascular health, outdoor sun exposure, and continuous glucose monitoring are shown. Connected worker platforms are discussed with information about the architecture, system modules, intelligent operations, and industry applications. Predictive analytics provide contextual information about occupational safety risks, resource allocation, equipment failure, and predictive maintenance. Altogether, these examples highlight the ground-level benefits of real-time visibility about frontline workers, work environment, distributed assets, workforce efficiency, and safety compliance",[],[],"['Vishal Patel', 'Austin Chesmore', 'Christopher M. Legner', 'Santosh Pandey']","['School of Computing, University of Utah', 'Computer Vision and Media Analytics Group, Conduent Labs', 'Indian Institute of Technology Kharagpur', 'Computer Vision and Media Analytics Group, Conduent Labs', 'Computer Vision and Media Analytics Group, Conduent Labs', 'Computer Vision and Media Analytics Group, Conduent Labs', 'Computer Vision and Media Analytics Group, Conduent Labs']",['India']
https://arxiv.org/abs/1902.00563,Security,Forecasting Intra-Hour Imbalances in Electric Power Systems.,"Keeping the electricity production in balance with the actual demand is becoming a difficult and expensive task in spite of an involvement of experienced human operators. This is due to the increasing complexity of the electric power grid system with the intermittent renewable production as one of the contributors. A beforehand information about an occurring imbalance can help the transmission system operator to adjust the production plans, and thus ensure a high security of supply by reducing the use of costly balancing reserves, and consequently reduce undesirable fluctuations of the 50 Hz power system frequency. In this paper, we introduce the relatively new problem of an intra-hour imbalance forecasting for the transmission system operator (TSO). We focus on the use case of the Norwegian TSO, Statnett. We present a complementary imbalance forecasting tool that is able to support the TSO in determining the trend of future imbalances, and show the potential to proactively alleviate imbalances with a higher accuracy compared to the contemporary solution.",[],[],"['Tárik S. Salem', 'Karan Kathuria', 'Heri Ramampiaro', 'Helge Langseth']","['Norwegian University of Science and Technology (NTNU), Department of Computer Science, Trondheim, Norway', 'Optimeering AS, Oslo, Norway', 'Norwegian University of Science and Technology (NTNU), Department of Computer Science, Trondheim, Norway', 'Norwegian University of Science and Technology (NTNU), Department of Computer Science, Trondheim, Norway']","['Norway', 'Norway', 'Norway', 'Norway']"
https://arxiv.org/abs/1805.10820,Security,Meaningful Explanations of Black Box AI Decision Systems.,"The recent years have witnessed the rise of accurate but obscure decision systems which hide the logic of their internal decision processes to the users. The lack of explanations for the decisions of black box systems is a key ethical issue, and a limitation to the adoption of machine learning components in socially sensitive and safety-critical contexts. %Therefore, we need explanations that reveals the reasons why a predictor takes a certain decision. In this paper we focus on the problem of black box outcome explanation, i.e., explaining the reasons of the decision taken on a specific instance. We propose LORE, an agnostic method able to provide interpretable and faithful explanations. LORE first leans a local interpretable predictor on a synthetic neighborhood generated by a genetic algorithm. Then it derives from the logic of the local interpretable predictor a meaningful explanation consisting of: a decision rule, which explains the reasons of the decision; and a set of counterfactual rules, suggesting the changes in the instance's features that lead to a different outcome. Wide experiments show that LORE outperforms existing methods and baselines both in the quality of explanations and in the accuracy in mimicking the black box.",[],[],"['Riccardo Guidotti', 'Anna Monreale', 'Salvatore Ruggieri', 'Dino Pedreschi', 'Franco Turini', 'Fosca Giannotti']","['University of Pisa', 'ISTI-CNR Pisa, Italy', 'ISTI-CNR Pisa, Italy', 'University of Pisa', 'University of Pisa', 'University of Pisa']","['Italy', 'Italy']"
https://arxiv.org/abs/2006.10679,Security,Borda Count in Collective Decision Making: A Summary of Recent Results.,"Deep Neural Networks (DNNs) are often criticized for being susceptible to adversarial attacks. Most successful defense strategies adopt adversarial training or random input transformations that typically require retraining or fine-tuning the model to achieve reasonable performance. In this work, our investigations of intermediate representations of a pre-trained DNN lead to an interesting discovery pointing to intrinsic robustness to adversarial attacks. We find that we can learn a generative classifier by statistically characterizing the neural response of an intermediate layer to clean training samples. The predictions of multiple such intermediate-layer based classifiers, when aggregated, show unexpected robustness to adversarial attacks. Specifically, we devise an ensemble of these generative classifiers that rank-aggregates their predictions via a Borda count-based consensus. Our proposed approach uses a subset of the clean training data and a pre-trained model, and yet is agnostic to network architectures or the adversarial attack generation method. We show extensive experiments to establish that our defense strategy achieves state-of-the-art performance on the ImageNet validation set.",[],[],"['Lokender Tiwari', 'Anish Madan', 'Saket Anand', 'Subhashis Banerjee']","['Institut für Informatik Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany']",['Germany']
https://arxiv.org/abs/1911.02621,Security,Reinforcement Learning under Threats.,"Machine learning models have made many decision support systems to be faster, more accurate, and more efficient. However, applications of machine learning in network security face a more disproportionate threat of active adversarial attacks compared to other domains. This is because machine learning applications in network security such as malware detection, intrusion detection, and spam filtering are by themselves adversarial in nature. In what could be considered an arm's race between attackers and defenders, adversaries constantly probe machine learning systems with inputs that are explicitly designed to bypass the system and induce a wrong prediction. In this survey, we first provide a taxonomy of machine learning techniques, tasks, and depth. We then introduce a classification of machine learning in network security applications. Next, we examine various adversarial attacks against machine learning in network security and introduce two classification approaches for adversarial attacks in network security. First, we classify adversarial attacks in network security based on a taxonomy of network security applications. Secondly, we categorize adversarial attacks in network security into a problem space vs feature space dimensional classification model. We then analyze the various defenses against adversarial attacks on machine learning-based network security applications. We conclude by introducing an adversarial risk grid map and evaluating several existing adversarial attacks against machine learning in network security using the risk grid map. We also identify where each attack classification resides within the adversarial risk grid map.",[],[],"['Olakunle Ibitoye', 'Rana Abou-Khamis', 'Mohamed el Shehaby', 'Ashraf Matrawy', 'M. Omair Shafiq']","['ICMAT-CSIC', 'ICMAT-CSIC', 'ICMAT-CSIC']",[]
https://arxiv.org/abs/2004.08833,Security,Meta-Path Augmented Response Generation.,"Knowledge graph-based dialogue systems are capable of generating more informative responses and can implement sophisticated reasoning mechanisms. However, these models do not take into account the sparseness and incompleteness of knowledge graph (KG)and current dialogue models cannot be applied to dynamic KG. This paper proposes a dynamic Knowledge graph-based dialogue generation method with improved adversarial Meta-Learning (KDAD). KDAD formulates dynamic knowledge triples as a problem of adversarial attack and incorporates the objective of quickly adapting to dynamic knowledge-aware dialogue generation. We train a knowledge graph-based dialog model with improved ADML using minimal training samples. The model can initialize the parameters and adapt to previous unseen knowledge so that training can be quickly completed based on only a few knowledge triples. We show that our model significantly outperforms other baselines. We evaluate and demonstrate that our method adapts extremely fast and well to dynamic knowledge graph-based dialogue generation.",[],[],"['Hongcai Xu', 'Junpeng Bao', 'Gaojie Zhang']","['Department of Computing, The Hong Kong Polytechnic University', 'Department of Computing, The Hong Kong Polytechnic University']","['Hong Kong', 'Hong Kong']"
https://arxiv.org/abs/1909.04779,Security,Towards Better Accuracy and Robustness with Localized Adversarial Training.,"Today's state-of-the-art image classifiers fail to correctly classify carefully manipulated adversarial images. In this work, we develop a new, localized adversarial attack that generates adversarial examples by imperceptibly altering the backgrounds of normal images. We first use this attack to highlight the unnecessary sensitivity of neural networks to changes in the background of an image, then use it as part of a new training technique: localized adversarial training. By including locally adversarial images in the training set, we are able to create a classifier that suffers less loss than a non-adversarially trained counterpart model on both natural and adversarial inputs. The evaluation of our localized adversarial training algorithm on MNIST and CIFAR-10 datasets shows decreased accuracy loss on natural images, and increased robustness against adversarial inputs.",[],[],"['Eitan Rothberg', 'Tingting Chen', 'Luo Jie', 'Hao Ji']","['Computer Science and Engineering, Ohio State University, Columbus, Ohio', 'Computer Science, California State Polytechnic University, Pomona, California', 'Computer Science, California State Polytechnic University, Pomona, California']",[]
https://arxiv.org/abs/1812.04599,Security,Adversarial Framing for Image and Video Classification.,"Neural networks are prone to adversarial attacks. In general, such attacks deteriorate the quality of the input by either slightly modifying most of its pixels, or by occluding it with a patch. In this paper, we propose a method that keeps the image unchanged and only adds an adversarial framing on the border of the image. We show empirically that our method is able to successfully attack state-of-the-art methods on both image and video classification problems. Notably, the proposed method results in a universal attack which is very fast at test time. Source code can be found at this https URL .",[],[],"['Konrad Zolna', 'Michal Zajac', 'Negar Rostamzadeh', 'Pedro O. Pinheiro']","['Jagiellonian University, Kraków, Poland and Nomagic, Warsaw, Poland', 'Jagiellonian University, Kraków, Poland and Element AI, Montréal, Canada', 'Element AI, Montréal, Canada', 'Element AI, Montréal, Canada']","['Poland', 'Canada', 'Canada', 'Canada']"