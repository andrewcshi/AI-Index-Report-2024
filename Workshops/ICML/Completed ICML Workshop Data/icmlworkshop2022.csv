link,category,title,abstract,keywords,ccs_concepts,author_names,author_affiliations,author_countries
https://icml.cc/virtual/2022/workshop/13453,Transparency & Explainability,Responsible Decision Making in Dynamic Environments,"With the widespread use of sophisticated machine learning models in sensitive applications, understanding their decision-making has become an essential task. Models trained on tabular data have witnessed significant progress in explanations of their underlying decision making processes by virtue of having a small number of discrete features. However, applying these methods to high-dimensional inputs such as images is not a trivial task. Images are composed of pixels at an atomic level and do not carry any interpretability by themselves. In this work, we seek to use annotated high-level interpretable features of images to provide explanations. We leverage the Shapley value framework from Game Theory, which has garnered wide acceptance in general XAI problems. By developing a pipeline to generate counterfactuals and subsequently using it to estimate Shapley values, we obtain contrastive and interpretable explanations with strong axiomatic guarantees.",[],[],"['Virginie Do', 'Thorsten Joachims', 'Alessandro Lazaric', 'Joelle Pineau', 'Matteo Pirotta', 'Harsh Satija', 'Nicolas Usunier']",[],[]
https://icml.cc/virtual/2022/workshop/13477,Fairness & Bias,DataPerf: Benchmarking Data for Data-Centric AI,"Machine learning research has long focused on models rather than datasets, and prominent datasets are used for common ML tasks without regard to the breadth, difficulty, and faithfulness of the underlying problems. Neglecting the fundamental importance of data has given rise to inaccuracy, bias, and fragility in real-world applications, and research is hindered by saturation across existing dataset benchmarks. In response, we present DataPerf, a community-led benchmark suite for evaluating ML datasets and data-centric algorithms. We aim to foster innovation in data-centric AI through competition, comparability, and reproducibility. We enable the ML community to iterate on datasets, instead of just architectures, and we provide an open, online platform with multiple rounds of challenges to support this iterative development. The first iteration of DataPerf contains five benchmarks covering a wide spectrum of data-centric techniques, tasks, and modalities in vision, speech, acquisition, debugging, and diffusion prompting, and we support hosting new contributed benchmarks from the community. The benchmarks, online evaluation platform, and baseline implementations are open source, and the MLCommons Association will maintain DataPerf to ensure long-term benefits to academia and industry.",[],[],"['Lora Aroyo', 'Newsha Ardalani', 'Colby Banbury', 'Gregory Diamos', 'William Gaviria Rojas', 'Tzu-Sheng Kuo', 'Mark Mazumder', 'Peter Mattson', 'Praveen Paritosh']",[],[]
https://icml.cc/virtual/2022/workshop/13470,Fairness & Bias,AI for Agent-Based Modelling (AI4ABM),"Calibrating agent-based models (ABMs) to data is among the most fundamental requirements to ensure the model fulfils its desired purpose. In recent years, simulation-based inference methods have emerged as powerful tools for performing this task when the model likelihood function is intractable, as is often the case for ABMs. In some real-world use cases of ABMs, both the observed data and the ABM output consist of the agents' states and their interactions over time. In such cases, there is a tension between the desire to make full use of the rich information content of such granular data on the one hand, and the need to reduce the dimensionality of the data to prevent difficulties associated with high-dimensional learning tasks on the other. A possible resolution is to construct lower-dimensional time-series through the use of summary statistics describing the macrostate of the system at each time point. However, a poor choice of summary statistics can result in an unacceptable loss of information from the original dataset, dramatically reducing the quality of the resulting calibration. In this work, we instead propose to learn parameter posteriors associated with granular microdata directly using temporal graph neural networks. We will demonstrate that such an approach offers highly compelling inductive biases for Bayesian inference using the raw ABM microstates as output.",[],[],"['Christian Schroeder', 'Yang Zhang', 'Anisoara Calinescu', 'Dylan Radovic', 'Prateek Gupta', 'Jakob Foerster']",[],[]
https://icml.cc/virtual/2022/workshop/13471,Fairness & Bias,Updatable Machine Learning,"It has been shown that deep neural networks are prone to overfitting on biased training data. Towards addressing this issue, meta-learning employs a meta model for correcting the training bias. Despite the promising performances, super slow training is currently the bottleneck in the meta learning approaches. In this paper, we introduce a novel Faster Meta Update Strategy (FaMUS) to replace the most expensive step in the meta gradient computation with a faster layer-wise approximation. We empirically find that FaMUS yields not only a reasonably accurate but also a low-variance approximation of the meta gradient. We conduct extensive experiments to verify the proposed method on two tasks. We show our method is able to save two-thirds of the training time while still maintaining the comparable or achieving even better generalization performance. In particular, our method achieves the state-of-the-art performance on both synthetic and realistic noisy labels, and obtains promising performance on long-tailed recognition on standard benchmarks.",[],[],"['Ayush Sekhari', 'Gautam Kamath', 'Jayadev Acharya']",[],[]
https://icml.cc/virtual/2022/workshop/13449,Fairness & Bias,2nd Workshop on Interpretable Machine Learning in Healthcare (IMLH),"Observation is an essential tool for understanding and studying human behavior and mental states. However, coding human behavior is a time-consuming, expensive task, in which reliability can be difficult to achieve and bias is a risk. Machine learning (ML) methods offer ways to improve reliability, decrease cost, and scale up behavioral coding for application in clinical and research settings. Here, we use computer vision to derive behavioral codes or concepts of a gold standard behavioral rating system, offering familiar interpretation for mental health professionals. Features were extracted from videos of clinical diagnostic interviews of children and adolescents with and without obsessive-compulsive disorder. Our computationally-derived ratings were comparable to human expert ratings for negative emotions, activity-level/arousal and anxiety. For the attention and positive affect concepts, our ML ratings performed reasonably. However, results for gaze and vocalization indicate a need for improved data quality or additional data modalities.",[],[],"['Ramin Zabih', 'S. Kevin Zhou', 'Weina Jin', 'Yuyin Zhou', 'Ipek Oguz', 'Xiaoxiao Li', 'Yifan Peng', 'Zongwei Zhou', 'Yucheng Tang']",[],[]
https://icml.cc/virtual/2022/workshop/13448,Privacy & Data Governance,Theory and Practice of Differential Privacy,"Bayesian inference has great promise for the privacy-preserving analysis of sensitive data, as posterior sampling automatically preserves differential privacy, an algorithmic notion of data privacy, under certain conditions (Dimitrakakis et al., 2014; Wang et al., 2015). While this one posterior sample (OPS) approach elegantly provides privacy ""for free,"" it is data inefficient in the sense of asymptotic relative efficiency (ARE). We show that a simple alternative based on the Laplace mechanism, the workhorse of differential privacy, is as asymptotically efficient as non-private posterior inference, under general assumptions. This technique also has practical advantages including efficient use of the privacy budget for MCMC. We demonstrate the practicality of our approach on a time-series analysis of sensitive military records from the Afghanistan and Iraq wars disclosed by the Wikileaks organization.",[],[],"['Gautam Kamath', 'Audra McMillan']",[],[]
https://icml.cc/virtual/2022/workshop/13464,Security,ICML 2022 Workshop on Computational Biology,"The approval success rate of drug candidates is very low with the majority of failure due to safety and efficacy. Increasingly available high dimensional information on targets, drug molecules and indications provides an opportunity for ML methods to integrate multiple data modalities and better predict clinically promising drug targets. Notably, drug targets with human genetics evidence are shown to have better odds to succeed. However, a recent tensor factorization-based approach found that additional information on targets and indications might not necessarily improve the predictive accuracy. Here we revisit this approach by integrating different types of human genetics evidence collated from publicly available sources to support each target-indication pair. We use Bayesian tensor factorization to show that models incorporating all available human genetics evidence (rare disease, gene burden, common disease) modestly improves the clinical outcome prediction over models using single line of genetics evidence. We provide additional insight into the relative predictive power of different types of human genetics evidence for predicting the success of clinical outcomes.",[],[],"['Cassandra Burdziak', 'Yubin Xie', 'Amine Remita', 'Mauricio Tec', 'Achille O R Nazaret', 'Pascal Notin', 'Mafalda Dias', 'Steffan Paul', 'Cameron Park', ""Dana Pe'er"", 'Debora Marks', 'Alexander Anderson', 'Elham Azizi', 'Abdoulaye Banir√© Diallo', 'Wesley Tansey', 'Julia Vogt', 'Sandhya Prabhakaran']",[],[]
https://icml.cc/virtual/2022/workshop/13458,Security,ICML workshop on Machine Learning for Cybersecurity (ICML-ML4Cyber),"In this paper we explore cyber security defence, through the unification of a novel cyber security simulator with models for (causal) decision-making through optimisation. Particular attention is paid to a recently published approach: dynamic causal Bayesian optimisation (DCBO). We propose that DCBO can act as a blue agent when provided with a view of a simulated network and a causal model of how a red agent spreads within that network. To investigate how DCBO can perform optimal interventions on host nodes, in order to reduce the cost of intrusions caused by the red agent. Through this we demonstrate a complete cyber-simulation system, which we use to generate observational data for DCBO and provide numerical quantitative results which lay the foundations for future work in this space.",[],[],"['John Emanuello', 'Andy Applebaum', 'William Arbaugh', 'Jack Davidson', 'Joseph Edappully', 'H. Howie Huang', 'Andrew Golczynski', 'Nicole Nichols', 'Tejas Patel', 'Ahmad Ridley', 'Vance Wong']",[],[]
https://icml.cc/virtual/2022/workshop/13473,Security,Workshop on Formal Verification of Machine Learning,"Recent works have tried to increase the verifiability of adversarially trained networks by running the attacks over domains larger than the original perturbations and adding various regularization terms to the objective. However, these algorithms either underperform or require complex and expensive stage-wise training procedures, hindering their practical applicability. We present IBP-R, a novel verified training algorithm that is both simple and effective. IBP-R induces network verifiability by coupling adversarial attacks on enlarged domains with a regularization term, based on inexpensive interval bound propagation, that minimizes the gap between the non-convex verification problem and its approximations. By leveraging recent branch-and-bound frameworks, we show that IBP-R obtains state-of-the-art verified robustness-accuracy trade-offs for small perturbations on CIFAR-10 while training significantly faster than relevant previous work. Additionally, we present UPB, a novel branching strategy that, relying on a simple heuristic based on $\beta$-CROWN, reduces the cost of state-of-the-art branching algorithms while yielding splits of comparable quality.",[],[],"['Huan Zhang', 'Leslie Rice', 'Kaidi Xu', 'aditi raghunathan', 'Wan-Yi Lin', 'Cho-Jui Hsieh', 'Clark Barrett', 'Martin Vechev', 'Zico Kolter']",[],[]
https://icml.cc/virtual/2022/workshop/13465,Security,Principles of Distribution Shift (PODS),"Estimating the test performance of software AI-based medical devices under distribution shifts is crucial for evaluating the safety, efficiency, and usability prior to clinical deployment. Due to the nature of regulated medical device software and the difficulty in acquiring large amounts of labeled medical datasets, we consider the task of predicting the test accuracy of an arbitrary black-box model on an unlabeled target domain without modification to the original training process or any distributional assumptions of the original source data (i.e. we treat the model as a ""black-box"" and only use the predicted output responses). We propose a ""black-box"" test estimation technique based on conformal prediction and evaluate it against other methods on three medical imaging datasets (mammography, dermatology, and histopathology) under several clinically relevant types of distribution shift (institution, hardware scanner, atlas, hospital). We hope that by promoting practical and effective estimation techniques for black-box models, manufacturers of medical devices will develop more standardized and realistic evaluation procedures to improve the robustness and trustworthiness of clinical AI tools.",[],[],"['Elan Rosenfeld', 'Saurabh Garg', 'Shibani Santurkar', 'Jamie Morgenstern', 'Hossein Mobahi', 'Zachary Lipton', 'Andrej Risteski']",[],[]