link,category,title,abstract,keywords,ccs_concepts,author_names,author_affiliations,author_countries
https://icml.cc/virtual/2023/workshop/21484,Fairness & Bias,Localized Learning: Decentralized Model Updates via Non-Global Objectives,"The federated learning (FL) framework trains a machine learning model using decentralized data stored at edge client devices by periodically aggregating locally trained models. Popular optimization algorithms of FL use vanilla (stochastic) gradient descent for both local updates at clients and global updates at the aggregating server. Recently, adaptive optimization methods such as AdaGrad have been studied for server updates. However, the effect of using adaptive optimization methods for local updates at clients is not yet understood. We show in both theory and practice that while local adaptive methods can accelerate convergence, they can cause a non-vanishing solution bias, where the final converged solution may be different from the stationary point of the global objective function. We propose correction techniques to overcome this inconsistency and complement the local adaptive methods for FL. Extensive experiments on realistic federated training tasks show that the proposed algorithms can achieve faster convergence and higher test accuracy than the baselines without local adaptivity.",[],[],"['David I. Inouye', 'Mengye Ren', 'Mateusz Malinowski', 'Michael Eickenberg', 'Gao Huang', 'Eugene Belilovsky']",[],[]
https://icml.cc/virtual/2023/workshop/21491,Fairness & Bias,Artificial Intelligence & Human Computer Interaction,"In medicine, patients can obtain real benefits from a sham treatment. These benefits are known as the placebo effect. We report two experiments (Experiment I: N=369; Experiment II: N=100) demonstrating a placebo effect in adaptive interfaces. Participants were asked to solve word puzzles while being supported by no system or an adaptive AI interface. All participants experienced the same word puzzle difficulty and had no support from an AI throughout the experiments. Our results showed that the belief of receiving adaptive AI support increases expectations regarding the participant's own task performance, sustained after interaction. These expectations were positively correlated to performance, as indicated by the number of solved word puzzles. We integrate our findings into technological acceptance theories and discuss implications for the future assessment of AI-based user interfaces and novel technologies. We argue that system descriptions can elicit placebo effects through user expectations biasing the results of user-centered studies.",[],[],"['Yang Li', 'Ranjay Krishna', 'Helena Vasconcelos', 'Bryan Wang', 'Forrest Huang']",[],[]
https://icml.cc/virtual/2023/workshop/21473,Privacy & Data Governance,"Federated Learning and Analytics in Practice: Algorithms, Systems, Applications, and Opportunities","Federated heavy-hitter analytics involves the identification of the most frequent items within distributed data. Existing methods for this task often encounter challenges such as compromising privacy or sacrificing utility. To address these issues, we introduce a novel privacy-preserving algorithm that exploits the hierarchical structure to discover local and global heavy hitters in non-IID data by utilizing perturbation and similarity techniques. We conduct extensive evaluations on both synthetic and real datasets to validate the effectiveness of our approach. We also present FedCampus, a demonstration application to showcase the capabilities of our algorithm in analyzing population statistics.",[],[],"['Zheng Xu', 'Peter Kairouz', 'Bo Li', 'Tian Li', 'John Nguyen', 'Jianyu Wang', 'Shiqiang Wang', 'Ayfer Ozgur']",[],[]
https://icml.cc/virtual/2023/workshop/21485,Privacy & Data Governance,"Neural Conversational AI Workshop - Whatâ€™s left to TEACH (Trustworthy, Enhanced, Adaptable, Capable and Human-centric) chatbots?","Artificial intelligence (AI) has the potential to transform education with its power of uncovering insights from massive data about student learning patterns. However, ethical and trustworthy concerns of AI have been raised but are unsolved. Prominent ethical issues in high school AI education include data privacy, information leakage, abusive language, and fairness. This paper describes technological components that were built to address ethical and trustworthy concerns in a multi-modal collaborative platform (called ALLURE chatbot) for high school students to collaborate with AI to solve the Rubik's cube. In data privacy, we want to ensure that the informed consent of children, parents, and teachers, is at the center of any data that is managed. Since children are involved, language, whether textual, audio, or visual, is acceptable both from users and AI and the system can steer interaction away from dangerous situations. In information management, we also want to ensure that the system, while learning to improve over time, does not leak information about users from one group to another.",[],[],"['Hyundong Cho', 'Nayeon Lee', 'Ninareh Mehrabi', 'Hsuan Su', 'Jonathan May', 'Hung-yi Lee', 'Ahmad Beirami']",[],[]
https://icml.cc/virtual/2023/workshop/21487,Security,2nd ICML Workshop on New Frontiers in Adversarial Machine Learning,"Previous research has shown that federated learning (FL) systems are exposed to an array of security risks. Despite the proposal of several defensive strategies, they tend to be non-adaptive and specific to certain types of attacks, rendering them ineffective against unpredictable or adaptive threats. This work models adversarial federated learning as a Bayesian Stackelberg Markov game (BSMG) to capture the defender's incomplete information of various attack types. We propose meta-Stackelberg learning (meta-SL), a provably efficient meta-learning algorithm, to solve the equilibrium strategy in BSMG, leading to an adaptable FL defense. We demonstrate that meta-SL converges to the first-order $\varepsilon$-equilibrium point in $O(\varepsilon^{-2})$ gradient iterations, with $O(\varepsilon^{-4})$ samples needed per iteration, matching the state of the art. Empirical evidence indicates that our meta-Stackelberg framework performs exceptionally well against potent model poisoning and backdoor attacks of an uncertain nature.",[],[],"['Sijia Liu', 'Pin-Yu Chen', 'Dongxiao Zhu', 'Eric Wong', 'Kathrin Grosse', 'Baharan Mirzasoleiman', 'Sanmi Koyejo']",[],[]
https://icml.cc/virtual/2023/workshop/21469,Security,Structured Probabilistic Inference and Generative Modeling,"Understanding the macroscopic characteristics of biological complexes demands precision and specificity in statistical ensemble modeling. One of the primary challenges in this domain lies in sampling from particular subsets of the state-space, driven either by existing structural knowledge or specific areas of interest within the state-space. We propose a method that enables sampling from distributions that rigorously adhere to arbitrary sets of geometric constraints in Euclidean spaces. This is achieved by integrating a constraint projection operator within the well-regarded architecture of Denoising Diffusion Probabilistic Models, a framework founded in generative modeling and probabilistic inference. The significance of this work becomes apparent, for instance, in the context of deep learning-based drug design, where it is imperative to maintain specific molecular profile interactions to realize the desired therapeutic outcomes and guarantee safety.",[],[],"['Dinghuai Zhang', 'Yuanqi Du', 'Chenlin Meng', 'Shawn Tan', 'Yingzhen Li', 'Max Welling', 'Yoshua Bengio']",[],[]