




<!DOCTYPE html>
<html lang="en" style="scroll-padding-top: 70px;"> 

<head>
    
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src="/static/virtual/js/virtual.js"></script>
    <meta name="google-site-verification" content="0jwPnVXIAk4FvFdT37dwMmd-kjHF86e5DKwvqlStUW0">

    <title>ICLR 2018</title>
    
    <link rel="stylesheet" href="/static/core/css/core.css" type="text/css">
    <link rel="stylesheet" href="/static/virtual/css/virtual.css" type="text/css">
     <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">

    <link rel="stylesheet" href="/static/core/css/custom.css" type="text/css">
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-select@1.14.0-beta2/dist/css/bootstrap-select.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
      "tex2jax": {
        "inlineMath": [["$","$"], ["\\(","\\)"]],
        "displayMath": [["\\[","\\]"]],
        "processEscapes": true
      }
    }
    );
    </script>

    <script type="text/javascript" async
            src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>

    <!--This script keeps local links inside the web app rather than opening them
in Safari, and has nothing to do with editing or Aloha.-->

<script type="text/javascript">
	(function(document,navigator,standalone) {
		// prevents links from apps from opening in mobile safari
		// this javascript must be the first script in your <head>
		if ((standalone in navigator) && navigator[standalone]) {
			var curnode, location=document.location, stop=/^(a|html)$/i;
			document.addEventListener('click', function(e) {
				curnode=e.target;
				while (!(stop).test(curnode.nodeName)) {
					curnode=curnode.parentNode;
				}
				// Conditions to do this only on links to your own app
				// if you want all links, use if('href' in curnode) instead.
				if(
					'href' in curnode && // is a link
					(chref=curnode.href).replace(location.href,'').indexOf('#') && // is not an anchor
					(	!(/^[a-z\+\.\-]+:/i).test(chref) ||                       // either does not have a proper scheme (relative links)
						chref.indexOf(location.protocol+'//'+location.host)===0 ) // or is in the same protocol and domain
				) {
					e.preventDefault();
					location.href = curnode.href;
				}
			},false);
		}
	})(document,window.navigator,'standalone');
</script>        

<!-- This style sets the minimum size of a blurb to 260 px unless there is a
template context variable blurb_min_height that sets it otherwise. If blurbs
aren't all about the same size, they don't flow well when the window is
resized.-->


<style>
/*This is here rather that in a .css file for a reason.*/
    @media screen and (min-width: 767px) {
        .blurb {
            min-height:260px;
        }
    }
</style>
    

<script src="https://code.jquery.com/jquery-3.6.1.min.js"
        integrity="sha256-o88AwQnZB+VDvE9tvIXrMQaPlFFSUTR+nldQm1LuPXQ=" crossorigin="anonymous"></script>
</script>

<script>
    if (typeof jQuery === 'undefined') {
        var script = document.createElement('script');
        script.type = 'text/javascript';
        script.src = "/static/core/js/jquery-3.6.1.min.js";
        document.head.appendChild(script);
    }
</script>


    <script>
        var $ = jQuery;
        /*Store a pointer to jquery2, so I can reference it later.  Aloha loads jquery 1.7 and much
        of bootstrap 3 is not compatible. This comment is deprecated. */
    </script>

    
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-kenU1KFdBIe4zVF0s0G1M5b4hcpxyD9F7jL+jjXkk+Q2h455rYXK/7HAuoJl+0I4" crossorigin="anonymous"></script>

    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>
    <script src="https://kit.fontawesome.com/be44b7e05d.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap-select@1.14.0-beta3/dist/js/bootstrap-select.min.js"></script>


    <style>
        body {
            font-family: Exo;}
    </style>







     

    <meta charset="utf-8">
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">
    <link href="https://fonts.googleapis.com/css2?family=Exo:wght@400;700&family=Lato:wght@400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/static/virtual/css/virtual.css">
    <script src="https://d3js.org/d3.v5.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/corejs-typeahead/1.3.1/typeahead.bundle.min.js" integrity="sha512-lEb9Vp/rkl9g2E/LdHIMFTqz21+LA79f84gqP75fbimHqVTu6483JG1AwJlWLLQ8ezTehty78fObKupq3HSHPQ==" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/moment@2.24.0/min/moment.min.js"
            integrity="sha256-4iQZ6BVL4qNKlQ27TExEhBN1HFPvAvAMbFavKKosSWQ="
            crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script>
    <script src="/static/core/js/ajax-csrf-snippet.js" type="text/javascript"></script>
    <script src="/static/virtual/js/virtual.js"></script>
    

    <title>ICLR 2018</title>
    

    <title>ICLR 2018 Workshops</title>
    <style>
        body {
            background: #f6f6f6;
        }
    </style>

</head>

<body>




<div class="noprint">
    
        
<!--Navbar start-->
<nav id="id_navbar" class="navbar navbar-expand-sm navbar-dark" style="background-color:#212529">
        <div class="container-fluid">
            <div><a class="navbar-brand" href="/"><img src="/static/core/img/iclr-navbar-logo.svg" height="40px"></a></div>


            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                    data-bs-target="#navbarToggler1" aria-controls="navbarSupportedContent"
                    aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarToggler1">
                <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                    
    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            ICLR
        </a>
        <ul class="dropdown-menu dropdown-menu-dark">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/FAQ">
                    <span >
                        Help/FAQ
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Help/Contact">
                    <span >
                        Contact ICLR
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Downloads">
                    <span >
                        Downloads
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="https://blog.iclr.cc/">
                    <span >
                        ICLR Blog
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/public/CodeOfConduct">
                    <span >
                        Code of Conduct
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/public/PrivacyPolicy">
                    <span >
                        Privacy Policy
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Profile/create">
                    <span >
                        Create Profile
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/public/JournalToConference">
                    <span >
                        Journal To Conference Track
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/public/DiversityInclusion">
                    <span >
                        Diversity &amp; Inclusion
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="https://openreview.net/group?id=ICLR.cc">
                    <span >
                        Proceedings at OpenReview
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/FutureMeetings">
                    <span >
                        Future Meetings
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2024/Press?showtab=pass">
                    <span >
                        Press
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Sponsors/sponsorinfo">
                    <span >
                        Exhibitor Information
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="https://twitter.com/iclr_conf?ref_src=twsrc%5Etfw">
                    <span >
                        ICLR Twitter
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/About">
                    <span >
                        About ICLR
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/MyStuff">
                    <span >
                        My Stuff
                    </span>
                </a>
            </li>

        

    

    

                </ul>

                <form class="d-flex" role="search" action="/search">
                    <div class="input-group" role="search">
                        <input type="text" class="form-control" placeholder="Search" name="q"
                               value=""
                               aria-label="Search" aria-describedby="btnGroupAddon">
                        <div class="input-group-text btn-primary" id="btnGroupAddon">
                            <button style="border: none; background-color: transparent; padding: 0;" type="submit">
                                <i class="fa-solid fa-magnifying-glass" ></i>
                            </button>
                        </div>
                    </div>
                </form>
                &nbsp;
                
                    <a href="/accounts/login?nextp=/Conferences/2018 " class="navbar-brand"><span
                            class="fa-solid fa-right-to-bracket"></span> Login</a>
                

            </div>
        </div>
    </nav>
<!--Navbar end-->
    
</div><!--noprint div-->


<!--This holds the whole page including the navbar-->

<main id="main">
    <div class="container-fluid">
        <!--Navbar start-->

<div class="dropdown">
    <nav class="align-middle navbar navbar-expand-md mx-4 border border-3 border-top-0 rounded-bottom"
         style="min-height: 57px; background-color: #F6f6f6;">
        <div class="container-fluid">

            <button class="navbar-toggler" type="button" data-bs-toggle="collapse"
                    data-bs-target="#navbarToggler1141" aria-controls="navbarSupportedContent"
                    aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarToggler1141">
                <ul class="navbar-nav me-auto mb-lg-0">
                    


    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle border-3  btn btn-primary text-white p-1" style= "background-color: #070bff; font-size: 1.2 em;"
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Select Year: (2018)
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2024">2024
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2023">2023
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2022">2022
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2021">2021
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2020">2020
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2019">2019
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/Conferences/2018">2018
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/archive/www/2017.html">2017
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/archive/www/2016.html">2016
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/archive/www/2015.html">2015
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/archive/2014/">2014
                </a>
            </li>
        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item " >
                <a class="dropdown-item p-1"
                   href="/archive/2013/">2013
                </a>
            </li>
        

    

    

        </ul>
    </li>
    



    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/Dates">
                    <span >
                        Dates
                    </span>
                </a>
            </li>

        

    

    

    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Schedule
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/ScheduleOverview">
                    <span >
                        Schedule Overview
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/Schedule">
                    <span >
                        Full Schedule
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Calls
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/CallForPapers">
                    <span >
                        Call for Papers
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/CallForWorkshops">
                    <span >
                        Call for Workshops
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Attend
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/Hotels">
                    <span >
                        Hotels
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="https://www.tourismvancouver.com/iclr2018/">
                    <span >
                        Vancouver Tourism
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="http://www.cityrunningtours.com/vancouver/">
                    <span >
                        City Running Tours
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="http://digital.canadawide.com/i/810732-2017-2018">
                    <span >
                        Vancouver Virtual Guide
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Organization
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/Board">
                    <span >
                        ICLR Board
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/OrganizingCommittee">
                    <span >
                        Organizing Committee
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/OrganizingCommittee">
                    <span >
                        Best Reviewers
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/AreaChairs">
                    <span >
                        Area Chairs
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="">
                    <span >
                        About ICLR
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



    <li class="dropdown-item dropdown pe-3">
        <a class="nav-link dropdown-toggle  p-1" 
           href="#"
           role="button" data-bs-toggle="dropdown" aria-expanded="false">
            Students
        </a>
        <ul class="dropdown-menu">
            
    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/TravelApplication">
                    <span >
                        Travel Application
                    </span>
                </a>
            </li>

        

    

    
        <hr class="dropdown-divider" aria-hidden="true">
    

    
        
            <li class="dropdown-item  pe-2" >
                <a class="nav-link p-1"  href="/Conferences/2018/VolunteerApplication">
                    <span >
                        Volunteer Application
                    </span>
                </a>
            </li>

        

    

    

        </ul>
    </li>
    



                </ul>
            </div>
        </div>
    </nav>
</div>
    <!--Navbar end-->
    </div>
    <br><br>
    
<div class="container-fluid">

    

    

    <br>

        <div class="row">
            <div class="col-md-12"></div>
            <div class="title-centered" style="text-align:center">Workshops</div>
            
        </div>


    

        

        <div class="row">  
            <div class="col-sm-12">

                
                    <div style="max-width: 1500px; margin:auto; border">
                        <div class="grid-displaycards">

                                
                                    <div class="displaycards touchup-date" id="event-415">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/415">ShakeDrop regularization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yoshihiro Yamada &middot; Masakazu Iwamura &middot; Koichi Kise</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-415"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-415" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-415" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-415">
                Abstract <i id="caret-415" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-415">
    <div class="abstract-display">
        <p>This paper proposes a powerful regularization method named ShakeDrop regularization.
ShakeDrop is inspired by Shake-Shake regularization that decreases error rates by disturbing learning.
While Shake-Shake can be applied to only ResNeXt which has multiple branches, ShakeDrop can be applied to not only ResNeXt but also ResNet, and PyramidNet in a memory efficient way.
Important and interesting feature of ShakeDrop is that it strongly disturbs learning by multiplying even a negative factor to the output of a convolutional layer in the forward training pass.
ShakeDrop outperformed state-of-the-arts on CIFAR-10/100.
The full version of the paper including other experiments is available at https://arxiv.org/abs/1802.02375.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-401">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/401">Feature Incay for Representation Regularization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">YUHUI YUAN &middot; Kuiyuan Yang &middot; Jianyuan Guo &middot; Chao Zhang &middot; Jingdong Wang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-401"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-401" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-401" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-401">
                Abstract <i id="caret-401" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-401">
    <div class="abstract-display">
        <p>Softmax-based loss is widely used in deep learning for multi-class classification, where each class is represented by a weight vector and each sample is represented as a feature vector. Different from traditional learning algorithms where features are pre-defined and only weight vectors are tunable through training, feature vectors are also tunable as representation learning in deep learning. Thus we investigate how to improve the classification performance by better adjusting the features. One main observation is that elongating the feature norm of both correctly-classified and mis-classified feature vectors improves learning: (1) increasing the feature norm of correctly-classified examples induce smaller training loss; (2) increasing the feature norm of mis-classified examples can upweight the contribution from hard examples. Accordingly, we propose feature incay to regularize representation learning by encouraging larger feature norm. In contrast to weight decay which shrinks the weight norm, feature incay is proposed to stretch the feature norm. Extensive empirical results on MNIST, CIFAR10, CIFAR100 and LFW demonstrate the effectiveness of feature incay. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-414">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/414">Local Explanation Methods for Deep Neural Networks Lack Sensitivity to Parameter Values</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Julius Adebayo &middot; Justin Gilmer &middot; Ian Goodfellow &middot; Been Kim</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-414"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-414" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-414" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-414">
                Abstract <i id="caret-414" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-414">
    <div class="abstract-display">
        <p>Explaining the output of a complicated machine learning model like a deep neural network (DNN) is a central challenge in machine learning. Several proposed local explanation methods address this issue by identifying what dimensions of a single input are most responsible for a DNN's  output. The goal of this work is to assess the sensitivity of local explanations to DNN parameter values. Somewhat surprisingly, we find that DNNs with randomly-initialized weights produce explanations that are both visually and quantitatively similar to those produced by DNNs with learned weights. Our conjecture is that this phenomenon occurs because these explanations are dominated by the lower level features of a DNN, and that a DNN's architecture provides a strong prior which significantly affects the representations learned at these lower layers.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-404">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/404">STOCHASTIC GRADIENT LANGEVIN DYNAMICS THAT EXPLOIT NEURAL NETWORK  STRUCTURE</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zachary Nado &middot; Jasper Snoek &middot; Roger Grosse &middot; David Duvenaud &middot; James Martens &middot; Bowen Xu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-404"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-404" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-404" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-404">
                Abstract <i id="caret-404" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-404">
    <div class="abstract-display">
        <p>Tractable approximate Bayesian inference for deep neural networks remains challenging.  Stochastic Gradient Langevin Dynamics (SGLD) offers a tractable approximation to the gold standard of Hamiltonian Monte Carlo.  We improve on existing methods for SGLD by incorporating a recently-developed tractable approximation of the Fisher information, known as K-FAC, as a preconditioner.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-405">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/405">Towards Mixed-initiative generation of multi-channel sequential structure</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Anna Huang &middot; Sherol Chen &middot; Mark Nelson &middot; Douglas Eck</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-405"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-405" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-405" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-405">
                Abstract <i id="caret-405" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-405">
    <div class="abstract-display">
        <p>We argue for the benefit of designing deep generative models through a mixed-initiative, co-creative combination of deep learning algorithms and human specifications, focusing on multi-channel music composition.  Sequence models have shown convincing results in domains such as summarization and translation; however, longer-term structure remains a major challenge. Given lengthy inputs and outputs, deep generative systems still lack reliable representations of beginnings, middles, and ends, which are standard aspects of creating content in domains such as music composition. This paper aims to contribute a framework for mixed-initiative generation approaches that let humans both supply and control some of these aspects in deep generative models for music, and present a case study of Counterpoint by Convolutional Neural Network (CoCoNet). </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-407">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/407">Semi-Supervised Learning With GANs: Revisiting Manifold Regularization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Bruno Lecouat &middot; Chuan-Sheng Foo &middot; Houssam Zenati &middot; Vijay Chandrasekhar</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-407"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-407" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-407" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-407">
                Abstract <i id="caret-407" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-407">
    <div class="abstract-display">
        <p>GANS are powerful generative models that are able to model the manifold of
natural images. We leverage this property to perform manifold regularization by
approximating the Laplacian norm using a Monte Carlo approximation that is easily
computed with the GAN. When incorporated into the feature-matching GAN
of Salimans et al. (2016), we achieve state-of-the-art results for GAN-based semisupervised
learning on the CIFAR-10 dataset, with a method that is significantly
easier to implement than competing methods.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-410">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/410">Towards Specification-Directed Program Repair</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Richard Shin &middot; Illia Polosukhin &middot; Dawn Song</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-410"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-410" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-410" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-410">
                Abstract <i id="caret-410" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-410">
    <div class="abstract-display">
        <p>Several recent papers have developed neural network program synthesizers by using supervised learning over large sets of randomly generated programs and specifications.
In this paper, we investigate the feasibility of this approach for program repair: given a specification and a candidate program assumed similar to a correct program for the specification, synthesize a program which meets the specification. <br />
Working in the Karel domain with a dataset of synthetically generated candidates, we develop models that can make effective use of the extra information in candidate programs, achieving 40% error reduction compared to a baseline program synthesis model that only receives the specification and not a candidate program.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-429">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/429">A Language and Compiler View on Differentiable Programming</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Fei Wang &middot; Tiark Rompf</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-429"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-429" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-429" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-429">
                Abstract <i id="caret-429" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-429">
    <div class="abstract-display">
        <p>Current and emerging deep learning architectures call for an expressive high-level programming style with end-to-end differentiation and for a high-performance implementation at the same time. But the current generation of deep learning
frameworks either limits expressiveness and ease of use for increased performance (e.g., TensorFlow) or vice versa (e.g., PyTorch). In this paper we demonstrate that a “best of both worlds” approach is possible, based on multi-stage programming
and delimited continuations, two orthogonal ideas firmly rooted in programming languages research.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-573">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/573">Tree-to-tree Neural Networks for Program Translation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Xinyun Chen &middot; Chang Liu &middot; Dawn Song</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-573"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-573" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-573" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-573">
                Abstract <i id="caret-573" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-573">
    <div class="abstract-display">
        <p>Program translation is an important tool to migrate legacy code in one language into an ecosystem built in a different language. In this work, we are the first to consider employing deep neural networks toward tackling this problem. We observe that program translation is a modular procedure, in which a sub-tree of the source tree is translated into the corresponding target sub-tree at each step. To capture this intuition, we design a tree-to-tree neural network as an encoder-decoder architecture to translate a source tree into a target one. Meanwhile, we develop an attention mechanism for the tree-to-tree model, so that when the decoder expands one non-terminal in the target tree, the attention mechanism locates the corresponding sub-tree in the source tree to guide the expansion of the decoder. We evaluate the program translation capability of our tree-to-tree model against several state-of-the-art approaches. Compared against other neural translation models, we observe that our approach is consistently better than the baselines with a margin of up to 15 points. Further, our approach can improve the previous state-of-the-art program translation approaches by a margin of 20 points on the translation of real-world projects.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-560">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/560">Extending the Framework of Equilibrium Propagation to General Dynamics</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Benjamin Scellier &middot; Anirudh Goyal &middot; Jonathan Binas &middot; Thomas Mesnard &middot; Yoshua Bengio</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-560"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-560" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-560" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-560">
                Abstract <i id="caret-560" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-560">
    <div class="abstract-display">
        <p>The biological plausibility of the backpropagation algorithm has long been doubted by neuroscientists. Two major reasons are that neurons would need to send two different types of signal in the forward and backward phases, and that pairs of neurons would need to communicate through symmetric bidirectional connections.
We present a simple two-phase learning procedure for fixed point recurrent networks that addresses both these issues.
In our model, neurons perform leaky integration and synaptic weights are updated through a local mechanism.
Our learning method extends the framework of Equilibrium Propagation to general dynamics, relaxing the requirement of an energy function.
As a consequence of this generalization, the algorithm does not compute the true gradient of the objective function,
but rather approximates it at a precision which is proven to be directly related to the degree of symmetry of the feedforward and feedback weights.
We show experimentally that the intrinsic properties of the system lead to alignment of the feedforward and feedback weights, and that our algorithm optimizes the objective function.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-408">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/408">Predicting Embryo Morphokinetics in Videos with Late Fusion Nets &amp; Dynamic Decoders</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Nathan Ng &middot; Julian McAuley &middot; Julian Gingold &middot; Nina Desai &middot; Zachary Lipton</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-408"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-408" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-408" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-408">
                Abstract <i id="caret-408" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-408">
    <div class="abstract-display">
        <p>To optimize clinical outcomes, many fertility clinics select embryos strategically, based on how quickly they reach certain developmental milestones. This requires manually annotating time-lapse EmbryoScope videos with their corresponding morphokinetics, a time-consuming process that requires experienced embryologists. We propose late-fusion ConvNets with a dynamic programming-based decoder for automatically labeling these videos. Experiments address data extracted from EmbryoScope incubators at the Cleveland Clinic Foundation Fertility Center. We focus on 6 stages, demonstrating 87% per-frame accuracy.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-409">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/409">Differentiable Neural Network Architecture Search</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Richard Shin &middot; Charles Packer &middot; Dawn Song</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-409"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-409" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-409" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-409">
                Abstract <i id="caret-409" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-409">
    <div class="abstract-display">
        <p>The successes of deep learning in recent years has been fueled by the development
of innovative new neural network architectures. However, the design of a neural
network architecture remains a difficult problem, requiring significant human expertise
as well as computational resources. In this paper, we propose a method
for transforming a discrete neural network architecture space into a continuous
and differentiable form, which enables the use of standard gradient-based optimization
techniques for this problem, and allows us to learn the architecture and
the parameters simultaneously. We evaluate our methods on the Udacity steering
angle prediction dataset, and show that our method can discover architectures
with similar or better predictive accuracy but significantly fewer parameters and
smaller computational cost.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-442">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/442">Towards Provable Control for Unknown Linear Dynamical Systems</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Sanjeev Arora &middot; Elad Hazan &middot; Holden Lee &middot; Karan Singh &middot; Cyril Zhang &middot; Yi Zhang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-442"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-442" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-442" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-442">
                Abstract <i id="caret-442" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-442">
    <div class="abstract-display">
        <p>We study the control of symmetric linear dynamical systems with unknown dynamics and a hidden state. Using a recent spectral filtering technique for concisely representing such systems in a linear basis, we formulate optimal control in this setting as a convex program. This approach eliminates the need to solve the non-convex problem of explicit identification of the system and its latent state, and allows for provable optimality guarantees for the control signal. We give the first efficient algorithm for finding the optimal control signal with an arbitrary time horizon T, with sample complexity (number of training rollouts) polynomial only in log(T) and other relevant parameters.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-428">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/428">Stable and Effective Trainable Greedy Decoding for Sequence to Sequence Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yun Chen &middot; Kyunghyun Cho &middot; Sam Bowman &middot; Victor OK Li</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-428"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-428" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-428" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-428">
                Abstract <i id="caret-428" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-428">
    <div class="abstract-display">
        <p>We introduce a fast, general method to manipulate the behavior of the decoder in a sequence to sequence neural network model. We propose a small neural network actor that observes and manipulates the hidden state of a previously-trained decoder. We evaluate our model on the task of neural machine translation. In this task, we use beam search to decode sentences from the plain decoder for each training set input, rank them by BLEU score, and train the actor to encourage the decoder to generate the highest-BLEU output in a single greedy decoding operation without beam search. Experiments on several datasets and models show  that our method yields substantial improvements in both translation quality and translation speed over its base system, with no additional data.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-402">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/402">Capturing Human Category Representations by Sampling in Deep Feature Spaces</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Joshua Peterson &middot; Krisha Aghi &middot; Jordan W Suchow &middot; Alexander Ku &middot; Thomas L Griffiths</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-402"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-402" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-402" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-402">
                Abstract <i id="caret-402" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-402">
    <div class="abstract-display">
        <p>Understanding how people represent categories is a core problem in cognitive science, with the flexibility of human learning remaining a gold standard to which modern artificial intelligence and machine learning aspire. Decades of psychological research have yielded a variety of formal theories of categories, yet validating these theories with naturalistic stimuli remains a challenge. The problem is that human category representations cannot be directly observed and running informative experiments with naturalistic stimuli such as images requires having a workable representation of these stimuli. Deep neural networks have recently been successful in a range of computer vision tasks and provide a way to represent the features of images. In this paper, we introduce a method for estimating the structure of human categories that draws on ideas from both cognitive science and machine learning, blending human-based algorithms with state-of-the-art deep representation learners. We provide qualitative and quantitative results as a proof of concept for the feasibility of the method. Samples drawn from human distributions rival the quality of current state-of-the-art generative models and outperform alternative methods for estimating the structure of human categories.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-423">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/423">Selecting the Best in GANs Family: a Post Selection Inference Framework</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yao-Hung Hubert Tsai &middot; Yi Wu &middot; Makoto Yamada &middot; Ruslan Salakhutdinov &middot; Ichiro Takeuchi &middot; Kenji Fukumizu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-423"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-423" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-423" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-423">
                Abstract <i id="caret-423" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-423">
    <div class="abstract-display">
        "Which Generative Adversarial Networks (GANs) generates the most plausible images?" has been a frequently asked question among researchers. To address this problem, we first propose an \emph{incomplete} U-statistics estimate of maximum mean discrepancy $\textnormal{MMD}_{inc}$ to measure the distribution discrepancy between generated and real images. $\textnormal{MMD}_{inc}$ enjoys the advantages of asymptotic normality, computation efficiency, and model agnosticity. We then propose a GANs analysis framework to select the "best" member in GANs family using the Post Selection Inference (PSI) with $\textnormal{MMD}_{inc}$. In the experiments, we adopt the proposed framework on 7 GANs variants and compare their $\textnormal{MMD}_{inc}$ scores.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-536">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/536">Deep Convolutional Malware Classifiers Can Learn from Raw Executables and Labels Only</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Marek Krčál &middot; Ondřej Švec &middot; Martin Bálek &middot; Otakar Jašek</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-536"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-536" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-536" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-536">
                Abstract <i id="caret-536" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-536">
    <div class="abstract-display">
        <p>We propose and evaluate a simple convolutional deep neural network architecture detecting malicious \emph{Portable Executables} (Windows executable files) by learning from their raw sequences of bytes and labels only, that is, without any domain-specific feature extraction nor preprocessing. On a dataset of 20 million \emph{unpacked} half megabyte Portable Executables, such end-to-end approach achieves performance almost on par with the traditional machine learning pipeline based on handcrafted features of Avast.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-489">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/489">Exploring Deep Recurrent Models with Reinforcement Learning for Molecule Design</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Daniel Neil &middot; Marwin Segler &middot; Laura Guasch &middot; Mohamed Ahmed &middot; Dean Plumbley &middot; Matthew Sellwood &middot; Nathan Brown</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-489"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-489" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-489" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-489">
                Abstract <i id="caret-489" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-489">
    <div class="abstract-display">
        <p>The design of small molecules with bespoke properties is of central importance to drug discovery.  However significant challenges yet remain for computational methods, despite recent advances such as deep recurrent networks and reinforcement learning strategies for sequence generation, and it can be difficult to compare results across different works.  This work proposes 19 benchmarks selected by subject experts, expands smaller datasets previously used to approximately 1.1 million training molecules, and explores how to apply new reinforcement learning techniques effectively for molecular design.  The benchmarks here, built as OpenAI Gym environments, will be open-sourced to encourage innovation in molecular design algorithms and to enable usage by those without a background in chemistry.  Finally, this work explores recent development in reinforcement-learning methods with excellent sample complexity (the A2C and PPO algorithms) and investigates their behavior in molecular generation, demonstrating significant performance gains compared to standard reinforcement learning techniques.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-445">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/445">LSTM Iteration Networks: An Exploration of Differentiable Path Finding</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Lisa Lee &middot; Emilio Parisotto &middot; Devendra Singh Chaplot &middot; Ruslan Salakhutdinov</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-445"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-445" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-445" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-445">
                Abstract <i id="caret-445" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-445">
    <div class="abstract-display">
        <p>Our motivation is to scale value iteration to larger environments without a huge increase in computational demand, and fix the problems inherent to Value Iteration Networks (VIN) such as spatial invariance and unstable optimization. We show that VINs, and even extended VINs which improve some of their shortcomings, are empirically difficult to optimize, exhibiting instability during training and sensitivity to random seeds. Furthermore, we explore whether the inductive biases utilized in past differentiable path planning modules are even necessary, and demonstrate that the requirement that the architectures strictly resemble path-finding algorithms does not hold. We do this by designing a new path planning architecture called the LSTM-Iteration Network, which achieves better performance than VINs in metrics such as success rate, training stability, and sensitivity to random seeds.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-418">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/418">Generative Modeling for Protein Structures</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Namrata Anand &middot; Possu Huang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-418"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-418" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-418" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-418">
                Abstract <i id="caret-418" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-418">
    <div class="abstract-display">
        <p>We apply deep generative models to the task of generating protein structures, toward application in protein design. We encode protein structures in terms of pairwise distances between alpha-carbons on the protein backbone, which by construction eliminates the need for the generative model to learn translational and rotational symmetries. We then introduce a convex formulation of corruption-robust 3-D structure recovery to fold protein structures from generated pairwise distance matrices, and solve this optimization problem using the Alternating Direction Method of Multipliers. Finally, we demonstrate the effectiveness of our models by predicting completions of corrupted protein structures and show that in many cases the models infer biochemically viable solutions.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-416">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/416">Faster Neural Networks Straight from JPEG</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Lionel Gueguen &middot; Alexander Sergeev &middot; Ruoqian Liu &middot; Jason Yosinski</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-416"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-416" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-416" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-416">
                Abstract <i id="caret-416" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-416">
    <div class="abstract-display">
        <p>Training convolutional neural networks (CNNs) directly from RGB pixels hasenjoyed overwhelming empirical success. But can more performance be squeezedout of networks by using different input representations? In this paper we proposeand explore a simple idea: train CNNs directly on the blockwise discrete cosinetransform (DCT) coefficients computed and available in the middle of the JPEG codec. We modify libjpeg to produce DCT coefficients directly, modify a ResNet-50 network to accommodate the differently sized and strided input, andevaluate performance on ImageNet. We find networks that are both faster and moreaccurate, as well as networks with about the same accuracy but 1.77x faster thanResNet-50.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-551">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/551">TransNets for Review Generation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Rose Kanjirathinkal &middot; William W Cohen</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-551"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-551" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-551" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-551">
                Abstract <i id="caret-551" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-551">
    <div class="abstract-display">
        <p>In recommender systems, review generation is increasingly becoming an important task. 
Previously proposed neural models concatenate the user and item information to each timestep of an RNN to steer it towards generating their specific review. 
In this paper, we show how a student-teacher like architecture can be used to rapidly build a review generator with a low perplexity score. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-514">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/514">Policy Optimization with Second-Order Advantage Information</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jiajin Li &middot; Baoxiang Wang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-514"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-514" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-514" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-514">
                Abstract <i id="caret-514" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-514">
    <div class="abstract-display">
        <p>Policy optimization on high-dimensional action spaces exhibits its difficulty caused by the high variance of the policy gradient estimators. We present the action subspace dependent gradient (ASDG) estimator which incorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a unified framework to reduce the variance. To invoke RB, the algorithm learns the underlying factorization structure among the action space based on the second-order gradient of the advantage function with respect to the action. Empirical studies demonstrate the performance improvement on high-dimensional synthetic settings and OpenAI Gym's MuJoCo continuous control tasks. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-433">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/433">Tempered Adversarial Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Mehdi Sajjadi &middot; Giambattista Parascandolo &middot; Arash Mehrjou &middot; Bernhard Schoelkopf</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-433"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-433" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-433" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-433">
                Abstract <i id="caret-433" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-433">
    <div class="abstract-display">
        <p>Generative adversarial networks (GANs) have been shown to produce realistic samples from high-dimensional distributions, but training them is considered hard. A possible explanation for training instabilities is the inherent imbalance between the networks: While the discriminator is trained directly on both real and fake samples, the generator only has control over the fake samples it produces since the real data distribution is fixed by the choice of a given dataset. We propose a simple modification that gives the generator control over the real samples, leading to a tempered learning process for both generator and discriminator. The real data distribution passes through a lens before being revealed to the discriminator, balancing the training process by gradually revealing more detailed features necessary to produce high-quality results. The proposed module automatically adjusts the learning process to the current strength of the networks, yet is generic and easy to add to any GAN variant. In a number of experiments, we show that this is a promising technique to improve quality, stability and/or convergence speed across a range of different GAN architectures (DCGAN, LSGAN, WGAN-GP).</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-471">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/471">Combating Adversarial Attacks Using Sparse Representations</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Soorya Gopalakrishnan &middot; Zhinus Marzi &middot; Upamanyu Madhow &middot; Ramtin Pedarsani</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-471"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-471" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-471" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-471">
                Abstract <i id="caret-471" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-471">
    <div class="abstract-display">
        <p>It is by now well-known that small adversarial perturbations can induce classification errors in deep neural networks (DNNs). In this paper, we make the case that sparse representations of the input data are a crucial tool for combating such attacks. For linear classifiers, we show that a sparsifying front end is provably effective against l∞-bounded attacks, reducing output distortion due to the attack by a factor of roughly K/N where N is the data dimension and K is the sparsity level. We then extend this concept to DNNs, showing that a “locally linear” model can be used to develop a theoretical foundation for crafting attacks and defenses. Experimental results for the MNIST dataset show the efficacy of the proposed sparsifying front end.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-447">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/447">FigureQA: An Annotated Figure Dataset for Visual Reasoning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Samira Ebrahimi Kahou &middot; Vincent Michalski &middot; Adam Atkinson &middot; Ákos Kádár &middot; Adam Trischler &middot; Yoshua Bengio</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-447"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-447" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-447" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-447">
                Abstract <i id="caret-447" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-447">
    <div class="abstract-display">
        <p>We introduce FigureQA, a visual reasoning corpus of over one million question-answer pairs grounded in over 100,000 images. The images are synthetic, scientific-style figures from five classes: line plots, dot-line plots, vertical and horizontal bar graphs, and pie charts. We formulate our reasoning task by generating questions from 15 templates; questions concern various relationships between plot elements and examine characteristics like the maximum, the minimum, area-under-the-curve, smoothness, and intersection. To resolve, such questions often require reference to multiple plot elements and synthesis of information distributed spatially throughout a figure. To facilitate the training of machine learning systems, the corpus also includes side data that can be used to formulate auxiliary objectives. In particular, we provide the numerical data used to generate each figure as well as bounding-box annotations for all plot elements. We study the proposed visual reasoning task by training several models, including the recently proposed Relation Network as a strong baseline. Preliminary results indicate that the task poses a significant machine learning challenge. We envision FigureQA as a first step towards developing models that can intuitively recognize patterns from visual representations of data.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-450">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/450">HoME: a Household Multimodal Environment</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Simon Brodeur &middot;   &middot; Ankesh Anand &middot; Florian Golemo &middot; Luca Celotti &middot; Florian Strub &middot; Jean Rouat &middot; Hugo Larochelle &middot; Aaron Courville</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-450"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-450" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-450" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-450">
                Abstract <i id="caret-450" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-450">
    <div class="abstract-display">
        <p>We introduce HoME: a Household Multimodal Environment for artificial agents to learn from vision, audio, semantics, physics, and interaction with objects and other agents, all within a realistic context. HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer. HoME is an open-source, OpenAI Gym-compatible platform extensible to tasks in reinforcement learning, language grounding, sound-based navigation, robotics, multi-agent learning, and more. We hope HoME better enables artificial agents to learn as humans do: in an interactive, multimodal, and richly contextualized setting.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-437">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/437">An interpretable LSTM neural network for autoregressive exogenous model</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tian Guo &middot; Tao Lin &middot; Yao Lu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-437"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-437" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-437" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-437">
                Abstract <i id="caret-437" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-437">
    <div class="abstract-display">
        <p>In this paper, we propose an interpretable LSTM recurrent neural network, i.e., multi-variable LSTM for time series with exogenous variables. Currently, widely used attention mechanism in recurrent neural networks mostly focuses on the temporal aspect of data and falls short of characterizing variable importance. To this end, our multi-variable LSTM equipped with tensorized hidden states is developed to learn variable specific representations, which give rise to both temporal and variable level attention. Preliminary experiments demonstrate comparable prediction performance of multi-variable LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable importance in real datasets characterized by the variable attention is highly in line with that determined by statistical Granger causality test, which exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end framework for both forecasting and knowledge discovery.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-449">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/449">Learning via social awareness: improving sketch representations with facial feedback</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Natasha Jaques &middot; Jesse Engel &middot; David Ha &middot;   &middot; Rosalind Picard &middot; Douglas Eck</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-449"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-449" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-449" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-449">
                Abstract <i id="caret-449" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-449">
    <div class="abstract-display">
        <p>In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-406">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/406">Winner&#x27;s Curse?  On Pace, Progress, and Empirical Rigor</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">D. Sculley &middot; Jasper Snoek &middot; Alex Wiltschko &middot; Ali Rahimi</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-406"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-406" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-406" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-406">
                Abstract <i id="caret-406" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-406">
    <div class="abstract-display">
        <p>The field of ML is distinguished both by rapid innovation and rapid dissemination of results. While the pace of progress has been extraordinary by any measure, in this paper we explore potential issues that we believe to be arising as a result.  In particular, we observe that the rate of empirical advancement may not have been matched by consistent increase in the level of empirical rigor across the field as a whole.  This short position paper highlights examples where progress has actually been slowed as a result, offers thoughts on incentive structures currently at play, and gives suggestions as seeds for discussions on productive change.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-492">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/492">Predict Responsibly: Increasing Fairness by Learning to Defer</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">David Madras &middot; Richard Zemel &middot; Toniann Pitassi</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-492"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-492" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-492" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-492">
                Abstract <i id="caret-492" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-492">
    <div class="abstract-display">
        <p>When machine learning models are used for high-stakes decisions, they should predict accurately, fairly, and responsibly. To fulfill these three requirements, a model must be able to output a reject option (i.e. say "``I Don't Know") when it is not qualified to make a prediction. In this work, we propose learning to defer, a method by which a model can defer judgment to a downstream decision-maker such as a human user. We show that learning to defer generalizes the rejection learning framework in two ways: by considering the effect of other agents in the decision-making process, and by allowing for optimization of complex objectives. We propose a learning algorithm which accounts for potential biases held by decision-makerslater in a pipeline. Experiments on real-world datasets demonstrate that learning
to defer can make a model not only more accurate but also less biased. Even when
operated by highly biased users, we show that
deferring models can still greatly improve the fairness of the entire pipeline.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-488">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/488">Can Deep Reinforcement Learning solve Erdos-Selfridge-Spencer Games?</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Maithra Raghu &middot; Alex Irpan &middot; Jacob Andreas &middot; Robert Kleinberg &middot; Quoc V Le &middot; Jon Kleinberg</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-488"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-488" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-488" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-488">
                Abstract <i id="caret-488" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-488">
    <div class="abstract-display">
        <p>Deep reinforcement learning has achieved many recent successes, but our understanding of its strengths and limitations is hampered by the lack of rich environments in which we can fully characterize optimal behavior, and correspondingly diagnose individual actions against such a characterization. Here we consider a family of combinatorial games, arising from work of Erdos, Selfridge, and Spencer, and we propose their use as environments for evaluating and comparing different approaches to reinforcement learning. These games have a number of appealing features: they are challenging for current learning approaches, but they form (i) a low-dimensional, simply parametrized environment where (ii) there is a linear closed form solution for optimal behavior from any state, and (iii) the difficulty of the game can be tuned by changing environment parameters in an interpretable way. We use these Erdos-Selfridge-Spencer games not only to compare different algorithms, but test for generalization, make comparisons to supervised learning, analyse multiagent play, and even develop a self play algorithm.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-570">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/570">Pelee: A Real-Time Object Detection System on Mobile Devices</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jun Wang &middot;   &middot; Shuang Ao &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-570"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-570" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-570" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-570">
                Abstract <i id="caret-570" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-570">
    <div class="abstract-display">
        <p>An increasing need of running Convolutional Neural Network (CNN)  models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years,  for example, MobileNet, ShuffleNet, and NASNet-A. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy by 0.6% (71.3% vs. 70.7%) and 11% lower computational cost than MobileNet, the state-of-the-art efficient architecture. Meanwhile, PeleeNet is only half of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 70.9% mAP (mean average precision) on PASCAL VOC2007 dataset at the speed of 17.1 FPS on iPhone 6s and 23.6 FPS on iPhone 8. Compared to TinyYOLOv2, our proposed Pelee is more accurate (70.9% vs. 57.1%), 1.88 times lower in computational cost and 1.92 times smaller in model size. …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-455">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/455">Negative eigenvalues of the Hessian in deep neural networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Guillaume Alain &middot; Nicolas Le Roux &middot; Pierre-Antoine Manzagol</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-455"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-455" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-455" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-455">
                Abstract <i id="caret-455" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-455">
    <div class="abstract-display">
        <p>We study the loss function of a deep neural network through the eigendecomposition of its Hessian matrix. We focus on negative eigenvalues, how important they are, and how to best deal with them. The goal is to develop an optimization method specifically tailored for deep neural networks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-456">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/456">GILBO: One Metric to Measure Them All</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Alexander Alemi &middot; Ian Fischer</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-456"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-456" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-456" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-456">
                Abstract <i id="caret-456" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-456">
    <div class="abstract-display">
        <p>We propose a simple, tractable lower bound on the mutual information contained in the joint generative density of any latent variable generative 
model: the GILBO (Generative Information Lower BOund). It offers a data independent measure of the complexity of the learned latent variable description, giving the log of the effective description length. It is well-defined for both VAEs and GANs. We compute the GILBO for 800 GANs and VAE s trained on MNIST and discuss the results.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-561">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/561">Learning Deep Models: Critical Points and Local Openness</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Maher Nouiehed &middot; Meisam Razaviyayn</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-561"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-561" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-561" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-561">
                Abstract <i id="caret-561" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-561">
    <div class="abstract-display">
        <p>In this paper we present a unifying framework to study the local/global optima equivalence of the optimization problems arising from training non-convex deep models. Using the local openness property of the underlying training models,  we provide simple sufficient conditions under which any local optimum of the resulting optimization problem is  globally optimal. We first completely characterize the local openness of matrix multiplication mapping in its range. Then we use our characterization to: 1) show that every local optimum of two layer linear networks is globally optimal.  Unlike many existing results, our result requires no assumption  on the target data matrix Y, and input data matrix X. 2) Develop almost complete characterization of the local/global optima equivalence of multi-layer linear neural networks. 3) Show global/local optima equivalence of non-linear deep models having certain pyramidal structure. Unlike some existing works, our result requires no assumption on the differentiability of the activation functions. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-463">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/463">GitGraph - from Computational Subgraphs to Smaller Architecture Search Spaces</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Kamil Bennani-Smires &middot; Claudiu Cristian Musat &middot; Andreea Hossmann &middot; Michael Baeriswyl</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-463"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-463" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-463" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-463">
                Abstract <i id="caret-463" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-463">
    <div class="abstract-display">
        <p>To simplify neural architecture creation, AutoML is gaining traction - from evolutionary algorithms to reinforcement learning or simple search in a constrained space of neural modules. 
A big issues is its computational cost: the size of the search space can easily go above 10^10 candidates for a 10-layer network and the cost of evaluating a single candidate is high - even if it's not fully trained.
In this work, we use the collective wisdom within the neural networks published in online code repositories to create better reusable neural modules. Concretely, we (a) extract and publish GitGraph, a corpus of neural architectures and their descriptions; (b) we create problem-specific neural architecture search spaces, implemented as a textual search mechanism over GitGraph and (c) we propose a method of identifying unique common computational subgraphs.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-538">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/538">Semiparametric Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Mika Jain &middot; John Lindsey</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-538"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-538" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-538" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-538">
                Abstract <i id="caret-538" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-538">
    <div class="abstract-display">
        <p>We introduce a semiparametric approach to deep reinforcement learning inspired by complementary learning systems theory in cognitive neuroscience.  Our approach allows a neural network to integrate nonparametric, episodic memory-based computations with parametric statistical learning in an end-to-end fashion. We give a deep Q network access to intermediate and final results of a differentiable approximation to k-nearest-neighbors performed on a dictionary of historic state-action embeddings.  Our method displays the early-learning advantage associated with episodic memory-based algorithms while mitigating the asymptotic performance disadvantage suffered by such approaches.  In several cases we find that our model learns even more quickly from few examples than pure kNN-based approaches.  Analysis shows that our semiparametric algorithm relies heavily on the kNN output early on and less so as training progresses, which is consistent with complementary learning systems theory.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-474">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/474">Bayesian Incremental Learning for Deep Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Maxim Kochurov &middot; Timur Garipov &middot; Dmitrii Podoprikhin &middot; Dmitry Molchanov &middot; Arsenii Ashukha &middot; Dmitry Vetrov</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-474"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-474" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-474" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-474">
                Abstract <i id="caret-474" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-474">
    <div class="abstract-display">
        <p>In industrial machine learning pipelines, data often arrive in parts. Particularly in the case of deep neural networks, it may be too expensive to train the model from scratch each time, so one would rather use a previously learned model and the new data to improve performance. However, deep neural networks are prone to getting stuck in a suboptimal solution when trained on only new data as compared to the full dataset. Our work focuses on a continuous learning setup where the task is always the same and new parts of data arrive sequentially. We apply a Bayesian approach to update the posterior approximation with each new piece of data and find this method to outperform the traditional approach in our experiments.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-422">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/422">Realistic Evaluation of Semi-Supervised Learning Algorithms</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Avital Oliver &middot; Augustus Odena &middot; Colin Raffel &middot; Ekin Cubuk &middot; Ian Goodfellow</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-422"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-422" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-422" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-422">
                Abstract <i id="caret-422" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-422">
    <div class="abstract-display">
        <p>Semi-supervised learning (SSL) provides a powerful framework for leveraging unlabeled data when labels are limited or expensive to obtain. Approaches based on deep neural networks have recently proven successful on standard benchmark tasks. However, we argue that these benchmarks fail to address many issues that these algorithms would face in real-world applications. After creating a unified reimplementation of various widely-used SSL techniques, we test them in a suite of experiments designed to address these issues. We find that simple baselines which do not use unlabeled data can be competitive with the state-of-the-art, that SSL methods differ in sensitivity to the amount of labeled and unlabeled data, and that performance can degrade substantially when the unlabeled dataset contains out-of-class examples.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-424">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/424">Learning to Learn Without Labels</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Luke Metz &middot; Niru Maheswaranathan &middot; Brian Cheung</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-424"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-424" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-424" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-424">
                Abstract <i id="caret-424" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-424">
    <div class="abstract-display">
        <p>A major goal of unsupervised learning is for algorithms to learn representations of data, useful for subsequent tasks, without access to supervised labels or other high-level attributes. Typically, these algorithms minimize a surrogate objective, such as reconstruction error or likelihood of a generative model, with the hope that representations useful for subsequent tasks will arise as a side effect (e.g. semi-supervised classification). In this work, we propose using meta-learning to learn an unsupervised learning rule, and meta-optimize the learning rule directly to produce good representations for a desired task. Here, our desired task (meta-objective) is the performance of the representation on semi-supervised classification, and we meta-learn an algorithm -- an unsupervised weight update rule -- that produces representations that perform well under this meta-objective. We examine the performance of the learned algorithm on several datasets and show that it learns useful features, generalizes across both network architectures and a wide array of datasets, and outperforms existing unsupervised learning techniques.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-578">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/578">ComboGAN: Unrestricted Scalability for Image Domain Translation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Asha Anoosheh &middot; Eirikur Agustsson &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-578"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-578" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-578" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-578">
                Abstract <i id="caret-578" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-578">
    <div class="abstract-display">
        <p>This past year alone has seen unprecedented leaps in the area of learning-based image translation, namely the unsupervised model CycleGAN, by Zhu et al. But experiments so far have been tailored to merely two domains at a time, and scaling them to more would require an quadratic number of models to be trained. With two-domain models taking days to train on current hardware, the number of domains quickly becomes limited by training. In this paper, we propose a multi-component image translation model and training scheme which scales linearly - both in resource consumption and time required - with the number of domains.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-525">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/525">Resilient Backpropagation (Rprop) for Batch-learning in TensorFlow</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ciprian Florescu &middot; Christian Igel</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-525"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-525" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-525" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-525">
                Abstract <i id="caret-525" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-525">
    <div class="abstract-display">
        <p>The resilient backpropagation (Rprop) algorithms are fast and accurate batch learning methods for neural networks. We describe their implementation in the popular machine learning framework TensorFlow. We present the first empirical evaluation of Rprop for training recurrent neural networks with gated recurrent units. In our experiments, Rprop with default hyperparameters outperformed vanilla steepest descent as well as the optimization algorithms RMSprop and Adam even if their hyperparameters were tuned.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-425">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/425">MemCNN: a Framework for Developing Memory Efficient Deep Invertible Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Sil van de Leemput &middot; Jonas Teuwen &middot; Rashindra Manniesing</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-425"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-425" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-425" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-425">
                Abstract <i id="caret-425" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-425">
    <div class="abstract-display">
        <p>Reversible operations have recently been successfully applied to classification problems to reduce memory requirements during neural network training. This feature is accomplished by removing the need to store the input activation for computing the gradients at the backward pass and instead reconstruct them on demand. However, current approaches rely on custom implementations of backpropagation, which limits applicability and extendibility. We present MemCNN, a novel PyTorch framework which simplifies the application of reversible functions by removing the need for a customized backpropagation. The framework contains a set of practical generalized tools, which can wrap common operations like convolutions and batch normalization and which take care of the memory management. We validate the presented framework by reproducing state-of-the-art experiments comparing classification accuracy and training time on Cifar-10 and Cifar-100 with the existing state-of-the-art, achieving similar classification accuracy and faster training times.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-426">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/426">Conditional Networks for Few-Shot Semantic Segmentation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Kate Rakelly &middot; Evan Shelhamer &middot; Trevor Darrell &middot; Alexei Efros &middot; Sergey Levine</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-426"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-426" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-426" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-426">
                Abstract <i id="caret-426" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-426">
    <div class="abstract-display">
        <p>Few-shot learning methods aim for good performance in the low-data regime.
Structured output tasks such as segmentation present difficulties for few-shot
learning because of their high dimensionality and the statistical dependencies
among outputs. To tackle this problem, we propose the co-FCN, a conditional
network learned by end-to-end optimization to perform fast, accurate few-shot
segmentation. The network conditions on an annotated support set of images via
feature fusion to perform inference on an unannotated query image. Once learned,
our conditioning approach requires no further optimization for new data. Addi-
tional annotated inputs are used to update the output via a single inference step,
making the model suitable for interactive use. Our conditional network signifi-
cantly improves few-shot accuracy over the prior state-of-the-art.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-427">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/427">An Optimization View on Dynamic Routing Between Capsules</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Dilin Wang &middot; Qiang Liu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-427"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-427" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-427" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-427">
                Abstract <i id="caret-427" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-427">
    <div class="abstract-display">
        <p>Despite the effectiveness of dynamic routing procedure recently proposed in \citep{sabour2017dynamic},
we still lack a standard formalization of the heuristic and its implications. In this paper, we partially formulate the routing strategy proposed in \citep{sabour2017dynamic} as an optimization problem that minimizes a combination of clustering-like loss and a KL regularization term between the current coupling distribution and its last states.
We then introduce another simple routing approach, which enjoys few interesting properties.
In an unsupervised perceptual grouping task, we show experimentally that our routing algorithm outperforms the dynamic routing method proposed in \citep{sabour2017dynamic}.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-430">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/430">Gradients explode - Deep Networks are shallow - ResNet explained</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Georg Philipp &middot; Dawn Song &middot; Jaime Carbonell</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-430"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-430" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-430" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-430">
                Abstract <i id="caret-430" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-430">
    <div class="abstract-display">
        <p>Whereas it is believed that techniques such as Adam, batch normalization and, more recently, SeLU nonlinearities "solve" the exploding gradient problem, we show that this is not the case and that in a range of popular MLP architectures, exploding gradients exist and that they limit the depth to which networks can be effectively trained, both in theory and in practice. We explain why exploding gradients occur and highlight the <em>collapsing domain problem</em>, which can arise in architectures that avoid exploding gradients. </p>

<p>ResNets have significantly lower gradients and thus can circumvent the exploding gradient problem, enabling the effective training of much deeper networks, which we show is a consequence of a surprising mathematical property. By noticing that <em>any neural network is a residual network</em>, we devise the <em>residual trick</em>, which reveals that introducing skip connections simplifies the network mathematically, and that this simplicity may be the major cause for their success.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-431">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/431">Learning Invariance with Compact Transforms</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Anna Thomas &middot; Albert Gu &middot; Tri Dao &middot; Atri Rudra &middot; Christopher Re</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-431"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-431" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-431" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-431">
                Abstract <i id="caret-431" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-431">
    <div class="abstract-display">
        <p>The problem of building machine learning models that admit efficient representations and also capture an appropriate inductive bias for the domain has recently attracted significant interest. Existing work for compressing deep learning pipelines has explored classes of structured matrices that exhibit forms of shift-invariance akin to convolutions. We leverage the displacement rank framework to automatically learn the structured class, allowing for adaptation to the invariances required for a given dataset while preserving asymptotically efficient multiplication and storage. In a setting with a small fixed parameter budget, our broad classes of structured matrices improve final accuracy by 5-7% on standard image classification datasets compared to conventional parameter constraining methods.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-441">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/441">Are Efficient Deep Representations Learnable?</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Maxwell Nye &middot; Andrew Saxe</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-441"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-441" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-441" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-441">
                Abstract <i id="caret-441" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-441">
    <div class="abstract-display">
        <p>Many theories of deep learning have shown that a deep network can require dramatically
fewer resources to represent a given function compared to a shallow
network. But a question remains: can these efficient representations be learned
using current deep learning techniques? In this work, we test whether standard
deep learning methods can in fact find the efficient representations posited by several
theories of deep representation. Specifically, we train deep neural networks
to learn two simple functions with known efficient solutions: the parity function
and the fast Fourier transform. We find that using gradient-based optimization, a
deep network does not learn the parity function, unless initialized very close to a
hand-coded exact solution. We also find that a deep linear neural network does not
learn the fast Fourier transform, even in the best-case scenario of infinite training
data, unless the weights are initialized very close to the exact hand-coded solution.
Our results suggest that not every element of the class of compositional functions
can be learned efficiently by a deep network, and further restrictions are necessary
to understand what functions are both efficiently representable and learnable.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-493">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/493">Multi-Agent Generative Adversarial Imitation Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jiaming Song &middot; Hongyu Ren &middot; Dorsa Sadigh &middot; Stefano Ermon</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-493"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-493" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-493" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-493">
                Abstract <i id="caret-493" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-493">
    <div class="abstract-display">
        <p>We propose a new framework for multi-agent imitation learning for general Markov games, where we build upon a generalized notion of inverse reinforcement learning. We introduce a practical multi-agent actor-critic algorithm with good empirical performance. Our method can be used to imitate complex behaviors in high-dimensional environments with multiple cooperative or competitive agents.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-453">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/453">Nonlinear Acceleration of CNNs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Damien Scieur &middot; Edouard Oyallon &middot; Alexandre d&#x27;Aspremont &middot; Francis Bach</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-453"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-453" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-453" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-453">
                Abstract <i id="caret-453" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-453">
    <div class="abstract-display">
        <p>Regularized Nonlinear Acceleration (RNA) can improve the rate of convergence of many optimization schemes such as gradient descent, SAGA or SVRG, estimating the optimum using a nonlinear average of past iterates. Until now, its analysis was limited to convex problems, but empirical observations show that RNA may be extended to a broader setting. Here, we investigate the benefits of nonlinear acceleration when applied to the training of neural networks, in particular for the task of image recognition on the CIFAR10 and ImageNet data sets. In our experiments, with minimal modifications to existing frameworks, RNA speeds up convergence and improves testing error on standard CNNs.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-490">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/490">Synthesizing Audio with GANs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chris Donahue &middot; Julian McAuley &middot; Miller Puckette</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-490"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-490" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-490" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-490">
                Abstract <i id="caret-490" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-490">
    <div class="abstract-display">
        <p>While Generative Adversarial Networks (GANs) have seen wide success at the problem of synthesizing realistic images, they have seen little application to audio generation. In this paper, we introduce WaveGAN, a first attempt at applying GANs to raw audio synthesis in an unsupervised setting. Our experiments on speech demonstrate that WaveGAN can produce intelligible words from a small vocabulary of human speech, as well as synthesize audio from other domains such as bird vocalizations, drums, and piano. Qualitatively, we find that human judges prefer the generated examples from WaveGAN over those from a method which naïvely applies GANs on image-like audio feature representations. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-535">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/535">SGD on Random Mixtures: Private Machine Learning under Data Breach Threats</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Kangwook Lee &middot; Kyungmin Lee &middot; Hoon Kim &middot; Changho Suh &middot; Kannan Ramchandran</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-535"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-535" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-535" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-535">
                Abstract <i id="caret-535" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-535">
    <div class="abstract-display">
        <p>We propose Stochastic Gradient Descent on Random Mixtures (SGDRM) as a simple way of protecting data under data breach threats. We show that SGDRM converges to the globally optimal point for deep neural networks with linear activations while being differentially private. We also train nonlinear neural networks with private mixtures as the training data, proving the practicality of SGDRM.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-443">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/443">Meta-Learning for Batch Mode Active Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Sachin Ravi &middot; Hugo Larochelle</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-443"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-443" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-443" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-443">
                Abstract <i id="caret-443" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-443">
    <div class="abstract-display">
        <p>Active learning involves selecting unlabeled data items to label in order to best improve an existing classifier. In most applications, batch mode active learning, where a set of items is picked all at once to be labeled and then used to re-train the classifier, is most feasible because it does not require the model to be re-trained after each individual selection and makes most efficient use of human labor for annotation. In this work, we explore using meta-learning to learn an active learning algorithm that selects the best set of unlabeled items to label given a classifier trained on a small training set. Our experiments show that our learned active learning algorithm is able to construct labeled sets that improve a classifier better than commonly used heuristics.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-532">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/532">LEARNING AND ANALYZING VECTOR ENCODING OF SYMBOLIC REPRESENTATION</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">  &middot;   &middot; Paul Smolensky &middot; Rishabh Singh</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-532"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-532" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-532" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-532">
                Abstract <i id="caret-532" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-532">
    <div class="abstract-display">
        <p>We present a formal language with expressions denoting general symbol structures and queries which access information in those structures. A sequence-to-sequence network processing this language learns to encode symbol structures and query them. The learned representation (approximately) shares a simple linearity property with theoretical techniques for performing this task.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-454">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/454">Decoupling Dynamics and Reward for Transfer Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Harsh Satija &middot; Amy Zhang &middot; Joelle Pineau</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-454"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-454" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-454" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-454">
                Abstract <i id="caret-454" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-454">
    <div class="abstract-display">
        <p>Reinforcement Learning (RL) provides a sound decision-theoretic framework to optimize the behavior of learning agents in an interactive setting.  However, one of the limitations to applications of RLto real-world tasks is the amount of data required for learning an optimal policy.  Our goal is to design an RL model that can be efficiently trained on new tasks, and produce solutions that generalize well beyond the training environment. We take inspiration from Successor Features (Dayan, 1993), which decouples the value function representation into dynamics and rewards, and learns them separately.  We take this further by explicitly decoupling learning the state representation, reward function, forward dynamics, and inverse dynamics of the environment. We posit that we can learn a representation space \mathcal{Z} via this decoupling that makes downstream learning easier as: (1) the modules can be learned separately enabling efficient reuse of common knowledge across tasks to quickly adapt to new tasks; (2) the modules can be optimized jointly leading to a representation space that is adapted to the policy and value function, rather than only the observation space; (3) the dynamics model enables forward search and planning, in the usual model-based RL way. Our approach is the first model-based RL method …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-481">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/481">Hockey-Stick GAN</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Edgar Minasyan &middot; Vinay Prabhu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-481"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-481" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-481" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-481">
                Abstract <i id="caret-481" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-481">
    <div class="abstract-display">
        <p>We propose a new objective for generative adversarial networks (GANs) that is aimed to address current issues in GANs such as mode collapse and unstable convergence. Our approach stems from the hockey-stick divergence that has properties we claim to be of great importance in generative models. We provide theoretical support for the model and preliminary results on synthetic Gaussian data.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-452">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/452">Monotonic models for real-time dynamic malware detection</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Alexander Chistyakov &middot;   &middot; Aleksandr Shevelev &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-452"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-452" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-452" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-452">
                Abstract <i id="caret-452" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-452">
    <div class="abstract-display">
        <p>In dynamic malware analysis, programs are classified as malware or benign based on their execution logs. We propose a concept of applying monotonic classification models to the analysis process, to make the trained model's predictions consistent over execution time and provably stable to the injection of any noise or `benign-looking' activity into the program's behavior. The predictions of such models change monotonically through the log in the sense that the addition of new lines into the log may only increase the probability of the file being found malicious, which make them suitable for real-time classification on a user's machine. We evaluate monotonic neural network models based on the work by Chistyakovet al. (2017) and demonstrate that they provide stable and interpretable results.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-440">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/440">ChatPainter: Improving Text to Image Generation using Dialogue</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Shikhar Sharma &middot; Dendi Suhubdy &middot; Vincent Michalski &middot; Samira Ebrahimi Kahou &middot; Yoshua Bengio</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-440"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-440" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-440" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-440">
                Abstract <i id="caret-440" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-440">
    <div class="abstract-display">
        <p>Synthesizing realistic images from text descriptions on a dataset like Microsoft Common Objects in Context (COCO), where each image can contain several objects, is a challenging task. Prior work has used text captions to generate images. However, captions might not be informative enough to capture the entire image and insufficient for the model to be able to understand which objects in the images correspond to which words in the captions. We show that adding a dialogue that further describes the scene leads to significant improvement in the inception score and in the quality of generated images on the COCO dataset.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-451">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/451">Analysis of Cosmic Microwave Background with Deep Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Siyu He &middot; Siamak Ravanbakhsh &middot; Shirley Ho</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-451"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-451" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-451" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-451">
                Abstract <i id="caret-451" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-451">
    <div class="abstract-display">
        <p>The observation of Cosmic Microwave Background (CMB) has been one of the cornerstones in establishing the current understanding of the Universe. This valuable source of information consists of primary and secondary effects. While the primary source of information in CMB (as a Gaussian random field) can be efficiently analyzed using established statistical methods, CMB is also host to secondary sources of information that are more complex to analyze and understand. Here, we report encouraging preliminary results as well as some difficulties in using deep learning for prediction of the cosmological parameters and uncertainty estimates from the primary CMB. This opens the way to application of deep models in analysis of the secondary CMB and joint analysis of CMB with other modalities such as the large-scale structure</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-461">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/461">Learning Efficient Tensor Representations with Ring Structure Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Qibin Zhao &middot; Masashi Sugiyama &middot; Longhao Yuan &middot; Andrzej Cichocki</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-461"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-461" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-461" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-461">
                Abstract <i id="caret-461" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-461">
    <div class="abstract-display">
        <p>\emph{Tensor train (TT) decomposition} is a powerful representation for high-order tensors, which has been successfully applied to various machine learning tasks in recent years.  In this paper, we propose a more generalized tensor decomposition with ring structure network  by employing circular multilinear products over a sequence of lower-order core tensors, which is termed as TR representation. Several learning algorithms including blockwise ALS  with adaptive tensor ranks and  SGD  with high scalability are presented. Furthermore, the mathematical properties are investigated, which enables us to perform basic algebra operations in a computationally efficiently way by using TR representations. Experimental results on synthetic signals and real-world datasets demonstrate the effectiveness of TR model and the learning algorithms. In particular, we show that  the structure information and high-order correlations within a 2D image can be captured efficiently by employing tensorization and TR representation. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-563">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/563">Empirical Analysis of the Hessian of Over-Parametrized Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Levent Sagun &middot; Utku Evci &middot; Veli Ugur Guney &middot; Yann Dauphin &middot; Leon Bottou</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-563"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-563" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-563" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-563">
                Abstract <i id="caret-563" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-563">
    <div class="abstract-display">
        <p>We study the properties of common loss surfaces through their Hessian matrix. In particular, in the context of deep learning, we empirically show that the spectrum of the Hessian is composed of two parts: (1) the bulk centered near zero, (2) and outliers away from the bulk. We present numerical evidence and mathematical justifications to the following conjectures laid out by Sagun et. al. (2016): Fixing data, increasing the number of parameters merely scales the bulk of the spectrum; fixing the dimension and changing the data (for instance adding more clusters or making the data less separable) only affects the outliers. We believe that our observations have striking implications for non-convex optimization in high dimensions. First, the <em>flatness</em> of such landscapes (which can be measured by the singularity of the Hessian) implies that classical notions of basins of attraction may be quite misleading. And that the discussion of wide/narrow basins may be in need of a new perspective around over-parametrization and redundancy that are able to create <em>large</em> connected components at the bottom of the landscape. Second, the dependence of a small number of large eigenvalues to the data distribution can be linked to the spectrum of the covariance matrix …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-478">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/478">To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Michael Zhu &middot; Suyog Gupta</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-478"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-478" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-478" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-478">
                Abstract <i id="caret-478" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-478">
    <div class="abstract-display">
        <p>Model pruning seeks to induce sparsity in a deep neural network's various connection matrices, thereby reducing the number of nonzero-valued parameters in the model. Recent reports (Han et al., 2015; Narang et al., 2017) prune deep networks at the cost of only a marginal loss in accuracy and achieve a sizable reduction in model size. This hints at the possibility that the baseline models in these experiments are perhaps severely over-parameterized at the outset and a viable alternative for model compression might be to simply reduce the number of hidden units while maintaining the model's dense connection structure, exposing a similar trade-off in model size and accuracy. We investigate these two distinct paths for model compression within the context of energy-efficient inference in resource-constrained environments and propose a new gradual pruning technique that is simple and straightforward to apply across a variety of models/datasets with minimal tuning and can be seamlessly incorporated within the training process. We compare the accuracy of large, but pruned models (large-sparse) and their smaller, but dense (small-dense) counterparts with identical memory footprint. Across a broad range of neural network architectures (deep CNNs, stacked LSTM, and seq2seq LSTM models), we find large-sparse models to consistently outperform …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-413">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/413">An Evaluation of Fisher Approximations Beyond Kronecker Factorization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">César Laurent &middot; Thomas George &middot; Xavier Bouthillier &middot; Nicolas Ballas &middot; Pascal Vincent</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-413"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-413" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-413" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-413">
                Abstract <i id="caret-413" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-413">
    <div class="abstract-display">
        <p>We study two coarser approximations on top of a Kronecker factorization (K-FAC) of the Fisher information matrix, to scale up Natural Gradient to deep and wide Convolutional Neural Networks (CNNs). The first considers the activations (feature maps) as spatially uncorrelated while the second considers only correlations among groups of channels. Both variants yield a further block-diagonal approximation tailored for CNNs, which is much more efficient to compute and invert. Experiments on the VGG11 and ResNet50 architectures show the technique can substantially speed up both K-FAC and a baseline with Batch Normalization in wall-clock time, yielding faster convergence to similar or better generalization error.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-403">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/403">Investigating Human Priors for Playing Video Games</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Rachit Dubey &middot; Pulkit Agrawal &middot; Deepak Pathak &middot; Alexei Efros &middot; Thomas L Griffiths</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-403"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-403" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-403" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-403">
                Abstract <i id="caret-403" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-403">
    <div class="abstract-display">
        <p>Deep reinforcement learning algorithms have recently achieved impressive results on a range of video games, yet they remain much less efficient than an average human player at learning a new game. What makes humans so good at solving these video games? Here, we study one aspect critical to human gameplay -- their use of strong priors that enable efficient decision making and problem-solving. We created a sample video game and conducted various experiments to quantify the kinds of prior knowledge humans bring in while playing such games. We do this by modifying the video game environment to systematically remove different types of visual information that could be used by humans as priors. We find that human performance degrades drastically once prior information has been removed, while that of an RL agent does not change. Interestingly, we also find that general priors about objects that humans learn when they are as little as two months old are some of the most critical priors that help in human gameplay. Based on these findings, we then propose a taxonomy of object priors people employ when solving video games that can potentially serve as a benchmark for future reinforcement learning algorithms aiming to incorporate …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-479">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/479">On the Limitation of Local Intrinsic Dimensionality for Characterizing the Subspaces of Adversarial Examples</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Pei-Hsuan Lu &middot; Pin-Yu Chen &middot; Chia-Mu Yu</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-479"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-479" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-479" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-479">
                Abstract <i id="caret-479" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-479">
    <div class="abstract-display">
        <p>Understanding and characterizing the subspaces of adversarial examples aid in studying the robustness of deep neural networks (DNNs) to adversarial perturbations. Very recently, (Ma et al. ICLR 2018)  proposed to use local intrinsic dimensionality (LID) in layer-wise hidden representations of DNNs to study adversarial subspaces. It was demonstrated that LID can be used to characterize the adversarial subspaces associated with different attack methods, e.g., the Carlini and Wagner's (C&amp;W) attack and the fast gradient sign attack. </p>

<p>In this paper, we use MNIST and CIFAR-10 to conduct two new sets of experiments that are absent in existing LID analysis and report the limitation of LID in characterizing the corresponding adversarial subspaces, which are (i) oblivious attacks and LID analysis using adversarial examples with different confidence levels; and (ii) black-box transfer attacks. For (i), we find that the performance of LID is very sensitive to the confidence parameter deployed by an attack, and the LID learned from ensembles of adversarial examples with varying confidence levels surprisingly gives poor performance. For (ii), we find that when adversarial examples are crafted from another DNN model, LID is ineffective in characterizing their adversarial subspaces. These two findings together suggest the limited capability of LID in …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-485">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/485">Fast Node Embeddings: Learning Ego-Centric Representations</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tiago Pimentel &middot; Adriano Veloso &middot; Nivio Ziviani</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-485"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-485" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-485" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-485">
                Abstract <i id="caret-485" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-485">
    <div class="abstract-display">
        <p>Representation learning is one of the foundations of Deep Learning and allowed important improvements on several Machine Learning tasks, such as Neural Machine Translation, Question Answering and Speech Recognition. Recent works have proposed new methods for learning representations for nodes and edges in graphs. Several of these methods are based on the SkipGram algorithm, and they usually process a large number of multi-hop neighbors in order to produce the context from which node representations are learned. In this paper, we propose an effective and also efficient method for generating node embeddings in graphs that employs a restricted number of permutations over the immediate neighborhood of a node as context to generate its representation, thus ego-centric representations. We present a thorough evaluation showing that our method outperforms state-of-the-art methods in six different datasets related to the problems of link prediction and node classification, being one to three orders of magnitude faster than baselines when generating node embeddings for very large graphs.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-444">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/444">Learning and Memorization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Satrajit Chatterjee</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-444"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-444" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-444" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-444">
                Abstract <i id="caret-444" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-444">
    <div class="abstract-display">
        <p>In the machine learning research community, it is generally believed that
there is a tension between memorization and generalization. In this work we
examine to what extent this tension exists, by exploring if it is
possible to generalize through memorization alone. Although direct memorization
with a lookup table obviously does not generalize, we find that introducing
depth in the form of a network of support-limited lookup tables leads to
generalization that is significantly above chance and closer to those
obtained by standard learning algorithms on several tasks derived from MNIST 
and CIFAR-10. Furthermore, we demonstrate through a series of
empirical results that our approach allows for a smooth tradeoff between
memorization and generalization and exhibits some of the most salient
characteristics of neural networks: depth improves performance; random data
can be memorized and yet there is generalization on real data; and 
memorizing random data is harder in a certain sense than memorizing real
data. The extreme simplicity of the algorithm and potential connections
with stability provide important insights into the impact of depth on
learning algorithms, and point to several interesting directions for future
research.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-458">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/458">Uncertainty Estimation via Stochastic Batch Normalization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Andrei Atanov &middot; Arsenii Ashukha &middot; Dmitry Molchanov &middot; Kirill Neklyudov &middot; Dmitry P. Vetrov</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-458"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-458" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-458" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-458">
                Abstract <i id="caret-458" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-458">
    <div class="abstract-display">
        <p>In this work, we investigate Batch Normalization technique and propose its probabilistic interpretation. We propose a probabilistic model and show that Batch Normalization maximazes the lower bound of its marginalized log-likelihood. Then, according to the new probabilistic model, we design an algorithm which acts consistently during train and test. However, inference becomes computationally inefficient. To reduce memory and computational cost, we propose Stochastic Batch Normalization -- an efficient approximation of proper inference procedure. This method provides us with a scalable uncertainty estimation technique. We demonstrate the performance of Stochastic Batch Normalization on popular architectures (including deep convolutional architectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-583">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/583">A Dataset To Evaluate The Representations Learned By Video Prediction Models</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ryan Szeto &middot; Simon Stent &middot; German Ros &middot; Jason J Corso</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-583"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-583" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-583" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-583">
                Abstract <i id="caret-583" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-583">
    <div class="abstract-display">
        <p>We present a parameterized synthetic dataset called Moving Symbols to support the objective study of video prediction networks. Using several instantiations of the dataset in which variation is explicitly controlled, we highlight issues in an existing state-of-the-art approach and propose the use of a performance metric with greater semantic meaning to improve experimental interpretability. Our dataset provides canonical test cases that will help the community better understand, and eventually improve, the representations learned by such networks in the future. Code is available at https://github.com/rszeto/moving-symbols.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-571">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/571">Weightless: Lossy weight encoding for deep neural network compression</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Brandon Reagen &middot; Udit Gupta &middot; Robert Adolf &middot; Michael Mitzenmacher &middot; Alexander Rush &middot; Alexander Rush &middot; Gu-Yeon Wei</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-571"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-571" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-571" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-571">
                Abstract <i id="caret-571" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-571">
    <div class="abstract-display">
        <p>The large memory requirements of deep neural networks limit their deployment and adoption on many devices. Model compression methods effectively reduce the memory requirements of these models, usually through applying transformations such as weight pruning or quantization. In this paper, we present a novel scheme for lossy weight encoding which complements conventional compression techniques. The encoding is based on the Bloomier filter, a probabilistic data structure that can save space at the cost of introducing random errors. Leveraging the ability of neural networks to tolerate these imperfections and by re-training around the errors, the proposed technique, Weightless, can compress DNN weights by up to 496× with the same model accuracy. This results in up to a 1.51× improvement over the state-of-the-art.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-446">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/446">Spatially Parallel Convolutions</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Peter Jin &middot; Boris Ginsburg &middot; Kurt Keutzer</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-446"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-446" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-446" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-446">
                Abstract <i id="caret-446" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-446">
    <div class="abstract-display">
        <p>The training of convolutional neural networks with large inputs on GPUs is limited by the available GPU memory capacity. In this work, we describe spatially parallel convolutions, which sidestep the memory capacity limit of a single GPU by partitioning tensors along their spatial axes across multiple GPUs. On modern multi-GPU systems, we demonstrate that spatially parallel convolutions attain excellent scaling when applied to input tensors with large spatial dimensions.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-540">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/540">Neuron as an Agent</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Shohei Ohsawa &middot; Kei Akuzawa &middot; Tatsuya Matsushima &middot; Gustavo Bezerra &middot; Yusuke Iwasawa &middot; Hiroshi Kajino &middot;   &middot; Yutaka Matsuo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-540"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-540" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-540" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-540">
                Abstract <i id="caret-540" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-540">
    <div class="abstract-display">
        <p>Existing multi-agent reinforcement learning (MARL) communication methods have relied on a trusted third party (TTP) to distribute reward to agents, leaving them inapplicable in peer-to-peer environments. This paper proposes reward distribution using {\em Neuron as an Agent} (NaaA) in MARL without a TTP with two key ideas: (i) inter-agent reward distribution and (ii) auction theory. Auction theory is introduced because inter-agent reward distribution is insufficient for optimization. Agents in NaaA maximize their profits (the difference between reward and cost) and, as a theoretical result, the auction mechanism is shown to have agents autonomously evaluate counterfactual returns as the values of other agents. NaaA enables representation trades in peer-to-peer environments, ultimately regarding unit in neural networks as agents. Finally, numerical experiments (a single-agent environment from OpenAI Gym and a multi-agent environment from ViZDoom) confirm that NaaA framework optimization leads to better performance in reinforcement learning.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-448">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/448">Fast and Accurate Text Classification: Skimming, Rereading and Early Stopping</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Keyi Yu &middot; Yang Liu &middot; Alex Schwing &middot; Jian Peng</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-448"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-448" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-448" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-448">
                Abstract <i id="caret-448" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-448">
    <div class="abstract-display">
        <p>Recent advances in recurrent neural nets (RNNs) have shown much promise in many applications in natural language processing. For most of these tasks, such as sentiment analysis of customer reviews, a recurrent neural net model parses the entire review before forming a decision. We argue that reading the entire input is not always necessary in practice, since a lot of reviews are often easy to classify, i.e., a decision can be formed after reading some crucial sentences or words in the provided text. In this paper, we present an approach of fast reading for text classification. Inspired by several well-known human reading techniques, our approach implements an intelligent recurrent agent which evaluates the importance of the current snippet in order to decide whether to make a prediction, or to skip some texts, or to re-read part of the sentence. Our agent uses an RNN module to encode information from the past and the current tokens, and applies a policy module to form decisions. With an end-to-end training algorithm based on policy gradient, we train and test our agent on several text classification datasets and achieve both higher efficiency and better accuracy compared to previous approaches. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-483">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/483">Neural Program Search: Solving Programming Tasks from Description and Examples</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Illia Polosukhin &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-483"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-483" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-483" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-483">
                Abstract <i id="caret-483" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-483">
    <div class="abstract-display">
        <p>We present a Neural Program Search, an algorithm to generate programs from natural language description and a small number of input/output examples. The algorithm combines methods from Deep Learning and Program Synthesis fields by designing rich domain-specific language (DSL) and defining efficient search algorithm guided by a Seq2Tree model on it.  To evaluate the quality of the approach we also present a semi-synthetic dataset of descriptions with test examples and corresponding programs.  We show that our algorithm significantly outperforms a sequence-to-sequence model with attention baseline.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-506">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/506">A Flexible Approach to Automated RNN Architecture Generation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Martin Schrimpf &middot; Stephen Merity &middot; James Bradbury &middot; richard socher</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-506"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-506" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-506" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-506">
                Abstract <i id="caret-506" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-506">
    <div class="abstract-display">
        <p>The process of designing neural architectures requires expert knowledge and extensive trial and error.
While automated architecture search may simplify these requirements, the recurrent neural network (RNN) architectures generated by existing methods are limited in both flexibility and components.
We propose a domain-specific language (DSL) for use in automated architecture search which can produce novel RNNs of arbitrary depth and width.
The DSL is flexible enough to define standard architectures such as the Gated Recurrent Unit and Long Short Term Memory and allows the introduction of non-standard RNN components such as trigonometric curves and layer normalization.  Using two different candidate generation techniques, random search with a ranking function and reinforcement learning, 
we explore the novel architectures produced by the RNN DSL for language modeling and machine translation domains.
The resulting architectures do not follow human intuition yet perform well on their targeted tasks, suggesting the space of usable RNN architectures is far larger than previously assumed.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-475">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/475">Minimally Redundant Laplacian Eigenmaps</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">David Pfau &middot; Christopher Burgess</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-475"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-475" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-475" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-475">
                Abstract <i id="caret-475" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-475">
    <div class="abstract-display">
        <p>Spectral algorithms for learning low-dimensional data manifolds have largely been supplanted by deep learning methods in recent years. One reason is that classic spectral manifold learning methods often learn collapsed embeddings that do not fill the embedding space. We show that this is a natural consequence of data where different latent dimensions have dramatically different scaling in observation space. We present a simple extension of Laplacian Eigenmaps to fix this problem based on choosing embedding vectors which are both orthogonal and \textit{minimally redundant} to other dimensions of the embedding. In experiments on NORB and similarity-transformed faces we show that Minimally Redundant Laplacian Eigenmap (MR-LEM) significantly improves the quality of embedding vectors over Laplacian Eigenmaps, accurately recovers the latent topology of the data, and discovers many disentangled factors of variation of comparable quality to state-of-the-art deep learning methods.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-473">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/473">Clustering Meets Implicit Generative Models</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Francesco Locatello &middot; Damien Vincent &middot; Ilya Tolstikhin &middot; Gunnar Rätsch &middot; Sylvain Gelly &middot; Bernhard Schoelkopf</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-473"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-473" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-473" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-473">
                Abstract <i id="caret-473" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-473">
    <div class="abstract-display">
        <p>Clustering is a cornerstone of unsupervised learning which can be thought as disentangling multiple generative mechanisms underlying the data. In this paper we introduce an algorithmic framework to train mixtures of implicit generative models which we particularize for variational autoencoders. Relying on an additional set of discriminators, we propose a competitive procedure in which the models only need to approximate the portion of the data distribution from which they can produce realistic samples. As a byproduct, each model is simpler to train, and a clustering interpretation arises naturally from the partitioning of the training points among the models. We empirically show that our approach splits the training distribution in a reasonable way and increases the quality of the generated samples.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-472">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/472">Rethinking Style and Content Disentanglement in Variational Autoencoders</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Rui Shu &middot; Shengjia Zhao &middot; Mykel J Kochenderfer</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-472"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-472" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-472" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-472">
                Abstract <i id="caret-472" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-472">
    <div class="abstract-display">
        <p>A common test for whether a generative model learns disentangled representations is its ability to learn style and content as independent factors of variation on digit datasets. To achieve such disentanglement with variational autoencoders, the label information is often provided in either a fully-supervised or semi-supervised fashion. We show, however, that the variational objective is insufficient in explaining the observed style and content disentanglement. Furthermore, we present an empirical framework to systematically evaluate the disentanglement behavior of our models. We show that the encoder and decoder independently favor disentangled representations and that this tendency depends on the implicit regularization by stochastic gradient descent.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-470">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/470">Compression by the signs: distributed learning is a two-way street</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jeremy Bernstein &middot; Yu-Xiang Wang &middot; Kamyar Azizzadenesheli &middot; anima anandkumar</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-470"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-470" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-470" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-470">
                Abstract <i id="caret-470" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-470">
    <div class="abstract-display">
        <p>Training large neural networks requires distributing learning over multiple workers. The rate limiting step is often in sending gradients from workers to parameter server and back again. We present signSGD with majority vote: the first gradient compression scheme to achieve 1-bit compression of worker-server communication in both directions with non-vacuous theoretical guarantees. To achieve this, we build an extensive theory of sign-based optimisation, which is also relevant to understanding adaptive gradient methods like Adam and RMSprop. We prove that signSGD can get the best of both worlds: compressed gradients and SGD-level convergence rate. signSGD can exploit mismatches between L1 and L2 geometry: when noise and curvature are much sparser than the gradients, signSGD is expected to converge at the same rate or faster than full-precision SGD. Measurements of the L1 versus L2 geometry of real networks support our theoretical claims, and we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-468">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/468">Comparing Fixed and Adaptive Computation Time for Recurrent Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Daniel Fojo &middot; Víctor Campos &middot; Xavier Giro-i-Nieto</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-468"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-468" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-468" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-468">
                Abstract <i id="caret-468" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-468">
    <div class="abstract-display">
        <p>Deep networks commonly perform better than shallow ones, but allocating the proper amount of computation for each particular input sample remains an open problem. This issue is particularly challenging in sequential tasks, where the required complexity may vary for different tokens in the input sequence. Adaptive Computation Time (ACT) was proposed as a method for dynamically adapting the computation at each step for Recurrent Neural Networks (RNN). ACT introduces two main modifications to the regular RNN formulation: (1) more than one RNN steps may be executed between an input sample is fed to the layer and and this layer generates an output,  and (2) this number of steps is dynamically predicted depending on the input token and the hidden state of the network. In our work, we aim at gaining intuition about the contribution of these two factors to the overall performance boost observed when augmenting RNNs with ACT. We design a new baseline, Repeat-RNN, which performs a constant number of RNN state updates larger than one before generating an output. Surprisingly, such uniform distribution of the computational resources matches the performance of ACT in the studied tasks. We hope that this finding motivates new research efforts towards designing RNN …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-457">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/457">Jointly Learning &quot;What&quot; and &quot;How&quot; from Instructions and Goal-States</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Dzmitry Bahdanau &middot; Felix Hill &middot; Jan Leike &middot; Edward Hughes &middot; Pushmeet Kohli &middot; Edward Grefenstette</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-457"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-457" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-457" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-457">
                Abstract <i id="caret-457" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-457">
    <div class="abstract-display">
        <p>Training agents to follow instructions requires some way of rewarding them for behavior which accomplishes the intent of the instruction. For non-trivial instructions, which may be either underspecified or contain some ambiguity, it can be difficult or impossible to specify a reward function or obtain relatable expert trajectories for the agent to imitate. For these scenarios, we introduce a method which requires only pairs on instructions and examples of positive goal states, from which we can jointly learn a model of the instruction-conditional reward and a policy which executes instructions. Two sets of experiments in a gridworld compare the effectiveness of our method to that of RL when a reward function can be specified, and the application of our method when no reward function is defined. We furthermore evaluate the generalization of our approach to unseen instructions, and to scenarios where environment dynamics change outside of training, requiring fine-tuning of the policy ``in the wild''.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-459">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/459">Deep learning mutation prediction enables early stage lung cancer detection in liquid biopsy</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Steven T. Kothen-Hill &middot; Asaf Zviran &middot; Rafael Schulman &middot; Sunil Deochand &middot; Federico Gaiti &middot; Dillon Maloney &middot; Kevin Huang &middot; Willey Liao &middot; Nicolas Robine &middot; Nathaniel Omans &middot; Dan Landau</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-459"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-459" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-459" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-459">
                Abstract <i id="caret-459" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-459">
    <div class="abstract-display">
        <p>Somatic cancer mutation detection at ultra-low variant allele frequencies (VAFs) is an unmet challenge that is intractable with current state-of-the-art mutation calling methods. Specifically, the limit of VAF detection is closely related to the depth of coverage, due to the requirement of multiple supporting reads in extant methods, precluding the detection of mutations at VAFs that are orders of magnitude lower than the depth of coverage. Nevertheless, the ability to detect cancer-associated mutations in ultra low VAFs is a fundamental requirement for low-tumor burden cancer diagnostics applications such as early detection, monitoring, and therapy nomination using liquid biopsy methods (cell-free DNA). Here we defined a spatial representation of sequencing information adapted for convolutional architecture that enables variant detection at VAFs, in a manner independent of the depth of sequencing. This method enables the detection of cancer mutations even in VAFs as low as 10x-4^, &gt;2 orders of magnitude below the current state-of-the-art. We validated our method on both simulated plasma and on clinical cfDNA plasma samples from cancer patients and non-cancer controls. This method introduces a new domain within bioinformatics and personalized medicine – somatic whole genome mutation calling for liquid biopsy.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-467">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/467">Deep Neural Maps</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Mehran Pesteie &middot; Purang Abolmaesumi &middot; Robert Rohling</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-467"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-467" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-467" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-467">
                Abstract <i id="caret-467" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-467">
    <div class="abstract-display">
        <p>We introduce a new unsupervised representation learning and visualization method using deep convolutional networks and self organizing maps called Deep Neural Maps (DNM). DNM jointly learns an embedding of the input data and a mapping from the embedding space to a two-dimensional lattice. We compare visualizations of DNM with those of t-SNE and LLE on the MNIST and COIL-20 data sets. Our experiments show that the DNM can learn efficient representations of the input data, which reflects characteristics of each class. This is shown via back- projecting the neurons of the map on the data space.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-460">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/460">Evaluating visual &quot;common sense&quot; using fine-grained classification and captioning tasks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Raghav Goyal &middot; Farzaneh Mahdisoltani &middot; Guillaume Berger &middot; Waseem Gharbieh &middot; Ingo Bax &middot; Roland Memisevic</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-460"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-460" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-460" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-460">
                Abstract <i id="caret-460" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-460">
    <div class="abstract-display">
        <p>We introduce the Something-something V2 dataset, which contains captions of finely-varying human-object interactions. We also discuss various baseline models, and show that neural networks show surprisingly strong performance on many of the very hard, detailed discrimination tasks associated with this dataset.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-569">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/569">The loss surface and expressivity of deep convolutional neural networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Quynh Nguyen &middot; Matthias Hein</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-569"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-569" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-569" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-569">
                Abstract <i id="caret-569" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-569">
    <div class="abstract-display">
        <p>We analyze the expressiveness and loss surface of practical deep convolutional neural networks (CNNs) with shared weights. We show that such CNNs produce linearly independent features (and thus linearly separable) at every ``wide'' layer which has more neurons than the number of training samples. This condition holds e.g. for the VGG network. Furthermore, we provide for such wide CNNs necessary and sufficient conditions for global minima with zero training error. For the case where the wide layer is followed by a fully connected layer we show that almost every critical point of the empirical loss is a global minimum with zero training error. Our analysis suggests that both depth and width are equally important in deep learning.  While depth brings more representational power and allows the network to learn high level features, width smoothes the optimization landscape of the loss function in the sense that a sufficiently wide CNN  has a well-behaved loss surface with almost no bad local minima.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-411">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/411">Universal Successor Representations for Transfer Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chen Ma &middot; Junfeng Wen &middot; Yoshua Bengio</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-411"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-411" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-411" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-411">
                Abstract <i id="caret-411" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-411">
    <div class="abstract-display">
        <p>The objective of transfer reinforcement learning is to generalize from a set of previous tasks to unseen new tasks. In this work, we focus on the transfer scenario where the dynamics among tasks are the same, but their goals differ. Although general value function (Sutton et al., 2011) has been shown to be useful for knowledge transfer, learning a universal value function can be challenging in practice. To attack this, we propose (1) to use universal successor representations (USR) to represent the transferable knowledge and (2) a USR approximator (USRA) that can be trained by interacting with the environment. Our experiments show that USR can be effectively applied to new tasks, and the agent initialized by the trained USRA can achieve the goal considerably faster than random initialization.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-547">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/547">Expert-based reward function training: the novel method to train sequence generators</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Joji Toyama &middot; Yusuke Iwasawa &middot; Kotaro Nakayama &middot; Yutaka Matsuo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-547"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-547" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-547" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-547">
                Abstract <i id="caret-547" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-547">
    <div class="abstract-display">
        <p>The training methods of sequence generator with a combination of GAN and policy gradient has shown good performance.
In this paper, we propose expert-based reward function training: the novel method to train sequence generator.
Different from previous studies of sequence generation, expert-based reward function training does not utilize GAN's framework.
Still, our model outperforms SeqGAN and a strong baseline, RankGAN.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-420">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/420">A Proximal Block Coordinate Descent Algorithm for Deep Neural Network Training</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tsz Kit Lau &middot; Jinshan Zeng &middot; Baoyuan Wu &middot; Yuan Yao</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-420"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-420" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-420" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-420">
                Abstract <i id="caret-420" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-420">
    <div class="abstract-display">
        <p>Training deep neural networks (DNNs) efficiently is a challenge due to the associated highly nonconvex optimization. The backpropagation (backprop) algorithm has long been the most widely used algorithm for gradient computation of parameters of DNNs and is used along with gradient descent-type algorithms for this optimization task. Recent work have shown the efficiency of block coordinate descent (BCD) type methods empirically for training DNNs. In view of this, we propose a novel algorithm based on the BCD method for training DNNs and provide its global convergence results built upon the powerful framework of the Kurdyka-Lojasiewicz (KL) property. Numerical experiments on standard datasets demonstrate its competitive efficiency against standard optimizers with backprop. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-595">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/595">Semi-Supervised Few-Shot Learning with MAML</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Rinu Boney &middot; Alexander Ilin</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-595"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-595" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-595" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-595">
                Abstract <i id="caret-595" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-595">
    <div class="abstract-display">
        <p>We present preliminary results on extending Model-Agnostic Meta-Learning (MAML) (Finn et al., 2017a) to fast adaptation to new classification tasks in the presence of unlabeled data. Using synthetic data, we show that MAML can adapt to new tasks without any labeled examples (unsupervised adaptation) when the new task has the same output space (classes) as the training tasks do. We further extend MAML to the semi-supervised few-shot learning scenario, when the output space of the new tasks can be different from the training tasks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-537">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/537">Kronecker Recurrent Units</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Cijo Jose &middot; Moustapha Cisse &middot; Francois Fleuret</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-537"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-537" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-537" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-537">
                Abstract <i id="caret-537" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-537">
    <div class="abstract-display">
        <p>Our work addresses two important issues with recurrent neural networks: (1) they are over-parameterized, and (2) the recurrent weight matrix is ill-conditioned. The former increases the sample complexity of learning and the training time. The latter causes the vanishing and exploding gradient problem. We present a flexible recurrent neural network model called Kronecker Recurrent Units (KRU). KRU achieves parameter efficiency in RNNs through a Kronecker factored recurrent matrix. It overcomes the ill-conditioning of the recurrent matrix by enforcing soft unitary constraints on the factors. Thanks to the small dimensionality of the factors, maintaining these constraints is computationally efficient. Our experimental results on seven standard data-sets reveal that KRU can reduce the number of parameters by three orders of magnitude in the recurrent weight matrix compared to the existing recurrent models, without trading the statistical performance. These results in particular show that while there are advantages in having a high dimensional recurrent space, the capacity of the recurrent part of the model can be dramatically reduced.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-527">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/527">Variance-based Gradient Compression for Efficient Distributed Deep Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yusuke Tsuzuku &middot; Hiroto Imachi &middot; Takuya Akiba</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-527"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-527" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-527" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-527">
                Abstract <i id="caret-527" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-527">
    <div class="abstract-display">
        <p>Due to the substantial computational cost, training state-of-the-art deep neural networks for large-scale datasets often requires distributed training using multiple computation workers. However, by nature, workers need to frequently communicate gradients, causing severe bottlenecks, especially on lower bandwidth connections. A few methods have been proposed to compress gradient for efficient communication, but they either suffer a low compression ratio or significantly harm the resulting model accuracy, particularly when applied to convolutional neural networks. To address these issues, we propose a method to reduce the communication overhead of distributed deep learning. Our key observation is that gradient updates can be delayed until an unambiguous (high amplitude, low variance) gradient has been calculated. We also present an efficient algorithm to compute the variance and prove that it can be obtained with negligible additional cost. We experimentally show that our method can achieve very high compression ratio while maintaining the result model accuracy. We also analyze the efficiency using computation and communication cost models and provide the evidence that this method enables distributed deep learning for many scenarios with commodity environments.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-501">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/501">Attacking the Madry Defense Model with $L_1$-based Adversarial Examples</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yash Sharma &middot; Pin-Yu Chen</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-501"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-501" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-501" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-501">
                Abstract <i id="caret-501" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-501">
    <div class="abstract-display">
        The Madry Lab recently hosted a competition designed to test the robustness of their adversarially trained MNIST model. Attacks were constrained to perturb each pixel of the input image by a scaled maximal $L_\infty$ distortion $\epsilon$ = 0.3. This decision discourages the use of attacks which are not optimized on the $L_\infty$ distortion metric. Our experimental results demonstrate that by relaxing the $L_\infty$ constraint of the competition, the \textbf{e}lastic-net \textbf{a}ttack to \textbf{d}eep neural networks (EAD) can generate transferable adversarial examples which, despite their high average $L_\infty$ distortion, have minimal visual distortion. These results call into question the use of $L_\infty$ as a sole measure for visual distortion, and further demonstrate the power of EAD at generating robust adversarial examples.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-500">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/500">Adversarial Spheres</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Justin Gilmer &middot; Luke Metz &middot; Fartash Faghri &middot; Samuel Schoenholz &middot;   &middot; Martin Wattenberg &middot; Ian Goodfellow</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-500"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-500" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-500" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-500">
                Abstract <i id="caret-500" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-500">
    <div class="abstract-display">
        State of the art computer vision models have been shown to be vulnerable to small adversarial perturbations of the input. In other words, most images in the data distribution are both correctly classified by the model and are very close to a visually similar misclassified image. Despite substantial research interest, the cause of the phenomenon is still poorly understood and remains unsolved. We hypothesize that this counter intuitive behavior is a naturally occurring result of the high dimensional geometry of the data manifold. As a first step towards exploring this hypothesis, we study a simple synthetic dataset of classifying between two concentric high dimensional spheres. For this dataset we show a fundamental tradeoff between the amount of test error and the average distance to nearest error. In particular, we prove that any model which misclassifies a small constant fraction of a sphere will be vulnerable to adversarial perturbations of size $O(1/\sqrt{d})$. Surprisingly, when we train several different architectures on this dataset, all of their error sets naturally approach this theoretical bound. As a result of the theory, the vulnerability of neural networks to small adversarial perturbations is a logical consequence of the amount of test error observed. We hope that …
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-502">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/502">Stable Distribution Alignment Using the Dual of the Adversarial Distance</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ben Usman &middot; Kate Saenko &middot; Brian Kulis</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-502"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-502" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-502" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-502">
                Abstract <i id="caret-502" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-502">
    <div class="abstract-display">
        <p>Methods that align distributions by minimizing an adversarial distance between them have recently achieved impressive results. However, these approaches are difficult to optimize with gradient descent and they often do not converge well without careful hyperparameter tuning and proper initialization. We investigate whether turning the adversarial min-max problem into an optimization problem by replacing the maximization part with its dual improves the quality of the resulting alignment and explore its connections to Maximum Mean Discrepancy. Our empirical results suggest that using the dual formulation for the restricted family of linear discriminators results in a more stable convergence to a desirable solution when compared with the performance of a primal min-max GAN-like objective and an MMD objective under the same restrictions. We test our hypothesis on the problem of aligning two synthetic point clouds on a plane and on a real-image domain adaptation problem on digits. In both cases, the dual formulation yields an iterative procedure that gives more stable and monotonic improvement over time.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-596">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/596">Stacked Filters Stationary Flow For Hardware-Oriented Acceleration Of Deep Convolutional Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yuechao Gao &middot; Nianhong Liu &middot; Zhang Sheng</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-596"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-596" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-596" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-596">
                Abstract <i id="caret-596" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-596">
    <div class="abstract-display">
        <p>To address memory and computation resource limitations for hardware-oriented acceleration of deep convolutional neural networks(CNNs), we present a computation flow, stacked filters stationary flow (SFS), and a corresponding data encoding format, relative indexed compressed sparse filter format (CSF), to make the best of data sparsity, and simplify data handling at execution time. Comparing with the state-of-the-art result (Han et al., 2016b), our methods achieve 1.11x improvement in reducing the storage required by AlexNet, and 1.09x improvement in reducing the storage required by SqueezeNet, without loss of accuracy on the ImageNet dataset. Moreover, using these approaches, chip area for logics handling irregular sparse data access can be saved. Comparing with the 2D-SIMD processure structures in DVAS, ENVISION, etc., our methods achieve about 3.65x processing element (PE) array utilization rate improvement (from 26.4% to 96.5%), using the data from Deep Compression on AlexNet.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-487">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/487">ReinforceWalk: Learning to Walk in Graph with Monte Carlo Tree Search</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yelong Shen &middot; Jianshu Chen &middot; Po-Sen Huang &middot; Yuqing Guo &middot; Jianfeng Gao</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-487"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-487" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-487" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-487">
                Abstract <i id="caret-487" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-487">
    <div class="abstract-display">
        <p>We consider the problem of learning to walk over a graph towards a target node for a given input query and a source node (e.g., knowledge graph reasoning). We propose a new method called ReinforceWalk, which consists of a deep recurrent neural network (RNN) and a Monte Carlo Tree Search (MCTS). The RNN encodes the history of observations and map it into the Q-value, the policy and the state value. The MCTS is combined with the RNN policy to generate trajectories with more positive rewards, overcoming the sparse reward problem. Then, the RNN policy is updated in an off-policy manner from these trajectories. ReinforceWalk repeats these steps to learn the policy. At testing stage, the MCTS is also combined with the RNN to predict the target node with higher accuracy. Experiment results show that we are able to learn better policies from less number of rollouts compared to other methods, which are mainly based on policy gradient method.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-533">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/533">A differentiable BLEU loss. Analysis and first results</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">noe casas &middot; Marta R. Costa-jussà &middot; Jose A.R Fonollosa</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-533"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-533" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-533" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-533">
                Abstract <i id="caret-533" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-533">
    <div class="abstract-display">
        <p>In natural language generation tasks, like neural machine translation and image captioning, there is usually a mismatch between the optimized loss and the de facto evaluation criterion, namely token-level maximum likelihood and corpus-level BLEU score. This article tries to reduce this gap by defining differentiable computations of the BLEU and GLEU scores. We test this approach on simple tasks, obtaining valuable lessons on its potential applications but also its pitfalls, mainly that these loss functions push each token in the hypothesis sequence toward the average of the tokens in the reference, resulting in a poor training signal.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-480">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/480">Depth separation and weight-width trade-offs for sigmoidal neural networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Amit Jayant Deshpande &middot; Navin Goyal &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-480"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-480" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-480" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-480">
                Abstract <i id="caret-480" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-480">
    <div class="abstract-display">
        Recent work has shown strong separation between the expressive power of depth-$2$ and depth-$3$ neural networks. These separation results exhibit a function and an input distributions, so that the function is well-approximable in $L_{2}$-norm on the input distribution by a depth-$3$ neural network of polynomial size but any depth-$2$ neural network that well-approximates it requires exponential size. A limitations of these results is that they work only for certain careful choices of functions and input distributions that are arguably not natural enough.

We provide a simple proof of $L_{2}$-norm separation between the expressive power of depth-$2$ and depth-$3$ sigmoidal neural networks for a large class of input distributions, assuming their weights are polynomially bounded. Our proof is simpler than previous results, uses known low-degree multivariate polynomial approximations to neural networks, and gives the first depth-$2$-vs-depth-$3$ separation that works for a large class of input distributions.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-579">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/579">Challenges in Disentangling Independent Factors of Variation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Attila Szabo &middot; Qiyang Hu &middot; Tiziano Portenier &middot; Matthias Zwicker &middot; Paolo Favaro</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-579"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-579" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-579" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-579">
                Abstract <i id="caret-579" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-579">
    <div class="abstract-display">
        <p>We study the problem of building models that disentangle independent factors of variation. Such models encode features that can efficiently be used for classification and to transfer attributes between different images in image synthesis. As data we use a weakly labeled training set, where labels indicate what single factor has changed between two data samples, although the relative value of the change is unknown. This labeling is of particular interest as it may be readily available without annotation costs. We introduce an autoencoder model and train it through constraints on image pairs and triplets. We show the role of feature dimensionality and adversarial training theoretically and experimentally. We formally prove the existence of the reference ambiguity, which is inherently present in the disentangling task when weakly labeled data is used. The numerical value of a factor has different meaning in different reference frames. When the reference depends on other factors, transferring that factor becomes ambiguous. We demonstrate experimentally that the proposed model can successfully transfer attributes on several datasets, but show also cases when the reference ambiguity occurs.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-562">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/562">Covariant Compositional Networks For Learning Graphs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Risi Kondor &middot; Truong Son Hy &middot;   &middot; Brandon Anderson &middot; Shubhendu Trivedi</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-562"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-562" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-562" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-562">
                Abstract <i id="caret-562" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-562">
    <div class="abstract-display">
        <p>Most existing neural networks for learning graphs deal with the issue of permutation invariance by conceiving of the network as a message passing scheme, where each node sums the feature vectors coming from its neighbors. We argue that this imposes a limitation on their representation power, and instead propose a new general architecture for representing objects consisting of a hierarchy of parts, which we call Covariant Compositional Networks (CCNs). Here covariance means that the activation of each neuron must transform in a specific way under permutations, similarly to steerability in CNNs. We achieve covariance by making each activation transform according to a tensor representation of the permutation group, and derive the corresponding tensor aggregation rules that each neuron must implement. Experiments show that CCNs can outperform competing methods on some standard graph learning benchmarks. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-549">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/549">No Spurious Local Minima in a Two Hidden Unit ReLU Network</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chenwei Wu &middot; jiajun luo &middot; Jason D Lee</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-549"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-549" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-549" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-549">
                Abstract <i id="caret-549" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-549">
    <div class="abstract-display">
        <p>Deep learning models can be efficiently optimized via stochastic gradient descent, but there is little theoretical evidence to support this. A key question in optimization is to understand when the optimization landscape of a neural network is amenable to gradient-based optimization. We focus on a simple neural network two-layer ReLU network with two hidden units, and show that all local minimizers are global. This combined with recent work of Lee et al. (2017); Lee et al. (2016) show that  gradient descent converges to the global minimizer.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-548">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/548">Isolating Sources of Disentanglement in Variational Autoencoders</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tian Qi Chen &middot; Xuechen Li &middot; Roger Grosse &middot; David Duvenaud</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-548"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-548" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-548" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-548">
                Abstract <i id="caret-548" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-548">
    <div class="abstract-display">
        <p>We decompose the evidence lower bound (ELBO) to show the existence of a total correlation term between latents. This motivates our beta-TCVAE (Total Correlation Variational Autoencoder), a refinement of the state-of-the-art beta-VAE for learning disentangled representations without supervision. We further propose a principled classifier-free measure of disentanglement called the Mutual Information Gap (MIG). We show a strong relationship between total correlation and disentanglement. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-539">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/539">IamNN: Iterative and Adaptive Mobile Neural Network for efficient image classification</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Sam Leroux &middot; Pavlo Molchanov &middot; Pieter Simoens &middot; Bart Dhoedt &middot; Thomas Breuel &middot; Jan Kautz</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-539"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-539" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-539" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-539">
                Abstract <i id="caret-539" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-539">
    <div class="abstract-display">
        <p>Deep residual networks (ResNets) made a recent breakthrough in deep learning. The core idea of ResNets is to have shortcut connections between layers that allow the network to be much deeper while still being easy to optimize avoiding vanishing gradients. These shortcut connections have interesting properties that make ResNets behave differently from other typical network architectures. In this work we use these properties to design a network based on a ResNet but with parameter sharing and with adaptive computation time. The resulting network is much smaller than the original network and can adapt the computational cost to the complexity of the input image.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-513">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/513">Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Vitalii Zhelezniak &middot; Dan Busbridge &middot; April Shen &middot; Samuel Smith &middot; Nils Hammerla</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-513"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-513" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-513" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-513">
                Abstract <i id="caret-513" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-513">
    <div class="abstract-display">
        <p>Experimental evidence indicates that simple models outperform complex deep networks on many unsupervised similarity tasks. We provide a simple yet rigorous explanation for this behaviour by introducing the concept of an optimal representation space, in which semantically close symbols are mapped to representations that are close under a similarity measure induced by the model’s objective function. In addition, we present a straightforward procedure that, without any retraining or architectural modifications, allows deep recurrent models to perform equally well (and sometimes better) when compared to shallow models. To validate our analysis, we conduct a set of consistent empirical evaluations and introduce several new sentence embedding models in the process. Even though this work is presented within the context of natural language processing, the insights are readily applicable to other domains that rely on distributed representations for transfer tasks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-509">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/509">Black-box Attacks on Deep Neural Networks via Gradient Estimation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Arjun Nitin Bhagoji &middot; Warren He &middot; Bo Li &middot; Dawn Song</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-509"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-509" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-509" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-509">
                Abstract <i id="caret-509" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-509">
    <div class="abstract-display">
        <p>In this paper, we propose novel Gradient Estimation black-box attacks to generate adversarial examples with query access to the target model's class probabilities, which do not rely on transferability. We also propose strategies to decouple the number of queries required to generate each adversarial example from the dimensionality of the input. An iterative variant of our attack achieves close to 100% attack success rates for both targeted and untargeted attacks on DNNs. We show that the proposed Gradient Estimation attacks outperform all other black-box attacks we tested on both MNIST and CIFAR-10 datasets, achieving attack success rates similar to well known, state-of-the-art white-box attacks. We also apply the Gradient Estimation attacks successfully against a real-world content moderation classifier hosted by Clarifai.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-505">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/505">Multiple Source Domain Adaptation with Adversarial Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Han Zhao &middot; Shanghang Zhang &middot; Guanhang Wu &middot;   &middot; José Moura &middot; Geoff Gordon</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-505"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-505" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-505" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-505">
                Abstract <i id="caret-505" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-505">
    <div class="abstract-display">
        <p>While domain adaptation has been actively researched in recent years, most theoretical results and algorithms focus on the single-source-single-target adaptation setting. Naive application of such algorithms on multiple source domain adaptation problem may lead to suboptimal solutions. We propose a new generalization bound for domain adaptation when there are multiple source domains with labeled instances and one target domain with unlabeled instances. Compared with existing bounds, the new bound does not require expert knowledge about the target distribution, nor the optimal combination rule for multisource domains. Interestingly, our theory also leads to an efficient learning strategy using adversarial neural networks: we show how to interpret it as learning feature representations that are invariant to the multiple domain shifts while still being discriminative for the learning task. To this end, we propose two models, both of which we call multisource domain adversarial networks (MDANs): the first model optimizes directly our bound, while the second model is a smoothed approximation of the first one, leading to a more data-efficient and task-adaptive model. The optimization tasks of both models are minimax saddle point problems that can be optimized by adversarial training. To demonstrate the effectiveness of MDANs, we conduct extensive experiments showing superior …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-504">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/504">Distributional Adversarial Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chengtao Li &middot; David Alvarez-Melis &middot; Keyulu Xu &middot; Stefanie Jegelka &middot; Suvrit Sra</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-504"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-504" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-504" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-504">
                Abstract <i id="caret-504" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-504">
    <div class="abstract-display">
        <p>In most current formulations of adversarial training, the discriminators can be expressed as single-input operators, that is, the mapping they define is separable over observations. In this work, we argue that this property might help explain the infamous mode collapse phenomenon in adversarially-trained generative models. Inspired by discrepancy measures and two-sample tests between probability distributions, we propose distributional adversaries that operate on samples, i.e., on sets of multiple points drawn from a distribution, rather than on single observations. We show how they can be easily implemented on top of existing models. Various experimental results show that generators trained in combination with our distributional adversaries are much more stable and are remarkably less prone to mode collapse than traditional models trained with observation-wise prediction discriminators. In addition, the application of our framework to domain adaptation results in strong improvement over baselines.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-499">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/499">Understanding the Loss Surface of Single-Layered Neural Networks for Binary Classification</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Shiyu Liang &middot; Ruoyu Sun &middot; Yixuan Li &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-499"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-499" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-499" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-499">
                Abstract <i id="caret-499" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-499">
    <div class="abstract-display">
        <p>It is widely conjectured that the reason that training algorithms for neural networks are successful because all local minima lead to similar performance; for example, see (LeCun et al., 2015; Choromanska et al., 2015; Dauphin et al., 2014). Performance is typically measured in terms of two metrics: training performance and generalization performance. Here we focus on the training performance of single-layered neural networks for binary classification, and provide conditions under which the training error is zero at all local minima of a smooth hinge loss function. Our conditions are roughly in the following form: the neurons have to be strictly convex and the surrogate loss function should be a smooth version of hinge loss. We also provide counterexamples to show that when the loss function is replaced with quadratic loss or logistic loss, the result may not hold.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-495">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/495">Diversity-Driven Exploration Strategy for Deep Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zhang-Wei Hong &middot; Tzu-Yun Shann &middot; Shih-Yang Su &middot; Yi-Hsiang Chang &middot; Chun-Yi Lee</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-495"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-495" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-495" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-495">
                Abstract <i id="caret-495" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-495">
    <div class="abstract-display">
        <p>Efficient exploration remains a challenging research problem in reinforcement learning, especially when an environment contains large state spaces, deceptive local optima, or sparse rewards. To tackle this problem, we present a diversity-driven approach for exploration, which can be easily combined with both off- and on-policy reinforcement learning algorithms. We show that by simply adding a distance measure to the loss function, the proposed methodology significantly enhances an agent's exploratory behaviors, and thus preventing the policy from being trapped in local optima. We further propose an adaptive scaling method for stabilizing the learning process. Our experimental results in Atari 2600 show that our method outperforms baseline approaches in several tasks in terms of mean scores and exploration efficiency.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-494">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/494">SpectralWords: Spectral Embeddings Approach to Word Similarity Task for Large Vocabularies</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ivan Lobov</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-494"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-494" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-494" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-494">
                Abstract <i id="caret-494" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-494">
    <div class="abstract-display">
        <p>In this paper we show how recent advances in spectral clustering using Bethe Hessian operator can be used to learn dense word representations. We propose an algorithm SpectralWords that achieves comparable to the state-of-the-art performance on word similarity tasks for medium-size vocabularies and can be superior for datasets with larger vocabularies.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-486">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/486">Coupled Ensembles of Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Anuvabh Dutt &middot; Denis Pellerin &middot; Georges Quénot</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-486"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-486" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-486" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-486">
                Abstract <i id="caret-486" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-486">
    <div class="abstract-display">
        <p>We present coupled ensembles of neural networks, which is a reconfiguration of existing neural network models into parallel branches. We empirically show that this modification leads to results on CIFAR and SVHN that are competitive to state of the art, with a greatly reduced parameter count. Additionally, for a fixed parameter, or a training time budget coupled ensembles are significantly better than single branch models. Preliminary results on ImageNet are also promising.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-484">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/484">THE EFFECTIVENESS OF A TWO-LAYER NEURAL NETWORK FOR RECOMMENDATIONS</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Oleg Rybakov &middot; Vijai Mohan &middot;   &middot; Scott LeGrand &middot; Rejith Joseph &middot; Kiuk Chung &middot; Siddharth Singh &middot; Qian You &middot; Eric Nalisnick &middot; Leo Dirac &middot; Runfei Luo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-484"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-484" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-484" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-484">
                Abstract <i id="caret-484" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-484">
    <div class="abstract-display">
        <p>We present a personalized recommender system using neural network for recommending
products, such as eBooks, audio-books, Mobile Apps, Video and Music.
It produces recommendations based on customer’s implicit feedback history such
as purchases, listens or watches. Our key contribution is to formulate recommendation
problem as a model that encodes historical behavior to predict the future
behavior using soft data split, combining predictor and auto-encoder models. We
introduce convolutional layer for learning the importance (time decay) of the purchases
depending on their purchase date and demonstrate that the shape of the time
decay function can be well approximated by a parametrical function. We present
offline experimental results showing that neural networks with two hidden layers
can capture seasonality changes, and at the same time outperform other modeling
techniques, including our recommender in production. Most importantly, we
demonstrate that our model can be scaled to all digital categories, and we observe
significant improvements in an online A/B test. We also discuss key enhancements
to the neural network model and describe our production pipeline. Finally
we open-sourced our deep learning library which supports multi-gpu model parallel
training. This is an important feature in building neural network based recommenders
with large dimensionality of input …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-477">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/477">Learning Longer-term Dependencies in RNNs with Auxiliary Losses</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Trieu Trinh &middot; Andrew Dai &middot; Thang Luong &middot; Quoc V Le</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-477"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-477" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-477" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-477">
                Abstract <i id="caret-477" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-477">
    <div class="abstract-display">
        <p>We present a simple method to improve learning long-term dependencies in recurrent neural networks (RNNs) by introducing unsupervised auxiliary losses. These auxiliary losses force RNNs to either remember distant past or predict future, enabling truncated backpropagation through time (BPTT) to work on very long sequences. We experimented on sequences up to 16000 tokens long and report faster training, more resource efficiency and better test performance than full BPTT baselines such as Long Short Term Memory (LSTM) networks or Transformer.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-469">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/469">Adapting to Continuously Shifting Domains</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Andreea Bobu &middot; Eric Tzeng &middot; Judy Hoffman &middot; Trevor Darrell</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-469"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-469" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-469" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-469">
                Abstract <i id="caret-469" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-469">
    <div class="abstract-display">
        <p>Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-462">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/462">Concept Learning with Energy-Based Models</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Igor Mordatch</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-462"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-462" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-462" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-462">
                Abstract <i id="caret-462" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-462">
    <div class="abstract-display">
        <p>We believe that many hallmarks of human intelligence, such as generalizing from limited experience, abstract reasoning and planning, analogical reasoning, creative problem solving, and capacity for language require the ability to consolidate experience into concepts, which act as basic building blocks of understanding and reasoning.
We present a framework that defines a concept by an energy function over events in the environment, as well as an attention mask over entities participating in the event. Given few demonstration events, our method uses inference-time optimization procedure to generate events involving similar concepts or identify entities involved in the concept.
We evaluate our framework on learning visual, quantitative, compositional, and relational concepts from demonstration events in an unsupervised manner. Our approach is able to successfully generate and identify concepts in a few-shot setting as well as transfer learned concepts between domains.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-432">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/432">Practical Hyperparameter Optimization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Stefan Falkner &middot;   &middot;  </div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-432"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-432" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-432" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-432">
                Abstract <i id="caret-432" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-432">
    <div class="abstract-display">
        <p>Recently, the bandit-based strategy Hyperband (HB) was shown to yield good
hyperparameter settings of deep neural networks faster than vanilla Bayesian
optimization (BO). However, for larger budgets, HB is limited by its random search
component, and BO works better. We propose to combine the benefits of both
approaches to obtain a new practical state-of-the-art hyperparameter optimization
method, which we show to consistently outperform both HB and BO on a range
of problem types, including feed-forward neural networks, Bayesian neural networks,
 and deep reinforcement learning. Our method is robust and versatile, while
at the same time being conceptually simple and easy to implement.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-412">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/412">Learning Invariances for Policy Generalization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Remi Combes &middot;   &middot; Harm Seijen</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-412"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-412" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-412" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-412">
                Abstract <i id="caret-412" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-412">
    <div class="abstract-display">
        <p>While recent progress has spawned very powerful machine learning systems, those agents remain extremely specialized and fail to transfer the knowledge they gain to similar yet unseen tasks. In this paper, we study a simple reinforcement learning problem and focus on learning policies that encode the proper invariances for generalization to different settings. We evaluate three potential methods for policy generalization: data augmentation, meta-learning and adversarial training. We find our data augmentation method to be effective, and study the potential of meta-learning and adversarial learning as alternative task-agnostic approaches.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-482">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/482">Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Robert DiPietro &middot; Christian Rupprecht &middot; Nassir Navab &middot; Gregory Hager</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-482"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-482" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-482" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-482">
                Abstract <i id="caret-482" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-482">
    <div class="abstract-display">
        <p>Recurrent neural networks (RNNs) have achieved state-of-the-art performance on many diverse tasks, from machine translation to surgical activity recognition, yet training RNNs to capture long-term dependencies remains difficult. To date, the vast majority of successful RNN architectures alleviate this problem using nearly-additive connections between states, as introduced by long short-term memory (LSTM). We take an orthogonal approach and introduce MIST RNNs, a NARX RNN architecture that allows direct connections from the very distant past. We show that MIST RNNs 1) exhibit superior vanishing-gradient properties in comparison to LSTM and previously-proposed NARX RNNs; 2) are far more efficient than previously-proposed NARX RNN architectures, requiring even fewer computations than LSTM; and 3) improve performance substantially over LSTM and Clockwork RNNs on tasks requiring very long-term dependencies.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-476">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/476">AUTOMATED DESIGN USING NEURAL NETWORKS AND GRADIENT DESCENT</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">oliver hennigh</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-476"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-476" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-476" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-476">
                Abstract <i id="caret-476" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-476">
    <div class="abstract-display">
        <p>We propose a novel method that makes use of deep neural networks and gradient decent to perform automated design on complex real world engineering tasks. Our approach works by training a neural network to mimic the fitness function of a design optimization task and then, using the differential nature of the neural network, perform gradient decent to maximize the fitness. We demonstrate this methods effectiveness by designing an optimized heat sink and both 2D and 3D airfoils that maximize the lift drag ratio under steady state flow conditions. We highlight that our method has two distinct benefits over other automated design approaches. First, evaluating the neural networks prediction of fitness can be orders of magnitude faster then simulating the system of interest. Second, using gradient decent allows the design space to be searched much more efficiently then other gradient free methods. These two strengths work together to overcome some of the current shortcomings of automated design.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-559">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/559">COLD FUSION: TRAINING SEQ2SEQ MODELS TOGETHER WITH LANGUAGE MODELS</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Anuroop Sriram &middot; Heewoo Jun &middot; Sanjeev Satheesh &middot; Adam Coates</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-559"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-559" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-559" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-559">
                Abstract <i id="caret-559" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-559">
    <div class="abstract-display">
        <p>Sequence-to-sequence (Seq2Seq) models with attention have excelled at tasks which involve generating natural language sentences such as machine translation, image captioning and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language model. In this work, we present the Cold Fusion method, which leverages a pre-trained language model during training, and show its effectiveness on the speech recognition task. We show that Seq2Seq models with Cold Fusion are able to better utilize language information enjoying i) faster convergence and better generalization, and ii) almost complete transfer to a new domain while using less than 10% of the labeled training data.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-534">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/534">Iterative GANs for Rotating Visual Objects</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ysbrand Galama &middot; Thomas Mensink</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-534"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-534" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-534" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-534">
                Abstract <i id="caret-534" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-534">
    <div class="abstract-display">
        <p>We are interested in learning visual representations which allow for 3D manipulations of visual objects based on a single 2D image. We cast this into an image-to-image transformation task, and propose Iterative Generative Adversarial Networks (IterGANs) to learn a visual representation that can be used for objects seen in training, but also for never seen objects. Since object manipulation requires a full understanding of the geometry and appearance of the object, our IterGANs learn an implicit 3D model and a full appearance model of the object, which are both inferred from a single (test) image. Moreover, the intermediate generated images from IterGANs can be used by additional loss functions to increase the quality of all generated images without the need for additional supervision. Experiments on rotated objects show how iterGANs help with the generation process.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-518">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/518">Efficient Entropy For Policy Gradient with Multi-Dimensional Action Space</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yiming Zhang &middot; Quan Vuong &middot; Kenny Song &middot; Xiao-Yue Gong &middot; Keith Ross</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-518"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-518" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-518" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-518">
                Abstract <i id="caret-518" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-518">
    <div class="abstract-display">
        <p>This paper considers entropy bonus, which is used to encourage exploration in policy gradient. In the case of high-dimensional action spaces, calculating the entropy and its gradient requires enumerating all the actions in the action space and running forward and backpropagation for each action, which may be computationally infeasible. We develop several novel unbiased estimators for the entropy bonus and its gradient. We apply these estimators to several models for the parameterized policies, including Independent Sampling, CommNet, Autoregressive with Modified MDP, and Autoregressive with LSTM. Finally, we test our algorithms on a multi-hunter multi-rabbit grid environment. The results show that our entropy estimators substantially improve performance with marginal additional computational cost.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-541">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/541">Training Shallow and Thin Networks for Acceleration via Knowledge Distillation with Conditional Adversarial Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zheng Xu &middot; Yen-Chang Hsu &middot; Jiawei Huang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-541"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-541" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-541" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-541">
                Abstract <i id="caret-541" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-541">
    <div class="abstract-display">
        <p>There is an increasing interest on accelerating neural networks for real-time applications. We study the student-teacher strategy, in which a small and fast student network is trained with the auxiliary information learned from a large and accurate teacher network. We propose to use conditional adversarial networks to learn the loss function to transfer knowledge from teacher to student. The experiments on three different image datasets show the student network gain a performance boost with proposed training strategy.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-419">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/419">DiCE: The Infinitely Differentiable Monte-Carlo Estimator</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jakob Foerster &middot; Gregory Farquhar &middot; Maruan Al-Shedivat &middot; Tim Rocktaeschel &middot; Eric P Xing &middot; Shimon Whiteson</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-419"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-419" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-419" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-419">
                Abstract <i id="caret-419" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-419">
    <div class="abstract-display">
        <p>The score function estimator is widely used for estimating gradients of stochastic objectives in Stochastic Computation Graphs (SCG), eg. in reinforcement learning and meta-learning. While deriving the first-order gradient estimators by differentiating a surrogate loss (SL) objective is computationally and conceptually simple, using the same approach for higher-order gradients is more challenging. Firstly, analytically deriving and implementing such estimators is laborious and not compliant with automatic differentiation. Secondly, repeatedly applying SL to construct new objectives for each order gradient involves increasingly cumbersome graph manipulations. Lastly, to match the first-order gradient under differentiation, SL treats part of the cost as a fixed sample, which we show leads to missing and wrong terms for higher-order gradient estimators. To address all these shortcomings in a unified way, we introduce DiCE, which provides a single objective that can be differentiated repeatedly, generating correct gradient estimators of any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the requisite graph manipulations. We verify the correctness of DiCE both through a proof and through numerical evaluation of the DiCE gradient estimates. We also use DiCE to propose and evaluate a novel approach for multi-agent learning. Our code is available at https://goo.gl/xkkGxN.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-496">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/496">Weighted Geodesic Distance Following Fermat&#x27;s Principle</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Facundo Sapienza &middot; Pablo Groisman &middot; Matthieu Jonckheere</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-496"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-496" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-496" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-496">
                Abstract <i id="caret-496" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-496">
    <div class="abstract-display">
        <p>We propose a density-based estimator for weighted geodesic distances suitable for data lying on a manifold of lower dimension than ambient space and sampled from a possibly nonuniform distribution. After discussing its properties and implementation, we evaluate its performance as a tool for clustering tasks. A discussion on the consistency of the estimator is also given.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-587">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/587">Beyond Finite Layer Neural Networks: Bridging Deep Architectures and Numerical Differential Equations</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yiping Lu &middot; Aoxiao Zhong &middot; Quanzheng Li &middot; Bin Dong</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-587"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-587" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-587" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-587">
                Abstract <i id="caret-587" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-587">
    <div class="abstract-display">
        <p>Deep neural networks have become the state-of-the-art models in numerous machine learning tasks. However, general guidance to network architecture design is still missing. In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multi-step method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (&gt;50%) the original networks while maintaining a similar performance. This can be explained mathematically using …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-575">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/575">Aspect-based Question Generation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Wenpeng Hu &middot; Bing Liu &middot; Jinwen Ma &middot; Dongyan Zhao &middot; Rui Yan</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-575"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-575" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-575" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-575">
                Abstract <i id="caret-575" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-575">
    <div class="abstract-display">
        <p>Asking questions is an important ability for a chatbot.  Although there are existing works on question generation with a piece of descriptive text, it remains to be a very challenging problem. In this paper, we consider a new question generation problem  which also requires the input of a target aspect in addition to a piece of descriptive text. The key reason for this new problem is that it has been found from practical applications that useful questions need to be targeted toward some relevant aspects. One almost never asks a random question in a conversation. Due to the fact that given a descriptive text, it is often possible to ask many types of questions, generating a question without knowing what it is about is of limited use. in order to solve this problem, we propose a novel neural network which is able to generate aspect-based questions. One major advantage of this model is that it can be trained directly using a question-answering corpus without requiring any additional annotations like annotating aspects in the questions or answers. Experimental results show that our proposed model outperforms the state-of-the-art question generation methods.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-552">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/552">LSH-SAMPLING BREAKS THE COMPUTATIONAL CHICKEN-AND-EGG LOOP IN ADAPTIVE STOCHASTIC GRADIENT ESTIMATION</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Beidi Chen &middot; Yingchen Xu &middot; Anshumali Shrivastava</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-552"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-552" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-552" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-552">
                Abstract <i id="caret-552" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-552">
    <div class="abstract-display">
        <p>Stochastic Gradient Descent or SGD is the most popular optimization algorithm for large-scale problems. SGD estimates the gradient by uniform sampling with sample size one. There have been several other works that suggest faster epoch wise convergence by using weighted non-uniform sampling for better gradient estimates. Unfortunately, the per-iteration cost of maintaining this adaptive distribution for gradient estimation is more than calculating the full gradient. As a result, the false impression of faster convergence in iterations leads to slower convergence in time, which we call a chicken-and-egg loop. In this paper, we break this barrier by providing the first demonstration of a sampling scheme, which leads to superior gradient estimation, while keeping the sampling cost per iteration similar to that of the uniform sampling. Such an algorithm is possible due to the sampling view of Locality Sensitive Hashing (LSH), which came to light recently. As a consequence of superior and fast estimation, we reduce the running time of all existing gradient descent algorithms. We demonstrate the benefits of our proposal on both SGD and AdaGrad.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-498">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/498">Learning Disentangled Representations with Wasserstein Auto-Encoders</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Paul Rubenstein &middot; Bernhard Schoelkopf &middot; Ilya Tolstikhin</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-498"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-498" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-498" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-498">
                Abstract <i id="caret-498" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-498">
    <div class="abstract-display">
        <p>We apply Wasserstein auto-encoders (WAEs) to the problem of disentangled representation learning. We highlight the potential of WAEs with promising results on a benchmark disentanglement task.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-526">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/526">3D-Scene-GAN: Three-dimensional Scene Reconstruction with Generative Adversarial Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chong Yu &middot; Yun Wang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-526"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-526" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-526" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-526">
                Abstract <i id="caret-526" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-526">
    <div class="abstract-display">
        <p>Three-dimensional (3D) Reconstruction is a vital and challenging research topic in advanced computer graphics and computer vision due to the intrinsic complexity and computation cost. Existing methods often produce holes, distortions and obscure parts in the reconstructed 3D models which are not adequate for real usage. The focus of this paper is to achieve high quality 3D reconstruction performance of complicated scene by adopting Generative Adversarial Network (GAN). We propose a novel workflow, namely 3D-Scene-GAN, which can iteratively improve any raw 3D reconstructed models consisting of meshes and textures. 3D-Scene-GAN is a weakly semi-supervised model. It only takes real-time 2D observation images as the supervision, and doesn’t rely on prior knowledge of shape models or any referenced observations. Finally, through the qualitative and quantitative experiments, 3D-Scene-GAN shows compelling advantages over the state-of-the-art methods: balanced rank estimation (BRE) scores are improved by 30%-100% on ICL-NUIM dataset, and 36%-190% on SUN3D dataset. And the mean distance error (MDR) also outperforms other state-of-the-art methods on benchmarks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-434">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/434">Easing non-convex optimization with neural networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">David Lopez-Paz &middot; Levent Sagun</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-434"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-434" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-434" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-434">
                Abstract <i id="caret-434" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-434">
    <div class="abstract-display">
        Despite being non-convex, deep neural networks are surprisingly amenable to optimization by gradient descent. In this note, we use a deep neural network with $D$ parameters to parametrize the input space of a generic $d$-dimensional non-convex optimization problem. Our experiments show that minimizing the over-parametrized $D \gg d$ variables provided by the deep neural network eases and accelerates the optimization of various non-convex test functions.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-503">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/503">Time-Dependent Representation for Neural Event Sequence Prediction</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yang Li &middot; Nan Du &middot; Samy Bengio</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-503"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-503" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-503" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-503">
                Abstract <i id="caret-503" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-503">
    <div class="abstract-display">
        <p>Existing sequence prediction methods are mostly concerned with time-independent sequences, in which the actual time span between events is irrelevant and the distance between events is simply the difference between their order positions in the sequence. While this time-independent view of sequences is applicable for data such as natural languages, e.g., dealing with words in a sentence, it is inappropriate and inefficient for many real world events that are observed and collected at unequally spaced points of time as they naturally arise, e.g., when a person goes to a grocery store or makes a phone call. The time span between events can carry important information about the sequence dependence of human behaviors. In this work, we propose a set of methods for using time in sequence prediction. Because neural sequence models such as RNN are more amenable for handling token-like input, we propose two methods for time-dependent event representation, based on the intuition on how time is tokenized in everyday life and previous work on embedding contextualization. We also introduce two methods for using next event duration as regularization for training a sequence prediction model. We discuss these methods based on recurrent neural nets. We evaluate these methods as well …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-568">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/568">Graph Partition Neural Networks for Semi-Supervised Classification</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Renjie Liao &middot; Marc Brockschmidt &middot; Danny Tarlow &middot; Alexander Gaunt &middot; Raquel Urtasun &middot; Richard Zemel</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-568"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-568" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-568" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-568">
                Abstract <i id="caret-568" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-568">
    <div class="abstract-display">
        <p>We present graph partition neural networks (GPNN), an extension of graph neural
networks (GNNs) able to handle extremely large graphs.
GPNNs alternate between locally propagating information between nodes in small
subgraphs and globally propagating information between the subgraphs.
To efficiently partition graphs, we experiment with spectral partitioning and also
propose a modified multi-seed flood fill for fast processing of large scale graphs.
We extensively test our model on a variety of semi-supervised node
classification tasks.
Experimental results indicate that GPNNs are either superior or comparable to 
state-of-the-art methods on a wide variety of datasets for graph-based 
semi-supervised classification. 
We also show that GPNNs can achieve similar performance as standard GNNs with
fewer propagation steps.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-567">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/567">Additive Margin Softmax for Face Verification</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Feng Wang &middot; Weiyang Liu &middot; Hanjun Dai &middot; Haijun Liu &middot; Jian Cheng</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-567"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-567" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-567" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-567">
                Abstract <i id="caret-567" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-567">
    <div class="abstract-display">
        <p>In this paper, we propose a conceptually simple and geometrically interpretable objective function, i.e. additive margin Softmax (AM-Softmax), for deep face verification. In general, the face verification task can be viewed as a metric learning problem, so learning large-margin face features whose intra-class variation is small and inter-class difference is large is of great importance in order to achieve good performance. Recently, Large-margin Softmax and Angular Softmaxhave been proposed to incorporate the angular margin in a multiplicative manner. In this work, we introduce a novel additive angular margin for the Softmax loss, which is intuitively appealing and more interpretable than the existing works. We also emphasize and discuss the importance of feature normalization in the paper. Most importantly, our experiments on LFW and MegaFace show that our additive margin softmax loss consistently performs better than the current state-of-the-art methods using the same network architecture and training dataset.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-529">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/529">Learning How Not to Act in Text-based Games</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Matan Haroush &middot; Tom Zahavy &middot; Daniel Mankowitz &middot; Shie Mannor</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-529"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-529" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-529" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-529">
                Abstract <i id="caret-529" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-529">
    <div class="abstract-display">
        <p>Large actions spaces impede an agent's ability to learn, especially when many of the actions are redundant or irrelevant. This is especially prevalent in text-based domains. We present the action-elimination architecture which combines the generalization power of Deep Reinforcement Learning and the natural language capabilities of NLP architectures to eliminate unnecessary actions and solves quests in the text-based game of Zork, significantly outperforming the baseline agents.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-507">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/507">Feature-Based Metrics for Exploring the Latent Space of Generative Models</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Samuli Laine</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-507"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-507" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-507" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-507">
                Abstract <i id="caret-507" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-507">
    <div class="abstract-display">
        <p>Several recent papers have treated the latent space of deep generative models, e.g., GANs or VAEs, as Riemannian manifolds. The argument is that operations such as interpolation are better done along geodesics that minimize path length not in the latent space but in the output space of the generator. However, this implicitly assumes that some simple metric such as L2 is meaningful in the output space, even though it is well known that for, e.g., semantic comparison of images it is woefully inadequate. In this work, we consider imposing an arbitrary metric on the generator’s output space and show both theoretically and experimentally that a feature-based metric can produce much more sensible interpolations than the usual L2 metric. This observation leads to the conclusion that analysis of latent space geometry would benefit from using a suitable, explicitly defined metric.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-497">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/497">Wasserstein Auto-Encoders: Latent Dimensionality and Random Encoders</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Paul Rubenstein &middot; Bernhard Schoelkopf &middot; Ilya Tolstikhin</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-497"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-497" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-497" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-497">
                Abstract <i id="caret-497" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-497">
    <div class="abstract-display">
        <p>We study the role of latent space dimensionality in Wasserstein auto-encoders (WAEs). Through experimentation on synthetic and real datasets, we argue that random encoders should be preferred over deterministic encoders.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-464">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/464">In reinforcement learning, all objective functions are not equal</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Romain Laroche &middot; Harm van Seijen</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-464"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-464" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-464" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-464">
                Abstract <i id="caret-464" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-464">
    <div class="abstract-display">
        We study the learnability of value functions. We get the reward back propagation out of the way by fitting directly a deep neural network on the analytically computed optimal value function, given a chosen objective function. We show that some objective functions are easier to train than others by several magnitude orders. We observe in particular the influence of the $\gamma$ parameter and the decomposition of the task into subtasks.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-584">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/584">DNA-GAN: Learning Disentangled Representations from Multi-Attribute Images</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Taihong Xiao &middot; Jiapeng Hong &middot; Jinwen Ma</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-584"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-584" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-584" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-584">
                Abstract <i id="caret-584" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-584">
    <div class="abstract-display">
        <p>Disentangling factors of variation has become a very challenging problem on representation learning. Existing algorithms suffer from many limitations, such as unpredictable disentangling factors, poor quality of generated images from encodings, lack of identity information, etc. In this paper, we propose a supervised learning model called DNA-GAN which tries to disentangle different factors or attributes of images. The latent representations of images are DNA-like, in which each individual piece (of the encoding) represents an independent factor of the variation. By annihilating the recessive piece and swapping a certain piece of one latent representation with that of the other one, we obtain two different representations which could be decoded into two kinds of images with the existence of the corresponding attribute being changed. In order to obtain realistic images and also disentangled representations, we further introduce the discriminator for adversarial training. Experiments on Multi-PIE and CelebA datasets finally demonstrate that our proposed method is effective for factors disentangling and even overcome certain limitations of the existing methods.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-511">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/511">Convolutional Sequence Modeling Revisited</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Shaojie Bai &middot; Zico Kolter &middot; Vladlen Koltun</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-511"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-511" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-511" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-511">
                Abstract <i id="caret-511" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-511">
    <div class="abstract-display">
        <p>Although both convolutional and recurrent architectures have a
long history in sequence prediction, the current "default" mindset in much of
the deep learning community is that generic sequence modeling is best handled
using recurrent networks.  Yet recent results indicate that convolutional architectures
can outperform recurrent networks on tasks such as audio synthesis and machine
translation. Given a new sequence modeling task or dataset, which architecture
should a practitioner use? We conduct a systematic evaluation of generic
convolutional and recurrent architectures for sequence modeling.
In particular, the models are evaluated across a broad range of standard tasks that are
commonly used to benchmark recurrent networks. Our results indicate that a
simple convolutional architecture outperforms canonical recurrent networks
such as LSTMs across a diverse range of tasks and datasets, while demonstrating
longer effective memory. We further show that thepotential "infinite memory" advantage 
that RNNs have over TCNs is largely absent in practice: TCNs indeed exhibit longer 
effective history sizes than their recurrent counterparts.   As a whole, we argue that 
it may be time to (re)consider ConvNets as the default ``go to'' architecture for sequence
modeling.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-512">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/512">Scalable Estimation via LSH Samplers (LSS)</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ryan Spring &middot; Anshumali Shrivastava</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-512"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-512" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-512" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-512">
                Abstract <i id="caret-512" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-512">
    <div class="abstract-display">
        <p>The softmax function has multiple applications in large-scale machine learning. However, calculating the partition function is a major bottleneck for large state spaces. In this paper, we propose a new sampling scheme using locality-sensitive hashing (LSH) and an unbiased estimator that approximates the partition function accurately in sub-linear time. The samples are correlated and unnormalized, but the derived estimator is unbiased. We demonstrate the significant advantages of our proposal by comparing the speed and accuracy of LSH-Based Samplers (LSS) against other state-of-the-art estimation techniques.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-524">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/524">NAM - Unsupervised Cross-Domain Image Mapping without Cycles or GANs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yedid Hoshen &middot; Lior Wolf</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-524"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-524" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-524" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-524">
                Abstract <i id="caret-524" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-524">
    <div class="abstract-display">
        <p>Several methods were recently proposed for Unsupervised Domain Mapping, which is the task of translating images between domains without prior knowledge of correspondences. Current approaches suffer from an instability in training due to relying on GANs which are powerful but highly sensitive to hyper-parameters and suffer from mode collapse. In addition, most methods rely heavily on "cycle" relationships between the domains, which enforce a one-to-one mapping. In this work, we introduce an alternative method: NAM.  NAM relies on a pre-trained generative model of the source domain, and aligns each target image with an image sampled from the source distribution while jointly optimizing the domain mapping function. Experiments are presented validating the effectiveness of our method.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-528">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/528">Ensemble Robustness and Generalization of Stochastic Deep Learning Algorithms</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tom Zahavy &middot; Bingyi Kang &middot; Alexander Sivak &middot; Jiashi Feng &middot; huan xu &middot; Shie Mannor</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-528"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-528" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-528" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-528">
                Abstract <i id="caret-528" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-528">
    <div class="abstract-display">
        <p>The question why deep learning algorithms generalize so well has attracted increasing
research interest. However, most of the well-established approaches,
such as hypothesis capacity, stability or sparseness, have not provided complete
explanations (Zhang et al., 2016; Kawaguchi et al., 2017). In this work, we focus
on the robustness approach (Xu &amp; Mannor, 2012), i.e., if the error of a hypothesis
will not change much due to perturbations of its training examples, then it
will also generalize well. As most deep learning algorithms are stochastic (e.g.,
Stochastic Gradient Descent, Dropout, and Bayes-by-backprop), we revisit the robustness
arguments of Xu &amp; Mannor, and introduce a new approach – ensemble
robustness – that concerns the robustness of a population of hypotheses. Through
the lens of ensemble robustness, we reveal that a stochastic learning algorithm can
generalize well as long as its sensitiveness to adversarial perturbations is bounded
in average over training examples. Moreover, an algorithm may be sensitive to
some adversarial examples (Goodfellow et al., 2015) but still generalize well. To
support our claims, we provide extensive simulations for different deep learning
algorithms and different network architectures exhibiting a strong correlation between
ensemble robustness and the ability to generalize.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-515">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/515">Searching for Activation Functions</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Prajit Ramachandran &middot; Barret Zoph &middot; Quoc V Le</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-515"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-515" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-515" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-515">
                Abstract <i id="caret-515" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-515">
    <div class="abstract-display">
        <p>The choice of activation functions in deep networks has a significant effect on the training dynamics and task performance. Currently, the most successful and widely-used activation function is the Rectified Linear Unit (ReLU). Although various hand-designed alternatives to ReLU have been proposed, none have managed to replace it due to inconsistent gains. In this work, we propose to leverage automatic search techniques to discover new activation functions. Using a combination of exhaustive and reinforcement learning-based search, we discover multiple novel activation functions. We verify the effectiveness of the searches by conducting an empirical evaluation with the best discovered activation function. Our experiments show that the best discovered activation function, f(x) = x * sigmoid(beta * x), which we name Swish, tends to work better than ReLU on deeper models across a number of challenging datasets. For example, simply replacing ReLUs with Swish units improves top-1 classification accuracy on ImageNet by 0.9% for Mobile NASNet-A and 0.6% for Inception-ResNet-v2. The simplicity of Swish and its similarity to ReLU make it easy for practitioners to replace ReLUs with Swish units in any neural network. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-542">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/542">PixelSNAIL: An Improved Autoregressive Generative Model</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Xi Chen &middot; Nikhil Mishra &middot; Mostafa Rohaninejad &middot; Pieter Abbeel</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-542"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-542" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-542" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-542">
                Abstract <i id="caret-542" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-542">
    <div class="abstract-display">
        Autoregressive generative models achieve the best results in density estimation tasks involving high dimensional data, such as images or audio.
They pose density estimation as a sequence modeling task, where a recurrent neural network (RNN) models the conditional distribution over the next element conditioned on all previous elements.
In this paradigm, the bottleneck is the extent to which the RNN can model long-range dependencies, and the most successful approaches rely on causal convolutions.
Taking inspiration from recent work in meta reinforcement learning, where dealing with long-range dependencies is also essential, we introduce a new generative model architecture that combines causal convolutions with self attention.
In this paper, we describe the resulting model and present state-of-the-art log-likelihood results on heavily benchmarked datasets: CIFAR-10 (2.85 bits per dim), $32 \times 32$ ImageNet (3.80 bits per dim) and $64 \times 64$ ImageNet (3.52 bits per dim).
Our implementation is publicly available at \url{https://github.com/neocxi/pixelsnail-public}.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-508">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/508">Adaptive Path-Integral Approach for Representation Learning and Planning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jung-Su Ha &middot; Young-Jin Park &middot; Hyeok-Joo Chae &middot; Soon-Seo Park &middot; Han-Lim Choi</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-508"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-508" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-508" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-508">
                Abstract <i id="caret-508" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-508">
    <div class="abstract-display">
        <p>We present a novel framework for representation learning that builds a low-dimensional latent dynamical model from high-dimensional sequential raw data, e.g., video. The framework builds upon recent advances in the amortized inference that constructs a fully-differentiable network, and takes advantage of the duality between control and inference to solve the intractable inference problem using the path integral control approach. We also present the efficient planning method that exploits the learned low-dimensional latent dynamics.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-435">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/435">The Mirage of Action-Dependent Baselines in Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">George Tucker &middot; Surya Bhupatiraju &middot; Shixiang Gu &middot; Richard E Turner &middot; Zoubin Ghahramani &middot; Sergey Levine</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-435"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-435" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-435" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-435">
                Abstract <i id="caret-435" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-435">
    <div class="abstract-display">
        <p>Model-free reinforcement learning with flexible function approximators has shown success in goal-directed sequential decision-making problems. Policy gradient methods are a widely used class of stable model-free algorithms and typically, a state-dependent baseline or control variate is necessary to reduce the gradient estimator variance. Several recent papers extend the baseline to depend on both the state and action, and suggest that this enables significant variance reduction and improved sample efficiency without introducing bias into the gradient estimates. To better understand this development, we decompose the variance of the policy gradient estimator and numerically show that learned state-action-dependent baselines do not in fact reduce variance over a state-dependent baseline in the commonly tested benchmark domains. We confirm this unexpected result by reviewing the open-source code accompanying these prior papers, and show that subtle implementation decisions cause deviations from the methods presented in the papers and explain the sources of the previously observed empirical gains.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-516">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/516">Benefits of Depth for Long-Term Memory of Recurrent Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yoav Levine &middot; Or Sharir &middot; Amnon Shashua</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-516"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-516" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-516" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-516">
                Abstract <i id="caret-516" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-516">
    <div class="abstract-display">
        <p>The key attribute that drives the unprecedented success of modern Recurrent Neural Networks (RNNs) on learning tasks which involve sequential data, is their ever-improving ability to model intricate long-term temporal dependencies. However, a well established measure of RNNs' long-term memory capacity is lacking, and thus formal understanding of their ability to correlate data throughout time is limited. Though depth efficiency in convolutional networks is well established by now, it does not suffice in order to account for the success of deep RNNs on inputs of varying lengths, and the need to address their 'time-series expressive power' arises. In this paper, we analyze the effect of depth on the ability of recurrent networks to express correlations ranging over long time-scales. To meet the above need, we introduce a measure of the information flow across time that can be supported by the network, referred to as the Start-End separation rank. Essentially, this measure reflects the distance of the function realized by the recurrent network from a function that models no interaction whatsoever between the beginning and end of the input sequence. We prove that deep recurrent networks support Start-End separation ranks which are exponentially higher than those supported by their shallow counterparts. …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-517">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/517">Accelerating Neural Architecture Search using Performance Prediction</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Bowen Baker &middot; Otkrist Gupta &middot; Ramesh Raskar &middot; Nikhil Naik</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-517"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-517" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-517" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-517">
                Abstract <i id="caret-517" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-517">
    <div class="abstract-display">
        <p>Methods for neural network hyperparameter optimization and meta-modeling are computationally expensive due to the need to train a large number of model configurations. In this paper, we show that standard frequentist regression models can predict the final performance of partially trained model configurations using features based on network architectures, hyperparameters, and time series validation performance data. We empirically show that our performance prediction models are much more effective than prominent Bayesian counterparts, are simpler to implement, and are faster to train. Our models can predict final performance in both visual classification and language modeling domains, are effective for predicting performance of drastically varying model architectures, and can even generalize between model classes. Using these prediction models, we also propose an early stopping method for hyperparameter optimization and meta-modeling, which obtains a speedup of a factor up to 6x in both hyperparameter optimization and meta-modeling. Finally, we empirically show that our early stopping method can be seamlessly incorporated into both reinforcement learning-based architecture selection algorithms and bandit based search methods. Through extensive experimentation, we empirically show our performance prediction models and early stopping algorithm are state-of-the-art in terms of prediction accuracy and speedup achieved while still identifying the optimal model configurations.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-519">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/519">Faster Discovery of Neural Architectures by Searching for Paths in a Large Model</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Hieu Pham &middot; Melody Y. Guan &middot; Barret Zoph &middot; Quoc V Le &middot; Jeff Dean</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-519"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-519" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-519" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-519">
                Abstract <i id="caret-519" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-519">
    <div class="abstract-display">
        <p>We propose Efficient Neural Architecture Search (ENAS), a faster and less expensive approach to automated model design than previous methods. In ENAS, a controller learns to discover neural network architectures by searching for an optimal path within a larger model. The controller is trained with policy gradient to select a path that maximizes the expected reward on the validation set. Meanwhile the model corresponding to the selected path is trained to minimize the cross entropy loss. On the Penn Treebank dataset, ENAS can discover a novel architecture thats achieves a test perplexity of 57.8, which is state-of-the-art among automatic model design methods on Penn Treebank. On the CIFAR-10 dataset, ENAS can design novel architectures that achieve a test error of 2.89%, close to the 2.65% achieved by standard NAS (Zoph et al., 2017). Most importantly, our experiments show that ENAS is more than 10x faster and 100x less resource-demanding than NAS.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-520">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/520">DLVM: A modern compiler infrastructure for deep learning systems</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Richard Wei &middot; Lane Schwartz &middot; Vikram Adve</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-520"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-520" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-520" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-520">
                Abstract <i id="caret-520" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-520">
    <div class="abstract-display">
        <p>Deep learning software demands reliability and performance. However, many of the existing deep learning frameworks are software libraries that act as an unsafe DSL in Python and a computation graph interpreter. We present DLVM, a design and implementation of a compiler infrastructure with a linear algebra intermediate representation, algorithmic differentiation by adjoint code generation, domain- specific optimizations and a code generator targeting GPU via LLVM. Designed as a modern compiler infrastructure inspired by LLVM, DLVM is more modular and more generic than existing deep learning compiler frameworks, and supports tensor DSLs with high expressivity. With our prototypical staged DSL embedded in Swift, we argue that the DLVM system enables a form of modular, safe and performant frameworks for deep learning.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-522">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/522">Reconstructing evolutionary trajectories of mutations in cancer</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yulia Rubanova &middot; Ruian Shi &middot; Roujia Li &middot; Jeff Wintersinger &middot; Amit Deshwar &middot; Nil Sahin &middot; Quaid Morris</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-522"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-522" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-522" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-522">
                Abstract <i id="caret-522" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-522">
    <div class="abstract-display">
        <p>We present a new method, TrackSig, to estimate evolutionary trajectories in cancer. Our method represents cancer evolution in terms of mutational signatures -- multinomial distributions over mutation types. TrackSig infers an approximate order in which mutations accumulated in cancer genome, and then fits the signatures to the mutation time series. We assess TrackSig's reconstruction accuracy using simulations. We find 1.9% median discrepancy between estimated mixtures and ground truth. The size of the signature change is consistent in 87% cases and direction of change is consistent in 95% of cases. The code is available at https://github.com/YuliaRubanova/TrackSig.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-523">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/523">DeepNCM: Deep Nearest Class Mean Classifiers</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Samantha Guerriero &middot; Barbara Caputo &middot; Thomas Mensink</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-523"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-523" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-523" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-523">
                Abstract <i id="caret-523" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-523">
    <div class="abstract-display">
        <p>In this paper we introduce DeepNCM, a Nearest Class Mean classification method enhanced to directly learn highly non-linear deep (visual) representations of the data. To overcome the computational expensive process of recomputing the class means after every update of the representation, we opt for approximating the class means with an online estimate. Moreover, to allow the class means to follow closely the drifting representation we introduce per epoch mean condensation. Using online class means with condensation, DeepNCM can train efficiently on large datasets. Our experimental results indicate that DeepNCM performs on par with SoftMax optimised networks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-530">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/530">Causal Discovery Using Proxy Variables</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Mateo Rojas-Carulla &middot; Marco Baroni &middot; David Lopez-Paz</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-530"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-530" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-530" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-530">
                Abstract <i id="caret-530" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-530">
    <div class="abstract-display">
        <p>In this paper, we develop a framework to estimate the cause-effect relation between two static entities x and y: for instance, an art masterpiece x and its fraudulent copy y. To this end, we introduce the notion of proxy variables, which allow the construction of a pair of random entities (A,B) from the pair of static entities (x,y). Then, estimating the cause-effect relation between A and B using an observational causal discovery algorithm leads to an estimation of the cause-effect relation between x and y. We evaluate our framework in  vision and language. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-545">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/545">Efficient Recurrent Neural Networks using Structured Matrices in FPGAs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zhe Li &middot; Shuo Wang &middot; Caiwen Ding &middot; Qinru Qiu &middot; Yanzhi Wang &middot; Yun Liang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-545"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-545" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-545" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-545">
                Abstract <i id="caret-545" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-545">
    <div class="abstract-display">
        Recurrent Neural Networks (RNNs) are becoming increasingly important for time series-related applications which require efficient and real-time implementations.The recent pruning based work \textit{ESE}~\citep{han2017ese} suffers from degradation of performance/energy efficiency due to the irregular network structure after pruning.
We propose block-circulant matrices for weight matrix representation in RNNs, thereby achieving simultaneous model compression and acceleration. We aim to implement RNNs in FPGA with highest performance and energy efficiency, with certain accuracy requirement (negligible accuracy degradation). Experimental results on actual FPGA deployments shows that the proposed framework achieves a maximum energy efficiency improvement of 35.7$\times$ compared with ESE.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-553">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/553">Systematic Weight Pruning of DNNs using Alternating Direction Method of Multipliers</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tianyun Zhang &middot;   &middot; Yipeng Zhang &middot; Yanzhi Wang &middot; Makan Fardad</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-553"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-553" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-553" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-553">
                Abstract <i id="caret-553" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-553">
    <div class="abstract-display">
        <p>We present a systematic weight pruning framework of deep neural networks (DNNs) using the alternating direction method of multipliers (ADMM). We first formulate the weight pruning problem of DNNs as a constrained nonconvex optimization problem, and then adopt the ADMM framework for systematic  weight pruning. We show that ADMM is highly suitable for weight pruning due to the computational efficiency it offers. We achieve a much higher compression ratio compared with prior work while maintaining the same test accuracy, together with a faster convergence rate.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-555">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/555">Spectral Capsule Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Mohammad Taha Bahadori</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-555"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-555" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-555" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-555">
                Abstract <i id="caret-555" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-555">
    <div class="abstract-display">
        <p>In search for more accurate predictive models, we customize capsule networks for the learning to diagnose problem. We also propose Spectral Capsule Networks, a novel variation of capsule networks, that converge faster than capsule network with EM routing. Spectral capsule networks  consist of spatial coincidence filters that detect entities based on the alignment of extracted features on a one-dimensional linear subspace. Experiments on a public benchmark learning to diagnose dataset not only shows the success of capsule networks on this task, but also confirm the faster convergence of the spectral capsule networks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-556">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/556">One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Tianhe Yu &middot; Chelsea Finn &middot; Annie Xie &middot; Sudeep Dasari &middot; Tianhao Zhang &middot; Pieter Abbeel &middot; Sergey Levine</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-556"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-556" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-556" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-556">
                Abstract <i id="caret-556" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-556">
    <div class="abstract-display">
        <p>Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a raw video pixels of a human, even when there is substantial domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on a PR2 arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-436">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/436">Gradient-based Optimization of Neural Network Architecture</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Will Grathwohl &middot; Elliot Creager &middot; Seyed Ghasemipour &middot; Richard Zemel</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-436"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-436" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-436" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-436">
                Abstract <i id="caret-436" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-436">
    <div class="abstract-display">
        <p>Neural networks can learn relevant features from data, but their predictive accuracy and propensity to overfit are sensitive to the values of the discrete hyperparameters that specify the network architecture (number of hidden layers, number of units per layer, etc.). Previous work optimized these hyperparmeters via grid search, random search, and black box optimization techniques such as Bayesian optimization. Bolstered by recent advances in gradient-based optimization of discrete stochastic objectives, we instead propose to directly model a distribution over possible architectures and use variational optimization to jointly optimize the network architecture and weights in one training pass. We discuss an implementation of this approach that estimates gradients via the Concrete relaxation, and show that it finds compact and accurate architectures for convolutional neural networks applied to the CIFAR10 and CIFAR100 datasets.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-572">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/572">Exponentially vanishing sub-optimal local minima in multilayer neural networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Daniel Soudry &middot; Elad Hoffer</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-572"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-572" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-572" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-572">
                Abstract <i id="caret-572" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-572">
    <div class="abstract-display">
        <p>Background: Statistical mechanics results (Dauphin et al. (2014); Choromanska et al. (2015)) suggest that local minima with high error are exponentially rare in high dimensions. However, to prove low error guarantees for Multilayer Neural Networks (MNNs), previous works so far required either a heavily modified MNN model or training method, strong assumptions on the labels (e.g., “near” linear separability), or an unrealistically wide hidden layer with \Omega(N) units. <br />
Results: We examine a MNN with one hidden layer of piecewise linear units, a single output, and a quadratic loss. We prove that, with high probability in the limit of N\rightarrow\infty datapoints, the volume of differentiable regions of the empiric loss containing sub-optimal differentiable local minima is exponentially vanishing in comparison with the same volume of global minima, given standard normal input of dimension d<em>0=\tilde{\Omega}(\sqrt{N}), and a more realistic number of d</em>1=\tilde{\Omega}(N/d<em>0) hidden units. We demonstrate our results numerically: for example, 0% binary classification training error on CIFAR with only N/d</em>0 = 16 hidden neurons.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-576">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/576">Towards Variational Generation of Small Graphs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Martin Simonovsky &middot; Nikos Komodakis</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-576"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-576" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-576" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-576">
                Abstract <i id="caret-576" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-576">
    <div class="abstract-display">
        <p>In this paper we propose a generative model for graphs formulated as a variational autoencoder. We sidestep hurdles associated with linearization of graphs by having the decoder output a probabilistic fully-connected graph of a predefined maximum size directly at once. We evaluate on the challenging task of molecule generation. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-586">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/586">Regret Minimization for Partially Observable Deep Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Peter Jin &middot; Sergey Levine &middot; Kurt Keutzer</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-586"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-586" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-586" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-586">
                Abstract <i id="caret-586" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-586">
    <div class="abstract-display">
        <p>Deep reinforcement learning algorithms that estimate state and state-action value functions have been shown to be effective in a variety of challenging domains, including learning control strategies from raw image pixels. However, algorithms that estimate state and state-action value functions typically assume a fully observed state and must compensate for partial or non-Markovian observations by using finite-length frame-history observations or recurrent networks. In this work, we propose a new deep reinforcement learning algorithm based on counterfactual regret minimization that iteratively updates an approximation to a cumulative clipped advantage function and is robust to partially observed state. We demonstrate that on several partially observed reinforcement learning tasks, this new class of algorithms can substantially outperform strong baseline methods: on Pong with single-frame observations, and on the challenging Doom (ViZDoom) and Minecraft (Malmö) first-person navigation benchmarks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-546">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/546">Censoring Representations with Multiple-Adversaries over Random Subspaces</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yusuke Iwasawa &middot; Kotaro Nakayama &middot; Yutaka Matsuo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-546"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-546" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-546" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-546">
                Abstract <i id="caret-546" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-546">
    <div class="abstract-display">
        <p>Adversarial feature learning has been successfully applied to censor the representations of neural networks; for example, AFL could help to learn anonymized representations to avoid privacy issues by constraining the representations with adversarial gradients that confuse the external discriminators that try to discern and extract sensitive information from the activations. In this paper, we propose the ensemble approach for the design of the discriminator based on the intuition that the discriminator need to be robust to the success of the AFL. The empirical validations on three user-anonymization tasks show that our proposed method achieves state-of-the-art performances in all three datasets without significantly harming the utility of data. We also provide initial theoretical results about the generalization error of the adversarial gradients, which suggest that the accuracy of the discriminator is not a deterministic factor for the design of the discriminator. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-543">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/543">PPP-Net: Platform-aware Progressive Search for Pareto-optimal Neural Architectures</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Jin-Dong Dong &middot; An-Chieh Cheng &middot; Da-Cheng Juan &middot; Wei Wei &middot; Min Sun</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-543"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-543" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-543" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-543">
                Abstract <i id="caret-543" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-543">
    <div class="abstract-display">
        <p>Recent breakthroughs in Neural Architectural Search (NAS) have achieved state-of-the-art performances in many applications such as image recognition. However, these techniques typically ignore platform-related constrictions (e.g., inference time and power consumptions) that can be critical for portable devices with limited computing resources. We propose PPP-Net: a multi-objective architectural search framework to automatically generate networks that achieve Pareto Optimality. PPP-Net employs a compact search space inspired by operations used in state-of-the-art mobile CNNs. PPP-Net has also adopted the progressive search strategy used in a recent literature (Liu et al. (2017a)).  Experimental results demonstrate that PPP-Net achieves better performances in both (a) higher accuracy and (b) shorter inference time, comparing to the state-of-the-art CondenseNet.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-585">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/585">Autoregressive Generative Adversarial Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yasin YAZICI &middot; Kim-Hui Yap &middot; Stefan Winkler</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-585"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-585" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-585" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-585">
                Abstract <i id="caret-585" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-585">
    <div class="abstract-display">
        <p>Generative Adversarial Networks (GANs) learn a generative model by playing an adversarial game between a generator and an auxiliary discriminator, which classifies data samples vs.\ generated ones. However, it does not explicitly model feature co-occurrences in samples. In this paper, we propose a novel Autoregressive Generative Adversarial Network (ARGAN), that models the latent distribution of data using an autoregressive model, rather than relying on binary classification of samples into data/generated categories. In this way, feature co-occurrences in samples can be more efficiently captured. Our model was evaluated on two widely used datasets: CIFAR-10 and STL-10. Its performance is competitive with respect to other GAN models both quantitatively and qualitatively.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-544">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/544">Intriguing Properties of Adversarial Examples</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ekin Cubuk &middot; Barret Zoph &middot; Samuel Schoenholz &middot; Quoc V Le</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-544"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-544" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-544" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-544">
                Abstract <i id="caret-544" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-544">
    <div class="abstract-display">
        <p>It is becoming increasingly clear that many machine learning classifiers are vulnerable to adversarial examples. In attempting to explain the origin of adversarial examples, previous studies have typically focused on the fact that neural networks operate on high dimensional data, they overfit, or they are too linear. Here we show that distributions of logit differences have a universal functional form. This functional form is independent of architecture, dataset, and training protocol; nor does it change during training. This leads to adversarial error having a universal scaling, as a power-law, with respect to the size of the adversarial perturbation. We show that this universality holds for a broad range of datasets (MNIST, CIFAR10, ImageNet, and random data), models (including state-of-the-art deep networks, linear models, adversarially trained networks, and networks trained on randomly shuffled labels), and attacks (FGSM, step l.l., PGD). Motivated by these results, we study the effects of reducing prediction entropy on adversarial robustness. Finally, we study the effect of network architectures on adversarial sensitivity. To do this, we use neural architecture search with reinforcement learning to find adversarially robust architectures on CIFAR10. Our resulting architecture is more robust to white \emph{and} black box attacks compared to previous attempts.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-588">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/588">PDE-Net: Learning PDEs from Data</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zichao Long &middot; Yiping Lu &middot; Xianzhong Ma &middot; Bin Dong</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-588"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-588" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-588" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-588">
                Abstract <i id="caret-588" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-588">
    <div class="abstract-display">
        <p>Partial differential equations (PDEs)  play a prominent role in many disciplines such as applied mathematics, physics, chemistry, material science, computer science, etc. PDEs are commonly derived based on physical laws or empirical observations. However, the governing equations for many complex systems in modern applications are still not fully known. With the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of hidden physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE-Net, to fulfill two objectives at the same time: to accurately predict dynamics of complex systems and to uncover the underlying hidden PDE models. The basic idea of the proposed PDE-Net is to learn differential operators by learning convolution kernels (filters), and apply neural networks or other machine learning methods to approximate the unknown nonlinear responses. Comparing with existing approaches, which either assume the form of the nonlinear response is known or fix certain finite difference approximations of differential operators, our approach has the most flexibility by learning both differential …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-465">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/465">Building Generalizable Agents with a Realistic and Rich 3D Environment</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yi Wu &middot; Yuxin Wu &middot; Georgia Gkioxari &middot; Yuandong Tian</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-465"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-465" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-465" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-465">
                Abstract <i id="caret-465" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-465">
    <div class="abstract-display">
        <p>Teaching an agent to navigate in an unseen 3D environment is a challenging task, even in the event of simulated environments. To generalize to unseen environments, an agent needs to be robust to low-level variations (e.g. color, texture, object changes), and also high-level variations (e.g. layout changes of the environment). To improve overall generalization, all types of variations in the environment have to be taken under consideration via different level of data augmentation steps. To this end, we propose House3D, a rich, extensible and efficient environment that contains 45,622 human-designed 3D scenes of visually realistic houses, ranging from single-room studios to multi-storied houses, equipped with a diverse set of fully labeled 3D objects, textures and scene layouts, based on the SUNCG dataset (Song et al., 2017). The diversity in House3D opens the door towards scene-level augmentation, while the label-rich nature of House3D enables us to inject pixel- &amp; task-level augmentations such as domain randomization (Tobin et al., 2017) and multi-task training. Using a subset of houses in House3D, we show that reinforcement learning agents trained with an enhancement of different levels of augmentations perform much better in unseen environments than our baselines with raw RGB input by over 8% in …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-581">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/581">Rotational Unit of Memory</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Rumen R Dangovski &middot; Li Jing &middot; Marin Soljacic</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-581"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-581" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-581" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-581">
                Abstract <i id="caret-581" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-581">
    <div class="abstract-display">
        <p>The concepts of unitary evolution matrices and associative memory have boosted the field of Recurrent Neural Networks (RNN) to state-of-the-art performance in a variety of sequential tasks.  However, RNN still has a limited capacity to manipulate long-term memory.  To bypass this weakness the most successful applications of RNN use external techniques such as attention mechanisms. In this paper we propose a novel RNN model that unifies the state-of-the-art approaches: Rotational Unit of Memory (RUM). The core of RUM is its rotational operation, which is,  naturally,  a unitary matrix, providing architectures with the power to learn long-term dependencies by overcoming the vanishing and exploding gradients problem.  Moreover,  the rotational unit also serves as associative memory. We evaluate our model on synthetic memorization, question answering and language modeling tasks.   RUM learns the Copying Memory task completely and improves the state-of-the-art result in the Recall task.  RUM’s performance in the bAbI Question Answering task is comparable to that of models with attention mechanism. We also improve the state-of-the-art result to 1.189 bits-per-character (BPC) loss in the Character Level Penn Treebank (PTB) task, which is to signify the applications of RUM to real-world sequential data. The universality of our construction, at the core of …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-550">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/550">A moth brain learns to read MNIST</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Charles Delahunt &middot; Nathan Kutz</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-550"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-550" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-550" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-550">
                Abstract <i id="caret-550" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-550">
    <div class="abstract-display">
        <p>We seek to characterize the learning tools (ie algorithmic components) used in biological neural networks, in order to port them to the machine learning context. In particular we address the regime of very few training samples.
The Moth Olfactory Network is among the simplest biological neural systems that can learn. We assigned  a computational model of the Moth Olfactory Network the  task of classifying the MNIST digits. The moth brain successfully learned to read given very few training samples (1 to 20 samples per class). In  this few-samples regime the moth brain substantially outperformed standard ML methods such as Nearest-neighbors, SVM, and CNN.
Our experiments elucidate biological mechanisms for fast learning that rely on cascaded networks, competitive inhibition, sparsity, and Hebbian plasticity. These biological algorithmic components represent a novel, alternative toolkit for building neural nets that may offer a valuable complement to standard  neural nets. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-438">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/438">Reward Estimation for Variance Reduction in Deep Reinforcement Learning</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Joshua Romoff &middot; Alexandre Piche &middot; Peter Henderson &middot; Vincent Francois-Lavet &middot; Joelle Pineau</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-438"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-438" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-438" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-438">
                Abstract <i id="caret-438" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-438">
    <div class="abstract-display">
        <p>In reinforcement learning (RL), stochastic environments can make learning a policy difficult due to high degrees of variance. As such, variance reduction methods have been investigated in other works, such as advantage estimation and control-variates estimation. Here, we propose to learn a separate reward estimator to train the value function, to help reduce variance caused by a noisy reward signal. This results in theoretical reductions in variance in the tabular case, as well as empirical improvements in both the function approximation and tabular settings in environments where rewards are stochastic. To do so, we use a modified version of Advantage Actor Critic (A2C) on variations of Atari games.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-577">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/577">Shifting Mean Activation Towards Zero with Bipolar Activation Functions</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Lars Eidnes &middot; Arild Nøkland</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-577"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-577" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-577" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-577">
                Abstract <i id="caret-577" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-577">
    <div class="abstract-display">
        <p>We propose a simple extension to the ReLU-family of activation functions that allows them to shift the mean activation across a layer towards zero. Combined with proper weight initialization, this alleviates the need for normalization layers. We explore the training of deep vanilla recurrent neural networks (RNNs) with up to 144 layers, and show that bipolar activation functions help learning in this setting. On the Penn Treebank and Text8 language modeling tasks we obtain competitive results, improving on the best reported results for non-gated networks. In experiments with convolutional neural networks without batch normalization, we find that bipolar activations produce a faster drop in training error, and results in a lower test error on the CIFAR-10 classification task.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-466">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/466">Extending Robust Adversarial Reinforcement Learning Considering Adaptation and Diversity</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Hiroaki Shioya &middot; Yusuke Iwasawa &middot; Yutaka Matsuo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-466"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-466" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-466" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-466">
                Abstract <i id="caret-466" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-466">
    <div class="abstract-display">
        <p>We propose two extensions to Robust Adversarial Reinforcement Learning. (Pinto et al., 2017) One is to add a penalty that brings the training domain closer to the test domain to the objective function of the adversarial agent. The other method trains multiple adversarial agents for one protagonist. We conducted experiments with the physical simulator benchmark task. The results show that our method improves performance in the test domain compared to the baseline.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-531">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/531">Meta-Learning a Dynamical Language Model</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Thomas Wolf &middot; Julien Chaumond &middot; clement delangue</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-531"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-531" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-531" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-531">
                Abstract <i id="caret-531" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-531">
    <div class="abstract-display">
        <p>We consider the task of word-level language modeling and study the possibility of combining hidden-states-based short-term representations with medium-term representations encoded in dynamical weights of a language model. Our work extends recent experiments on language models with dynamically evolving weights by casting the language modeling problem into an online learning-to-learn framework in which a meta-learner is trained by gradient-descent to continuously update a language model weights.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-421">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/421">Learning Rich Image Representation with Deep Layer Aggregation</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Fisher Yu &middot; Dequan Wang &middot; Evan Shelhamer &middot; Trevor Darrell</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-421"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-421" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-421" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-421">
                Abstract <i id="caret-421" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-421">
    <div class="abstract-display">
        <p>Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-582">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/582">An Experimental Study of Neural Networks for Variable Graphs</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Xavier Bresson &middot; Thomas Laurent</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-582"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-582" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-582" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-582">
                Abstract <i id="caret-582" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-582">
    <div class="abstract-display">
        <p>Graph-structured data such as social networks, functional brain networks, chemical molecules have brought the interest in generalizing deep learning techniques to graph domains. In this work, we propose an empirical study of neural networks for graphs with variable size and connectivity. We rigorously compare several graph recurrent neural networks (RNNs) and graph convolutional neural networks (ConvNets) to solve two fundamental and representative graph problems, subgraph matching and graph clustering. Numerical results show that graph ConvNets are 3-17% more accurate and 1.5-4x faster than graph RNNs. Interestingly, graph ConvNets are also 36% more accurate than non-learning (variational) techniques. The benefit of such study is to show that complex architectures like LSTM is not useful in the context of graph neural networks, but one should favour architectures with minimal inner structures, such as locality, weight sharing, index invariance, multi-scale, gates and residuality, to design efficient novel neural network models for applications like drugs design, genes analysis and particle physics.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-580">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/580">Learning to Organize Knowledge with N-Gram Machines</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Fan Yang &middot; Jiazhong Nie &middot; William W Cohen &middot; Ni Lao</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-580"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-580" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-580" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-580">
                Abstract <i id="caret-580" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-580">
    <div class="abstract-display">
        <p>Deep neural networks (DNNs) had great success on NLP tasks such as language modeling, machine translation and certain question answering (QA) tasks. However, the success is limited at more knowledge intensive tasks such as QA from a big corpus. Existing end-to-end deep QA models (Miller et al., 2016; Weston et al., 2014) need to read the entire text after observing the question, and therefore their complexity in responding a question is linear in the text size. This is prohibitive for practical tasks such as QA from Wikipedia, a novel, or the Web. We propose to solve this scalability issue by using symbolic meaning representations, which can be indexed and retrieved efficiently with complexity that is independent of the text size. More specifically, we use sequence-to-sequence models to encode knowledge symbolically and generate programs to answer questions from the encoded knowledge. We apply our approach, called the N-Gram Machine (NGM), to the bAbI tasks (Weston et al., 2015) and a special version of them (“life-long bAbI”) which has stories of up to 10 million sentences. Our experiments show that NGM can successfully solve both of these tasks accurately and efficiently. Unlike fully differentiable memory models, NGM’s time complexity and answering quality …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-554">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/554">Learning Representations and Generative Models for 3D Point Clouds</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Panagiotis Achlioptas &middot; Olga Diamanti &middot; Ioannis Mitliagkas &middot; Leonidas Guibas</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-554"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-554" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-554" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-554">
                Abstract <i id="caret-554" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-554">
    <div class="abstract-display">
        <p>Three-dimensional geometric data offer an excellent domain for studying representation learning and generative modeling. In this paper, we look at geometric data represented as point clouds. We introduce a deep autoencoder (AE) network with excellent reconstruction quality and generalization ability. The learned representations outperform the state of the art in 3D recognition tasks and enable basic shape editing applications via simple algebraic manipulations, such as semantic part editing, shape analogies and shape interpolation. We also perform a thorough study of different generative models including GANs operating on the raw point clouds, significantly improved GANs trained in the fixed latent space our AEs and, Gaussian mixture models (GMM). Interestingly, GMMs trained in the latent space of our AEs produce samples of the best fidelity and diversity.
To perform our quantitative evaluation of generative models, we propose simple measures of fidelity and diversity based on optimally matching between sets point clouds.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-591">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/591">Parametric Adversarial Divergences are Good Task Losses for Generative Modeling</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Gabriel Huang &middot; Hugo Berard &middot; Ahmed Touati &middot; Gauthier Gidel &middot; Pascal Vincent &middot; Simon Lacoste-Julien</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-591"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-591" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-591" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-591">
                Abstract <i id="caret-591" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-591">
    <div class="abstract-display">
        <p>Generative modeling of high dimensional data like images is a notoriously difficult and ill-defined problem. In particular, how to evaluate a learned generative model is unclear.
In this paper, we argue that <em>adversarial learning</em>, pioneered with generative adversarial networks (GANs), provides an interesting framework to implicitly define more meaningful task losses for unsupervised tasks, such as for generating "visually realistic" images. By relating GANs and structured prediction under the framework of statistical decision theory, we put into light links between recent advances in structured prediction theory and the choice of the divergence in GANs. We argue that the insights about the notions of "hard" and "easy" to learn losses can be analogously extended to adversarial divergences. We also discuss the attractive properties of parametric adversarial divergences for generative modeling, and perform experiments to show the importance of choosing a divergence that reflects the final task.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-592">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/592">Learning to Infer</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Joe Marino &middot; Yisong Yue &middot; Stephan Mandt</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-592"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-592" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-592" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-592">
                Abstract <i id="caret-592" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-592">
    <div class="abstract-display">
        <p>Inference models, which replace an optimization-based inference procedure with a learned model, have been fundamental in advancing Bayesian deep learning, the most notable example being variational auto-encoders (VAEs). In this paper, we propose iterative inference models, which learn how to optimize a variational lower bound through repeatedly encoding gradients. Our approach generalizes VAEs under certain conditions, and by viewing VAEs in the context of iterative inference, we provide further insight into several recent empirical findings. We demonstrate the inference optimization capabilities of iterative inference models, explore unique aspects of these models, and show that they outperform standard inference models on typical benchmark data sets.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-590">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/590">Adaptive Memory Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Daniel Li &middot; Asim Kadav</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-590"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-590" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-590" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-590">
                Abstract <i id="caret-590" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-590">
    <div class="abstract-display">
        <p>We present Adaptive Memory Networks (AMN) that process input-question pairs to dynamically construct a network architecture optimized for lower inference times. AMN creates multiple memory banks to store entities from the input story to answer the questions. The model learns to reason important entities from the input text based on the question and concentrates these entities within a single memory bank. At inference, one or few banks are used, creating a tradeoff between accuracy and performance. AMN is enabled by first, a novel bank controller that makes discrete decisions with high accuracy and second,  the capabilities of dynamic frameworks (such as PyTorch) that allow for dynamic network sizing and efficient variable mini-batching.  In our results, we demonstrate that our model learns to construct a varying number of memory banks based on task complexity and achieves faster inference times for standard bAbI tasks, and modified bAbI tasks.  We solve all bAbI tasks with an average of 48% fewer entities on tasks containing excess, unrelated information.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-510">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/510">Simple and efficient architecture search for Convolutional Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Thomas Elsken &middot; Jan Hendrik Metzen &middot; Frank Hutter</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-510"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-510" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-510" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-510">
                Abstract <i id="caret-510" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-510">
    <div class="abstract-display">
        <p>Neural networks have recently had a lot of success for many tasks. However, neural
network architectures that perform well are still typically designed manually
by experts in a cumbersome trial-and-error process. We propose a new method
to automatically search for well-performing CNN architectures based on a simple
hill climbing procedure whose operators apply network morphisms, followed
by short optimization runs by cosine annealing. Surprisingly, this simple method
yields competitive results, despite only requiring resources in the same order of
magnitude as training a single network. E.g., on CIFAR-10, our method designs
and trains networks with an error rate below 6% in only 12 hours on a single GPU;
training for one day reduces this error further, to almost 5%.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-574">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/574">Neural network parameter regression for lattice quantum chromodynamics simulations in nuclear and particle physics</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Phiala Shanahan &middot; Daniel Trewartha &middot; William Detmold</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-574"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-574" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-574" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-574">
                Abstract <i id="caret-574" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-574">
    <div class="abstract-display">
        <p>Nuclear and particle physicists seek to understand the structure of matter at the smallest scales through numerical simulations of lattice Quantum Chromodynamics (LQCD) performed on the largest supercomputers available. Multi-scale techniques have the potential to dramatically reduce the computational cost of such simulations, if a challenging parameter regression problem matching physics  at different resolution scales can be solved. Simple neural networks applied to this task fail because of the dramatic inverted data hierarchy that this problem displays, with orders of magnitude fewer samples typically available  than degrees of freedom per sample. Symmetry-aware networks that respect the complicated invariances of the underlying physics, however, provide an efficient and practical solution. Further efforts to incorporate invariances and constraints that are typical of physics problems into  neural networks and other machine learning algorithms have potential to dramatically impact studies of systems in nuclear, particle, condensed matter, and statistical physics.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-521">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/521">Adversarial Policy Gradient for Alternating Markov Games</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Chao Gao &middot; Martin Mueller &middot; Ryan Hayward</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-521"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-521" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-521" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-521">
                Abstract <i id="caret-521" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-521">
    <div class="abstract-display">
        <p>Policy gradient reinforcement learning has been applied to two-player alternate-turn zero-sum games, e.g., in AlphaGo, self-play REINFORCE was used to improve the neural net model after supervised learning. In this paper, we emphasize that two-player zero-sum games with alternating turns, which have been previously formulated as Alternating Markov Games (AMGs), are different from standard MDP because of their two-agent nature. We exploit the difference in associated Bellman equations, which leads to different policy iteration algorithms. As policy gradient method is a kind of generalized policy iteration, we show how these differences in policy iteration are reflected in policy gradient for AMGs. We formulate an adversarial policy gradient and discuss potential possibilities for developing better policy gradient methods other than self-play REINFORCE. The core idea is to estimate the minimum rather than the mean for the “critic”. Experimental results on the game of Hex show the modified Monte Carlo policy gradient methods are able to learn better pure neural net policies than the REINFORCE variants. To apply learned neural weights to multiple board sizes Hex, we describe a board-size independent neural net architecture. We show that when combined with search, using a single neural net model, the resulting program consistently beats …</p>
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-564">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/564">eCommerceGAN: A Generative Adversarial Network for e-commerce</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Ashutosh Kumar &middot; Arijit Biswas &middot; Subhajit Sanyal</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-564"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-564" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-564" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-564">
                Abstract <i id="caret-564" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-564">
    <div class="abstract-display">
        <p>E-commerce companies such as Amazon, Alibaba, and Flipkart process billions of orders every year. However, these orders represent only a small fraction of all plausible orders. Exploring the space of all plausible orders could help us better understand the relationships between the various entities in an e-commerce ecosystem, namely the customers and the products they purchase. In this paper, we propose a Generative Adversarial Network (GAN) for e-commerce orders. Our contributions include: (a) creating a dense and low-dimensional representation of e-commerce orders, (b) train an ecommerceGAN (ecGAN) with real orders to show the feasibility of the proposed paradigm, and (c) train an ecommerce-conditional- GAN (ec2GAN) to generate the plausible orders involving a particular product. We evaluate ecGAN qualitatively to demonstrate its effectiveness. The ec2GAN is used for various kinds of characterization of possible orders involving cold-start products.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-565">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/565">SufiSent - Universal Sentence Representations Using Suffix Encodings</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Siddhartha Brahma</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-565"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-565" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-565" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-565">
                Abstract <i id="caret-565" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-565">
    <div class="abstract-display">
        <p>Computing universal distributed representations of sentences is a fundamental task
in natural language processing. We propose a method to learn such representations
by encoding the suffixes of word sequences in a sentence and training on the
Stanford Natural Language Inference (SNLI) dataset. We demonstrate the effectiveness
of our approach by evaluating it on the SentEval benchmark, improving
on existing approaches on several transfer tasks.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-566">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/566">Regularization Neural Networks via Constrained Virtual Movement Field</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Zhendong Zhang &middot; Cheolkon Jung</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-566"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-566" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-566" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-566">
                Abstract <i id="caret-566" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-566">
    <div class="abstract-display">
        <p>We smooth the objective of neural networks w.r.t small adversarial perturbations of the inputs. Different from previous works, we assume the adversarial perturbations are caused by the movement field. When the magnitude of movement field approaches 0, we call it virtual movement field. By introducing the movement field, we cast the problem of finding adversarial perturbations into the problem of finding adversarial movement field. By adding proper geometrical constraints to the movement field, such smoothness can be approximated in closed-form by solving a min-max problem and its geometric meaning is clear. We define the approximated smoothness as the regularization term.  We derive three regularization terms as running examples which measure the smoothness w.r.t shift, rotation and scale respectively by adding different constraints. We evaluate our methods on synthetic data, MNIST and CIFAR-10. Experimental results show that our proposed method can significantly improve the baseline neural networks. Compared with the state of the art regularization methods, proposed method achieves a tradeoff between accuracy and geometrical interpretability as well as computational cost.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-558">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/558">Finding Flatter Minima with SGD</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Devansh Arpit</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-558"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-558" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-558" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-558">
                Abstract <i id="caret-558" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-558">
    <div class="abstract-display">
        <p>It has been discussed that over-parameterized deep neural networks (DNNs) trained using stochastic gradient descent (SGD) with smaller batch sizes generalize better compared with those trained with larger batch sizes. Additionally, model parameters found by small batch size SGD tend to be in flatter regions. We extend these empirical observations and experimentally show that both large learning rate and small batch size contribute towards SGD finding flatter minima that generalize well. Conversely, we find that small learning rates and large batch sizes lead to sharper minima that correlate with poor generalization in DNNs.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-557">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/557">Designing Efficient Neural Attention Systems Towards Achieving Human-level Sharp Vision</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Abdul Rahman Abdul Ghani &middot; Nishanth Koganti &middot; Alfredo Solano &middot; Yusuke Iwasawa &middot; Kotaro Nakayama &middot; Yutaka Matsuo</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-557"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-557" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-557" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-557">
                Abstract <i id="caret-557" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-557">
    <div class="abstract-display">
        <p>Human vision is capable of focusing on subtle visual cues at high resolution by relying on a foveal view coupled with an attention mechanism. Recently, there have been several studies that proposed deep reinforcement learning based attention models. However, these studies do not explicitly consider the design of a foveal representation and its effect on an attention system is unclear. In this paper, we investigate the effect of using a hierarchy of visual streams in training an efficient attention model towards achieving a human-level sharp vision. We perform our evaluation on a simulated human-robot interaction task where the agent attends to faces that are looking at it. The experimental results show that the performance of the system relies on factors such as the number of visual streams, their relative field-of-view and we demonstrate that maintaining a hierarchy within the visual streams is crucial to learn attention strategies. </p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-439">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/439">Online variance-reducing optimization</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Nicolas Le Roux &middot; Reza Babanezhad Harikandeh &middot; Pierre-Antoine Manzagol</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-439"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-439" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-439" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-439">
                Abstract <i id="caret-439" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-439">
    <div class="abstract-display">
        <p>We emphasize the importance of variance reduction in stochastic methods and propose a probabilistic interpretation as a way to store information about past gradients. The resulting algorithm is very similar to the momentum method, with the difference that the weight over past gradients depends on the distance moved in parameter space rather than the number of steps.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-589">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/589">Reinforcement Learning from Imperfect Demonstrations</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yang Gao &middot; Huazhe Xu &middot; Ji Lin &middot; Fisher Yu &middot; Sergey Levine &middot; Trevor Darrell</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-589"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-589" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-589" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-589">
                Abstract <i id="caret-589" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-589">
    <div class="abstract-display">
        <p>Robust real-world  learning should benefit from both demonstrations and interaction with the environment. Current approaches to learning from demonstration and reward perform supervised learning on expert demonstration data and use reinforcement learning  to further improve performance based on reward from the environment. These tasks have divergent losses which are difficult to jointly optimize; further, such methods can be very sensitive to noisy demonstrations. We propose a unified reinforcement learning algorithm, Normalized Actor-Critic (NAC), that effectively normalizes the Q-function, reducing the Q-values of actions unseen in the demonstration data. NAC learns an initial policy network from demonstration and refines the policy in a real environment. Crucially, both learning from demonstration and interactive refinement use exactly the same objective, unlike prior approaches that combine distinct supervised and reinforcement losses. This makes NAC robust to suboptimal demonstration data, since the method is not forced to mimic all of the examples in the dataset. We show that our unified reinforcement learning algorithm can learn robustly and  outperform existing baselines when evaluated on several realistic driving games.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-491">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/491">Leveraging Constraint Logic Programming for Neural Guided Program Synthesis</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Lisa Zhang &middot; Gregory Rosenblatt &middot; Ethan Fetaya &middot; Renjie Liao &middot; William Byrd &middot; Raquel Urtasun &middot; Richard Zemel</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-491"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-491" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-491" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-491">
                Abstract <i id="caret-491" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-491">
    <div class="abstract-display">
        <p>We present a method for solving Programming by Example (PBE) problems that tightly integrates a neural network with a constraint logic programming system called miniKanren. Internally, miniKanren searches for a program that satisfies the recursive constraints imposed by the provided examples. Our Recurrent Neural Network (RNN) model uses these constraints as input to score candidate programs. We show evidence that using our method to guide miniKanren’s search is a promising approach to solving PBE problems.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-594">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/594">GeoSeq2Seq: Information Geometric Sequence-to-Sequence Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Alessandro Bay &middot; Biswa Sengupta</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-594"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-594" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-594" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-594">
                Abstract <i id="caret-594" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-594">
    <div class="abstract-display">
        <p>The Fisher information metric is an important foundation of information geometry, wherein it allows us to approximate the local geometry of a probability distribution. Recurrent neural networks such as the Sequence-to-Sequence (Seq2Seq) networks that have lately been used to yield state-of-the-art performance on speech translation or image captioning have so far ignored the geometry of the latent embedding, that they iteratively learn. We propose the information geometric Seq2Seq (GeoSeq2Seq) network which abridges the gap between deep recurrent neural networks and information geometry. Specifically, the latent embedding offered by a recurrent network is encoded as a Fisher kernel of a parametric Gaussian Mixture Model, a formalism common in computer vision. We utilise such a network to predict the shortest routes between two nodes of a graph by learning the adjacency matrix using the GeoSeq2Seq formalism; our results show that for such a problem the probabilistic representation of the latent embedding supersedes the non-probabilistic embedding by 10-15\%.</p>

    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-593">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/593">3D-FilterMap: A Compact Architecture for Deep Convolutional Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">Yingzhen Yang &middot; Jianchao Yang &middot; Ning Xu &middot; Wei Han &middot; Nebojsa Jojic &middot; Thomas Huang</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-593"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-593" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-593" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-593">
                Abstract <i id="caret-593" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-593">
    <div class="abstract-display">
        We present a novel and compact architecture for deep Convolutional Neural Networks (CNNs) in this paper, termed $3$D-FilterMap Convolutional Neural Networks ($3$D-FM-CNNs). The convolution layer of $3$D-FM-CNN learns a compact representation of the filters, named $3$D-FilterMap, instead of a set of independent filters in the conventional convolution layer. The filters are extracted from the $3$D-FilterMap as overlapping $3$D submatrics with weight sharing among nearby filters, and these filters are convolved with the input to generate the output of the convolution layer for $3$D-FM-CNN. Due to the weight sharing scheme, the parameter size of the $3$D-FilterMap is much smaller than that of the filters to be learned in the conventional convolution layer when $3$D-FilterMap generates the same number of filters. Our work is fundamentally different from the network compression literature that reduces the size of a learned large network in the sense that a small network is directly learned from scratch. Experimental results demonstrate that $3$D-FM-CNN enjoys a small parameter space by learning compact $3$D-FilterMaps, while achieving performance compared to that of the baseline CNNs which learn the same number of filters as that generated by the corresponding $3$D-FilterMap.
    </div>
</div>

                                    </div>
                                
                                    <div class="displaycards touchup-date" id="event-417">
                                        

                                        

<div style="width:80%;margin:auto;">
    <a class="small-title" href="/virtual/2018/workshop/417">Inference in probabilistic graphical models by Graph Neural Networks</a>
</div>
<div class="type_display_name_minus_type"></div>
<div class="author-str">KiJung Yoon &middot; Renjie Liao &middot; Yuwen Xiong &middot; Lisa Zhang &middot; Ethan Fetaya &middot; Raquel Urtasun &middot; Richard Zemel &middot; Xaq Pitkow</div>
<div class="author-str higher"></div>
<div class="text-muted touchup-date-div" id="touchup-date-event-417"></div>


    <p style="font-size:.9em;">[ East Meeting Level 8 + 15 ]</p>





<div class="abstract-section">
    
        <div>
            <a id="abstract-link-417" class="abstract-link" data-toggle="collapse"
               href="#collapse-event-abstract-417" role="button"
               aria-expanded="false" aria-controls="collapse-event-abstract-417">
                Abstract <i id="caret-417" class="fas fa-caret-right"></i>
            </a>
        </div>

    
</div>
<div class="collapse" id="collapse-event-abstract-417">
    <div class="abstract-display">
        <p>A useful computation when acting in a complex environment is to infer the marginal probabilities or most probable states of task-relevant variables. Probabilistic graphical models can efficiently represent the structure of such complex data, but performing these inferences is generally difficult. Message-passing algorithms, such as belief propagation, are a natural way to disseminate evidence amongst correlated variables while exploiting the graph structure, but these algorithms can struggle when the conditional dependency graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a message-passing algorithm that solves these inference tasks. We demonstrate the efficacy of this inference approach by training GNNs on an ensemble of graphical models and showing that they substantially outperform belief propagation on loopy graphs. Our message-passing algorithms generalize out of the training set to larger graphs and graphs with different structure.</p>

    </div>
</div>

                                    </div>
                                
                        </div>
                    </div>
                
            </div>


        
        <script>
            function listmode(){
                $(".cards_img").hide();
                $(".pp-card").addClass("pp-mode-list").removeClass("pp-mode-compact");
            }
            function compactmode(){
                $(".cards_img").show();
                $(".pp-card").removeClass("pp-mode-list").addClass("pp-mode-compact");
            }
        </script>


    

<script>


    $(document).ready(function() {
        $(".abstract-link").on('click', function(e){
            var target = $(e.target).find("i")
            target.toggleClass("fa-caret-right");
            target.toggleClass("fa-caret-up");
        })
        touchup();
        /* touchup events currently adds dates to cached virtualcards for events */
    })

</script>


    
        </div>
    

</main>
<!--END BLOCK CONTENT-->


<!--Footer for the edit button-->


<script>

    $(function () {
        if ($(".editable").length == 0) {
            $("#editFooter").hide();
        }
    })
</script>

<script src="/static/core/js/fastclick.min.js" type="text/javascript"></script>

<!--We don't know if there are editable tags on the page until after the django template engine has rendered the page. So,
test in javascript for "editable" tags and if present, load the ckeditor engine dynamically. -->

<script>
  if (document.getElementsByClassName('editable').length > 0) {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src = "/static/core/ckeditor/4.18/ckeditor.js";    // use this for linked script
    script.text = "alert('voila!');"               // use this for inline script
    document.body.appendChild(script);
  }

</script>


<script>
  function fetchContent() {
    $(".editable").each(function (index) {
    var myself = this;
    var docvID = this.getAttribute('documentversion');
    var blurbtext = this.getAttribute("blurbtext");
    $.ajax({
       url: "/Admin/RetrieveDocumentVersion",
       type:"POST",
       data:{
           docvID : docvID,
           blurbtext : blurbtext,
           csrfmiddlewaretoken: csrftoken,
       },
       success: function(data, textStatus, jqXHR) {
           myself.setAttribute("contenteditable", "true");
           myself.innerHTML = data;
           CKEDITOR.inline(myself.id);
       },
    });
  })
}

$("#nopageedit").hide();
function start_edit(){

  $(".editable").addClass("warning-ring");

  //At the beginning of an edit, we need to replace the content of the
  //editable div with it's databased content in order to preserve the
  //template tags. We want the tag, not the rendered tag.

  /* You must remove any countdown.js timers on the page before replacing the page with it's
  document version otherwise, Javascript will throw an exception.  */


  $("[class$='-countdown']").parent().remove();
  fetchContent();
  $(".editable").attr("onblur", "ckeditorsave(this)");
  window.status.bold();
  window.status = "Click outside the editable area to save. Changes are LIVE!! Refresh page to discard changes.";
  $("#editpage").hide();
  $("#noeditpage").show();
}


  function stop_edit() {
    ckeditorsave();
    $("#noeditpage").hide();
    $("#editpage").show();
    window.location.reload();
}
function ckeditorsave(event){
  for (var name in CKEDITOR.instances){
    if ( CKEDITOR.instances[name].checkDirty() ){
      editor = CKEDITOR.instances[name];
      saveEditable(editor);
    }
  }
}

function saveEditable(editor){
  var content = editor.getData();
  var contentId = editor.name;
  var pageId = window.location.pathname;
  var originalContent = "N/A";
  var documentversion = editor.container.getAttribute("documentversion");
  var blurbtext = editor.container.getAttribute("blurbtext");
  if ( contentId.match(/-aloha$/gi) ) {
    contentId = contentId.replace( /-aloha/gi, '' );
  }  /*I'm not sure what this does but it seems like it would matter*/
  var request = jQuery.ajax({
    url: "/Admin/SaveDocument",
    type: "POST",
    async: false,
    data: {
      content : content,
      originalContent: originalContent,
      contentId : contentId,
      pageId : pageId,
      documentversion:documentversion,
      blurbtext : blurbtext,
      csrfmiddlewaretoken: csrftoken
    },
    success: function(data){
        if (data['message']){
            alert(data['message']);
        }
    },
    error: function(xqXHR, textStatus){
        window.status = textStatus;
        debugger;
    }

  });

};




</script>

<script type="text/javascript">
       jQuery(document).ajaxSend(function(event, xhr, settings) {
           function getCookie(name) {
               var cookieValue = null;
               if (document.cookie && document.cookie != '') {
                   var cookies = document.cookie.split(';');
                   for (var i = 0; i < cookies.length; i++) {
                       var cookie = jQuery.trim(cookies[i]);
                       // Does this cookie string begin with the name we want?
                       if (cookie.substring(0, name.length + 1) == (name + '=')) {
                           cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                           break;
                       }
                   }
               }
               return cookieValue;
           }
           function sameOrigin(url) {
               // url could be relative or scheme relative or absolute
               var host = document.location.host; // host + port
               var protocol = document.location.protocol;
               var sr_origin = '//' + host;
               var origin = protocol + sr_origin;
               // Allow absolute or scheme relative URLs to same origin
               return (url == origin || url.slice(0, origin.length + 1) == origin + '/') ||
                   (url == sr_origin || url.slice(0, sr_origin.length + 1) == sr_origin + '/') ||
                   // or any other URL that isn't scheme relative or absolute i.e relative.
                   !(/^(\/\/|http:|https:).*/.test(url));
           }
           function safeMethod(method) {
               return (/^(GET|HEAD|OPTIONS|TRACE)$/.test(method));
           }

           if (!safeMethod(settings.type) && sameOrigin(settings.url)) {
               xhr.setRequestHeader("X-CSRFToken", getCookie('csrftoken'));
           }
       });
</script>





<div id="successful-page-load" class='hidden'>Successful Page Load</div>





    
        <link href="/static/conf_gdpr/css/conf_gdpr.css" rel="stylesheet">
        <div id="cookie-bar" style="z-index: 8">
            <table class="gdpr-statement">
                <col>
                <col style="width:120px">
                <tr>
                    <td style="padding:5px">
                        ICLR uses cookies to remember that you are logged in. By using our websites, you agree
                        to the placement of cookies. <a href="/public/PrivacyPolicy">
                        Our Privacy Policy &raquo;&nbsp;</a>
                    </td>
                    <td>
                        <button float-end class="btn btn-light btn-sm btn btn-outline-dark" onClick="accept_cookies();">Accept
                            Cookies
                        </button>
                    </td>
                </tr>
            </table>
        </div>

        <script>
            function accept_cookies() {

                $.ajax({
                    method: "POST",
                    url: "/conf_gdpr/accept",
                    data: {
                        csrfmiddlewaretoken: csrftoken,
                    },
                }).done(function (data) {
                    console.log(data);
                    $("#cookie-bar").fadeOut();
                }).fail(function (jqXHR, textStatus) {
                    alert(textStatus);
                });
            }
        </script>

    






<br>
<footer id="bootstrap-footer" class="text-center text-lg-start bg-light text-muted">

    <div class="text-center p-1 border-top border-dark">
    </div>
    <!-- Section: Links  -->
    <section class="pt-1">
        <div class="container text-center text-md-start mt-3">
            <!-- Grid row -->
            <div class="row mt-3">
                <!-- Grid column -->
                <div class="col-md-3 col-lg-3 col-xl-3 mx-auto mb-3">
                    <!-- Content -->
                    <h6 class="text-uppercase fw-bold mb-4">
                        <img src="/static/core/img/ICLR-logo.svg" alt="ICLR logo" height='30px'>
                    </h6>
                    <p>
                        The ICLR Logo above may be used on presentations. Right-click and choose
                        download. It is a vector graphic and may be used at any scale.
                    </p>

                </div>


                <!-- Grid column -->
                <div class="col-md-5 col-lg-4 col-xl-3 mx-auto mb-4" style="max-width: 300px;">
                    <!-- Links -->
                    <h6 class="text-uppercase fw-bold mb-4 text-center">
                        Useful links
                    </h6>
                    <div></div>
                </div>
                <!-- Grid column -->

                <!-- Grid column -->
                <div class="col-md-4 col-lg-3 col-xl-3 mx-auto mb-md-0 mb-4">
                    <!-- Links -->
                    <h6 class="text-uppercase fw-bold mb-4">Contact</h6>
                    
                        <p>
                            <i class="fas fa-home me-3"></i> 2710 E Corridor Dr, Appleton WI 54913
                        </p>
                    
                    <p>
                        <i class="fas fa-envelope me-3"></i> <a href="/Help/Contact">Email</a>
                    </p>
                    
                        <p><i class="fas fa-phone me-3"></i> Phone: +1-714-214-1616</p>
                    
                    


                </div>
                <!-- Grid column -->
            </div>
            <!-- Grid row -->
        </div>
    </section>
    <!-- Section: Links  -->

    <!-- Copyright -->
    <div class="text-center p-4" style="background-color: rgba(0, 0, 0, 0.05);">
        <div></div>
    </div>
    <!-- Copyright -->
</footer>
<!-- Footer -->

<!-- Footer -->

</body>
</html>
